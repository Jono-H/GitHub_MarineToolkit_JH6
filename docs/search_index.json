[["index.html", "Marine Megafauna Conservation Toolkit Welcome Toolkit overview What is the toolkit? How does the toolkit work? What content does the toolkit cover? Who made the toolkit", " Marine Megafauna Conservation Toolkit Welcome Toolkit overview Watch the video below to learn more about the Marine Megafauna Conservation Toolkit What is the toolkit? The Marine Megafauna Conservation Toolkit is an open-access online toolkit which facilitates the identification of important sites for marine megafauna and pathways to advocate for their conservation. Essentially, the toolkit is like an interactive textbook with key lessons and training material within it. How does the toolkit work? Click on the sections outlined in the table of contents on the left panel to navigate through the different material. What content does the toolkit cover? Through three main components, the toolkit: helps users identify critical sites for species, including supporting users to turn complex animal tracking data into outputs useful for decision-makers. (The toolkit helps you analyse data with R software to create key outputs) helps users in identifying effective conservation interventions through case studies curated by the global Conservation Evidence Team. (The toolkit helps you understand what solutions are known to help with species conservation) helps users understand which mechanisms can support decision-makers to act, by guiding users through the policy and advocacy opportunities for site-based conservation. (The toolkit helps you understand how decision-makers can use your data) Who made the toolkit First edition, produced on February 23, 2024 This toolkit was produced by the BirdLife International Marine Programme of BirdLife International, with support from: British Trust for Ornithology Royal Society for the Protection of Birds Cambridge University Conservation Evidence Key Biodiversity Area Secretariat Conservation International The toolkit builds upon the Marine IBA Toolkit (BirdLife International (2010)). Key organisations who supported the development of the current toolkit include: Association BIOM, Croatia BirdLife Malta, Malta Hellenic Ornithological Society, Greece BirdLife South Africa, South Africa Bombay Natural History Society, India Previous supporting organisations include: Portuguese Society for the Study of Birds (SPEA) SEO/BirdLife Ligue pour la Protection des Oiseaux (LPO) The development of this toolkit was made possible by Cambridge Conservation Initiative Collaborative Fund, with key support from: Arcadia - a charitable fund of Lisbet Rausing and Peter Baldwin, A.G. Leventis Foundation Additional support to project partners was provided by: Life Artina Life Pan Puffinus "],["executive-summary.html", "1 Executive summary", " 1 Executive summary Welcome to the Marine Megafauna Conservation Toolkit. The Marine Megafauna Conservation Toolkit is an open-access online toolkit which facilitates the identification of important sites for marine megafauna and pathways to advocate for their conservation. A primary goal of the toolkit is to facilitate the application of methods to identify sites that meet Key Biodiversity Area (KBA) criteria, including from tracking data, and relevant implementation of conservation actions to support marine megafauna achieve or maintain a favourable conservation status. The toolkit was built because identifying important sites for marine megafauna and knowing how to leverage important site information to achieve a conservation outcome is not straightforward. This new toolkit therefore facilitates the urgent need to scale solutions for nature conservation. Through three main components, the toolkit: (1) helps users identify critical sites for species, including supporting users to turn complex animal tracking data into outputs useful for decision-makers, (2) helps users in identifying effective conservation interventions through case studies curated by the global Conservation Evidence Team, and (3) helps users understand which mechanisms can support decision-makers to act, by guiding users through the policy and advocacy opportunities for site-based conservation. Whether focused on an individual site or networks of sites from national, regional, to global levels, the toolkit serves to scale solutions for the conservation of marine megafauna. Ultimately, the toolkit is a key facilitating mechanism that can enable individuals or groups to better deliver outputs and information required for achieving global commitments such as those of the Kunming-Montreal Global Biodiversity Framework and UN Sustainable Development Goals. "],["what-the-toolkit-offers.html", "2 What the toolkit offers 2.1 Key Biodiversity Areas 2.2 Overview of toolkit content", " 2 What the toolkit offers The toolkit comprises three main components that: help users identify critical sites for species, including supporting users to turn complex animal tracking data into outputs useful for decision-makers. The toolkit also helps guide users to generate the data they need for an effective Key Biodiversity Area proposal. help users to identify threats that may impact species at sites and then identify effective conservation interventions which could be applied at sites. help users understand which mechanisms can support decision-makers to act, by guiding users through the policy and advocacy opportunties for site-based conservation. Ultimately, the toolkit provides the foundations to recognise important sites for marine megafauna; helping us to prioritise and conserve critical sites for the persistence of biodiversity from individual sites, to national, regional and global networks. 2.1 Key Biodiversity Areas This toolkit ultimately aims to support users achieve species being in a favourable conservation status. The toolkit is biased to site-based conservation measures which support species achieving a favrouable conservation status through the conservation and management of globally important sites for biodiversity, Key Biodiversity Areas (KBAs), given the strong links KBAs have to global and national policy mechanisms. However, many of the processes and tools outlined in the toolkit will be relevant to the conservation and management of sites which do not meet the criteria to be a considered a Key Biodiversity Area but, nevertheless, may warrant conservation and management measures at differing scales. 2.2 Overview of toolkit content The figure below outlines the content of each section and chapter within the toolkit: "],["what-the-toolkit-does-not-offer.html", "3 What the toolkit does not offer", " 3 What the toolkit does not offer The toolkit has much room for growth and we wholeheartedly welcome contributions from the broader community working toward marine megafauna conservation. Nevertheless, the toolkit cannot cover every aspect possible that could contribute toward marine megafauna conservation. Although we would love to highlight available resources through the toolkit. Considering what the toolkit aims to achieve, and broader knowledge a user might need to achieve key outputs, the toolkit does not cover the following in detail: How to install R and RStudio, and the fundamentals of R. Detailed instructions about how to generate animal abundance estimates. Comprehensive background to analysing animal tracking data. Analysing at-sea survey data or developing species distribution models. We welcome guidance we can recommend on some of these points or links to key tutorials or training courses. "],["contribute-to-the-toolkit.html", "4 Contribute to the toolkit", " 4 Contribute to the toolkit We want your help to make this toolkit better! This Marine Megafauna Conservation Toolkit builds on past successes of a previous toolkit that has contributed greatly to marine conservation outcomes (BirdLife International (2010)). This latest version was built with a small budget by a small team, and with support from an incredible group of contributors. Our understanding of marine systems will change, technology will change, methods will change, policy will change, accessibility will change. All these changes mean there are ever growing opportunities to improve on things and do things better: ultimately allowing us to scale up the urgent solutions needed to deliver conservation outcomes for marine megafauna and associated biodiversity. We have a growing list of ideas and questions we are considering to make this toolkit better for everyone and we can’t do it alone. We want this toolkit to evolve into a marine conservation community led initiative. If you have an idea or suggestion for an improvement (anything from language, visualisation, analysis, other), please reach out to us. We have not worked out all the details about the best way to contribute. But, fundamentally, it is our philosophy that anyone who contributes in a constructive way deserves accreditation in the toolkit. "],["getting-a-site-conserved.html", "5 Getting a site conserved 5.1 Theory of Change 5.2 Simplified Theory of Change 5.3 Detailed Theory of Change", " 5 Getting a site conserved This toolkit ultimately aims to support users achieve species being in a favourable conservation status. The toolkit is biased to site-based conservation measures which support species achieving a favrouable conservation status through the conservation and management of globally important sites for biodiversity: Key Biodiversity Areas (KBAs). However, many of the processes and tools outlined in the toolkit will be relevant to the conservation and management of sites which do not meet the criteria to be a considered a Key Biodiversity Area but, nevertheless, may warrant conservation and management measures at differing scales. We primarily consider a “favourable conservation status” in the context of the International Union for Conservation of Nature’s (IUCN) Red List of Threatened Species, the world’s most comprehensive information source on the global extinction risk status of animal, fungus and plant species. We recognise that other indices of what may be considered a “favourable conservation status” also exist. For example, national level indices may exist that categorise species in a different way compared to the global IUCN Red List of Threatened Species. Although the resources in the toolkit are biased to particular global outputs (i.e. Key Biodiveristy Areas, KBAs), the toolkit can also help users achieve species reaching a favourable conservation status at scales varying from site specific, to national, regional and global levels. 5.1 Theory of Change To showcase how users can achieve species being in a favourable conservation status, we use a planning tool called a Theory of Change. A Theory of Change is simply a visual way of depicting the causal pathways (the steps) leading toward the conservation outcome you are trying to achieve. 5.2 Simplified Theory of Change The simplified summary Theory of Change is outlined below. This simplified Theory of Change recognises the following: The long-term goal that we want to see for marine megafauan, and of course biodiversity more broadly, is that populations of species are in favourable conservation status. To achieve this: we need the necessary decision-makers to act This means decision makers need both pull (policy) and push (advocacy) mechanisms to implement practices favourable to biodiversity. The relative mechanisms that can bring about change need to be based on appropriate evidence. And we need to know where and when to act (the sites). Therefore, it’s critical to identify important places in which interventions will be beneficial, and for which species require those interventions Ideally, this should occur in a cyclical process, where the impact of interventions is consistently monitored and altered accordingly to achieve the desired outcome. 5.3 Detailed Theory of Change The detailed Theory of Change is outlined below. The detailed Theory of Change is also a useful planning tool when considering what components of a project you would like to achieve and fundraise for. This detailed visual way of depicting the causal pathways (the steps) leading toward the conservation outcome you are trying to achieve, shows some of the key actions required (i.e. the things you must do) to deliver the necessary outcomes required (i.e. the things that will happen based on the things that you do). By doing the actions and achieving each of the intermediate outcomes, this can lead toward the final threat reduction outcomes and ultimately the long term goal being achieved (Marine megafauna in favorable conservation status). In the detailed Theory of Change outlined below, we refer to sites* more generally given many of the processes and tools outlined in the toolkit will be relevant to the conservation and management of sites which do not meet the criteria to be a considered a Key Biodiversity Area. But we note again that ultimately assessing a site against KBA criteria has added benefit given the links that KBAs have to key policy mechanisms. "],["project-management-considerations.html", "6 Project management considerations", " 6 Project management considerations The Theory of Change, in the “Getting a site conserved” chapter, outlines the suggested steps required to ultimately achieve a conservation outcome through a site-based conservation approach. These steps are a guide only and can be a useful project planning tool. Each project will differ in the overall number of people required and total steps that need to be achieved in order to deliver a conservation outcome for a site, or network of sites important for biodiversity. In the context of Key Biodiversity Areas in general, a recent paper Plumptre et al. (2024) recommended that for a comprehensive national assessment across all taxonomic groups (i.e. to only identify or reassess KBAs in a country): “Experience to date suggests that a budget of c.$300,000–500,000 US dollars is needed per country (in the Global South) to engage stakeholders including governments and biodiversity experts to compile existing data, identify and propose KBAs, and that this process can take 2–3 years.” While $300,000–500,000 US dollars and a timeline of 2 - 3 years can help achieve a comprehensive national assessment across all taxonomic groups, proposing a KBA can also be done by a single individual. Where a single individual already has the data, identifying or reassessing a site can be done in a single day. Key message: there is a massive spectrum of work that can, or will be required to be done, when identifying or proposing an important site. Project managers must consider this when executing projects. We strongly advise contacting a KBA regional focal point before beginning an assessment. They can help advise on current best practice opportunities. "],["before-you-begin-a-kba-project.html", "7 Before you begin a KBA project", " 7 Before you begin a KBA project Key message: Before you begin a project involving Key Biodiversity Areas (KBAs) have a conversation. Reach out to: KBA Regional Focal Points (people who should be able to tell you what major KBA projects are happening in what regions) The KBA Secretariat (people who should be able to direct you to the relevant people for support) Marine Megafauna Conservation Toolkit authors (people who should be able to help you with some of the specifics related to important sites for marine megafauna) Contact details for relevant groups / people should be available via the relevant websites. BirdLife Partners: should also contact relevant Important Bird and Biodiversity Area (IBA) leads, as these people can also help support KBA (and IBA) related work. "],["sites-marine-sites-concepts.html", "8 Sites: Marine sites concepts 8.1 Key Biodiversity Areas 8.2 Important Bird and Biodiversity Areas 8.3 Other sites 8.4 Important sites in the marine environment", " 8 Sites: Marine sites concepts The concept of what constitutes a specific site for supporting marine megafauna conservation is still the subject of debate. Sites may be small and managed by a single local authority, or sites may be large and managed by a collective group of decision-makers from multiple countries. Through example of protected areas represented on the World Database of Protected Areas: One of the smallest marine protected areas is the Eacho Bay Marine Park in Canada. It is only 0.01km2, and it is managed at a sub-national level. Whereas one of the largest marine protected areas is the North Atlantic Current and Evlanov Basin (NACES) MPA. It is 595156 km2, and it is managed through a collaborative governance approach. 8.1 Key Biodiversity Areas In the toolkit, we recognise a spectrum of sites. However, we advocate for, and support the identification of, Key Biodiversity Areas (KBAs). This is because by formally identifying a site as a KBA, the site will have added ability to bring about a change by a decision-maker that supports species maintaining or achieving a favourable conservation status. 8.2 Important Bird and Biodiversity Areas For bird species specifically, we recognise the historic value of Important Bird and Biodiversity Areas (IBAs). IBAs have formed the cornerstone of conservation efforts for BirdLife International and its partners. IBAs have also been a leading tool for seabird conservation. 8.3 Other sites Sites that do not meet KBA or IBA criteria, may still be particularly relevant for key biodiversity at unique sites at local, national and regional scales. The tools outlined in this Toolkit can help users identify and justify the validity of a site when trying to get decision-makers to act. 8.4 Important sites in the marine environment Multiple different frameworks exist aimed to identify and describe sites within the marine environment that are of ecological significance, differing in their focus, scope, and processes of identification. Example frameworks include: Key Biodiversity Areas (KBAs) Important Bird and Biodiversity Areas (IBAs) Ecological and Biologically Signification Areas (EBSAs) Important Shark and Ray Areas (ISRAs) Important Marine Mammal Areas (IMMAs) Important Marine Turtle Areas (IMTAs) Marine Key Ecological Features (MKEFs) While these frameworks do not specifically dictate a protected status for the specific site, they guide policy makers in identifying which sites are of most importance for preserving biodiversity according to a set of pre-defined criteria. The Toolkit focuses on KBAs as a key policy mechanism given they are an overarching framework which facilitates recognition of sites contributing significantly to the global persistence of biodiversity across all taxonomic groups. Furthermore, KBAs are formally recognised in a suite of international agreements that promote, support and enable the conservation of biodiversity. See Plumptre et al. (2024) (Plumptre et al. (2024)) for an overview about KBAs and a comparison of the conservation objectives and relevance to different systems of the main approaches to identification of areas of particular importance for biodiversity. "],["sites-kbas-ibas.html", "9 Sites: KBAs &amp; IBAs 9.1 Key Biodiversity Areas (KBAs) 9.2 Important Bird and Biodiversity Areas (IBAs)", " 9 Sites: KBAs &amp; IBAs REMINDER: While the Toolkit helps users identify the steps required to ultimately get a site formally conserved, a core component of the toolkit is the technical component. The technical component helps users analyse complex data and ultimately develop the information required to propose a site to the relevant authority. In the toolkit, we recognise a spectrum of sites. However, we advocate for, and support the identification of, Key Biodiversity Areas (KBAs); sites contributing significantly to the global persistence of biodiversity. KBAs are a unified global currency helping to identify the most important sites for nature. The KBA initiative builds off four decades of BirdLife’s experience in identifying and promoting the conservation of Important Bird and Biodiversity Areas (IBAs). IBAs are BirdLife’s contribution to KBAs. BirdLife is a KBA Partner and provides strong support to the KBA Programme. Both KBAs and IBAs are underpinned by high scientific standards and are based on objective data and criteria; they can therefore help inform decision-making at all levels. Key message for users of the toolkit: KBAs are the leading mechanism through which the Toolkit promotes and supports identification of important sites. However, the tools outlined in this Toolkit will also help users identify sites which can be assessed against IBA criteria (likely other criteria too). Where circumstance dictates, users should contact the relevant BirdLife authority to discuss the identification and monitoring of IBAs. 9.1 Key Biodiversity Areas (KBAs) Key Biodiversity Areas (KBAs) are sites contributing significantly to the global persistence of biodiversity. Sites can be significant for a single species, assemblages of species, ecosystems, sites of outstanding ecological integrity, or sites with high irreplaceability. KBAs are identified based on 11 quantitative criteria. Use of global quantitative criteria enables comparisons to be made between sites anywhere in the world. For a site to qualify as a KBA, it must hold a significant proportion of the biodiversity element, where the threshold required is also dependent on the IUCN Red List Conservation Status of a species or ecosystem. The KBA website provides details about: KBA Criteria: Global Standard for the Identification of Key Biodiversity Areas. KBA Guidelines: They explain the key terms, how to measure the criteria using different assessment parameters and how to delineate KBAs KBA Proposal and update process: How to actually propose or reassess a site as a KBA Additional resources on the KBA website include: Links to online training courses Guides about monitoring KBAs Guides about appealing a specific KBA 9.1.1 KBA site definition As per the KBA Standards, a site is defined as: KBA Site: A geographical area on land and/or in water with defined ecological, physical, administrative or management boundaries that is actually or potentially manageable as a single unit (e.g. a protected area or other managed conservation unit). For this reason, large-scale biogeographic regions such as ecoregions, Endemic Bird Areas and Biodiversity Hotspots, and land-/seascapes containing multiple management units, are not considered to be sites. In the context of KBAs, “site” and “area” are used interchangeably. 9.2 Important Bird and Biodiversity Areas (IBAs) Important Bird and Biodiversity Areas (IBAs) are BirdLife’s contribution to KBAs. IBAs are sites of conservation importance for bird populations. Two key papers summarise IBAs with regards to: IBA impact on conservation policy, advocacy and action: Waliczky et al. (2019) IBA development and characteristics of sites: Donald et al. (2019) 9.2.1 IBA site definition From (Donald et al. (2019)): As far as possible, IBA boundaries are identified such that: the area inside the boundary is different in character, habitat or ornithological importance from surrounding areas; the IBA exists as a discrete manageable unit, such as a protected area, with or without buffer zones, and the site is an area that provides the requirements of the trigger species (i.e. those for which the site qualifies) while present, alone or in combination with networks of other sites. In many cases, delineation is straightforward, often dictated by obvious habitat boundaries or guided by existing protected area boundaries, land ownership or management boundaries. There is no set maximum or minimum size for an IBA, although the condition that the site forms a single manageable unit places a constraint on the maximum sensible area. "],["sites-toolkit-context.html", "10 Sites: Toolkit context", " 10 Sites: Toolkit context The Toolkit currently supports users to identify three types of sites, based on examples from seabird data. We advocate for the identification of each site type separately as this process can ensure unique sites which may be subject to different management regimes can be considered. The three site types are: Colony sites (i.e. breeding locations, or unique locations where you can typically count animals in a defined area) Seaward extensions (i.e. sites that are adjacent to land and may be derived from inferred distribution of animals) Pelagic sites (i.e. truly marine sites typically identified from animal tracking data) We acknowledge other site types by BirdLife International have been considered for seabirds in the past (BirdLife International (2010)). Future versions of the Toolkit will seek to provide further guidance about methods that can be used to identify these different site types (i.e. Non-breeding coastal congregations, migration bottlenecks) Further details on each of the three site types for which guidance is offered in the toolkit is outlined below: In the context of the Toolkit, these sites can support conservation of species in two key ways: Sites that meet global criteria (KBA criteria, or IBA criteria in special circumstances for birds) Sites that do not meet global criteria, but still fulfill the concept of a site suited to management measures. Where the concept of a site that is suited to management measures is one which is: regularly or predictably used by a significant number of individuals deemed to be sufficiently aggregating. The primary data needed to identify such sites are: data used to define a boundary which can be considered as a site (e.g. tracking data, or ability to identify a known area used by animals), and knowledge of how the species uses the site. The data should also enable users to create a spatial polygon file (typically a shapefile) an abundance estimate for the site (the Toolkit focuses on mature individuals as the key unit for determining abundance) the conservation status of the species (typically the global IUCN Red List Status) a global abundance estimate With that data, one can determine whether or not a site meets relevant criteria. In the toolkit, while we recognise a spectrum of sites, we advocate for, and support the identification of, Key Biodiversity Areas (KBAs). This is because by formally identifying a site as a KBA, the site will have added ability to bring about a change by a decision-maker that supports species maintaining or achieving a favourable conservation status. Below, summarises some of the key concepts with regards to identifying a site for the conservation of marine megafuana, particularly through a KBA approach. "],["sites-method-considerations-for-project-managers.html", "11 Sites: Method considerations for project managers 11.1 Colony site (abundance data) 11.2 Seaward extension site (distribution estimates) 11.3 Pelagic site (tracking data)", " 11 Sites: Method considerations for project managers While current examples in the toolkit are biased to seabirds, the methods used in the toolkit have applicability to other marine megafauna, and even terrestrial taxa which are studied with animal tracking devices. The figure below highlights some of the key taxa for which each method in the toolkit may be applicable for, or have been applied to. REMEMBER: A primary goal of this toolkit is to help users derive the best possible information to justify for, and advocate why, a site is important for marine megafauna and their associated biodiversity. These data, where applicable, can be used as the best possible basis through which to propose a Key Biodiversity Area (i.e. the toolkit aims to help you derive the right data needed for proposing a KBA) Here we summarise some key considerations for project managers with regards to the methods outlined in the toolkit. 11.1 Colony site (abundance data) To determine whether a particular site meets KBA criteria, you need abundance data. The toolkit focuses on estimates of mature individuals. For the purpose of KBAs, other estimate of abundance are also appropriate. However, the toolkit does not currently detail methods which explore these other estimates of abundance (particularly relevant for globally threatened species). Key message: determining the number of animals using a site can be extremely challenging. It may require challenging field work or use of advanced remote sensing. Data collected from either of these processes may also then require advanced modelling to derive a final estimate of abundance. Project managers should assess what data is already available and, ideally, well curated. Where data is not available nor well curated, project managers must allow sufficient time for data collection and processing. 11.2 Seaward extension site (distribution estimates) In some instances (likely many), estimates of an animals distribution will not exist for a particular location (or possibly any locations). In these instances, especially when relevant data layers are needed by decision makers, inferring the distribution of animals will be useful. Key message: inferring the distribution of animals can be challenging. Analysts may be required to spend significant amounts of time reviewing literature so the best possible parameters can be used when inferring distribution. Analysts may also be required to develop advanced models in order to infer distribution of animals in one location based on known estimates of distribution from another location. Note: Any KBA proposed through an estimate of distribution (i.e. some form of modelling exercise), should also be validated with independent occurrence data (See the KBA guidelines for further details) 11.3 Pelagic site (tracking data) The goal of the tracking analysis outlined in the toolkit is to identify a particular site that is used by a threshold number of individuals from a particular source population. We consider an identified site to be representative of the source population when a sufficient number of animals largely use the same place. While the tracking analysis outlined in the toolkit (Beal, Oppel, et al. (2021)) was originally designed for seabirds, the methods have now been applied to pinnipeds, turtles, cetaceans, storks and vultures. Further testing of this method will reveal just how broadly applicable the outlined tool will be for informing conservation outcomes. Key message: analysis of animal tracking data is non-trivial. There are many steps to be considered to go from raw data collected, to final outputs for decision-makers. The more data an analyst has, the more likelihood there will be multiple challenges the analyst must overcome. Project managers must try to account for the time required to translate raw data into final outputs for decision-makers. "],["sites-conservation-of-sites-summary.html", "12 Sites: Conservation of sites (summary) 12.1 What threats exist? 12.2 What threats impact seabirds? 12.3 What known solutions to threats exist? 12.4 What scale should threat mitigation be considered over? 12.5 Best available science", " 12 Sites: Conservation of sites (summary) Once you have done the work of identifying a site which may require action to conserve biodiversity at the site (Technical), then you have to determine what the likely actions are that can conserve the biodiversity (Conservation). 12.1 What threats exist? Typically, one must first understand what a potential threat to the site might be. The Toolkit advocates for recognising threats in a globally standardised way. The IUCN Red List Threat Classification Scheme, https://www.iucnredlist.org/resources/threat-classification-scheme, offers a way of recognising threats in a globally standardised way. 12.2 What threats impact seabirds? For seabirds, two key papers provide the starting point for users to consider what human activities may likely impact a species: Croxall et al. (2012); Dias et al. (2019) Users should use these papers as a guide to understand the threats recognised to impact species at a global level, and then consider what threats might be impacting species at a potential local, national or regional scale. 12.3 What known solutions to threats exist? When identifying whether a threat may impact species at the site, users should also look beyond their specific species and explore whether a potential human activity has been documented to impact related species. Once potential threats to species at the site have been identified, then users should understand what the potential solutions to the threats are. The Cambridge University Conservation Evidence group summarises the documented evidence for the effectiveness of conservation actions. Here, users can find evidence of actions known to reduce the impacts of threats to species. This evidence will be key to building the case for management measures that are necessary to conserve biodiversity at a site. 12.4 What scale should threat mitigation be considered over? Different threats occur at different scales. Therefore, conservation actions for species will need to occur at different scales depending on the scale of the threat and the species dispersal ability. Two key papers document this consideration of scale with respect to conservation solutions for seabirds and broader biodiversity: Seabirds: Oppel et al. (2018) Broader biodiversity: Boyd et al. (2008) 12.5 Best available science For many species at sites where human impacts are likely to occur, it’s likely species will be impacted by multiple threats. Disentangling which threat impacts a species most, and, therefore, which course of action will be most appropriate to conserve the species, may be challenging. Where there is uncertainty about the impact of a potential threat to species, this Toolkit advocates for consideration of the “precautionary principle” and recognises the text of certain agreements which call for decisions to be made on the “best available science”. Ultimately, determining a course of action to reduce a threat to species within a site will require understanding a number of factors. The Cambridge University Conservation Evidence group showcases known solutions, but the “best available science” should also be used to inform solutions to conserve biodiversity when necessary. "],["sites-policy-advocacy-tools-summary.html", "13 Sites: Policy &amp; Advocacy tools (summary)", " 13 Sites: Policy &amp; Advocacy tools (summary) Once you have done the work of identifying a site which requires action to conserve biodiversity at the site (Technical), and once you have determined what the likely actions required in the area of the site are (Conservation), then critical to the success of getting conservation actions implemented is getting decision-makers to act (Policy &amp; Advocacy). Decision-makers typically act for one of two reasons, or a combination of both. In the policy and advocacy section of the toolkit we describe these in further detail. Decision makers are: typically pulled into acting when there is an established legal or other policy related mechanism in place (Policy), or they are pushed into acting through advocacy efforts (Advocacy). Management measures that enable a site to be protected so species can achieve a favourable conservation status, do not explicitly need to be formal protected areas. The concept of a site is the critical concept in the Toolkit. In the toolkit, we recognise a spectrum of sites. However, we advocate for, and support the identification of, Key Biodiversity Areas (KBAs). This is because by formally identifying a site as a KBA, the site will have added ability to bring about a change by a decision-maker that supports species maintaining or achieving a favourable conservation status. Key message for conservationists: by formally identifying a site as a KBA, there are formal mechanisms that can help get the site protected through an appropriate management measure. Beyond KBAs, the “best available science” describing key biodiversity at a unique site should also be used to support implementation of management measures at sites. This may be particularly relevant for key biodiversity at unique sites at local, national and regional scales. Key message for conservationists: while the concept of a site for a KBA has a definition, the concept of what constitutes a specific site for supporting marine megafauna conservation is still the subject of debate. Toolkit users are encouraged to explore the tools in the Toolkit that can help identify a site, but should also consider the scale of the particular site and how it could be used to inform delivery of a conservation outcome for species. (e.g. the track2KBA tool can be applied to GLS animal tracking data. However, the resultant site may be extremely large compared to typical areas managed within the context of a single country; even larger than a countries EEZ. Nevertheless, this type of site could still inform where bycatch mitigation measures should be enforced in tuna RFMOs which operate at the ocean basin scale.) "],["data-needs-identifying-a-site.html", "14 Data needs: Identifying a site", " 14 Data needs: Identifying a site As per the chapter “Sites: Toolkit context” The typical data needed to identify site types outlined in the toolkit are: data used to define a boundary which can be considered as a site (e.g. tracking data, or ability to identify a known area used by animals), and knowledge of how the species uses the site. The data should also enable users to create a spatial polygon file (typically a shapefile) an abundance estimate for the site (the Toolkit focuses on mature individuals as the key unit for determining abundance) the conservation status of the species (typically the global IUCN Red List Status) a global abundance estimate With those data, one can determine whether or not a site meets relevant criteria. In the toolkit, while we recognise a spectrum of sites, we advocate for, and support the identification of, Key Biodiversity Areas (KBAs). This is because by formally identifying a site as a KBA, the site will have added ability to bring about a change by a decision-maker that supports species maintaining or achieving a favourable conservation status. Below, summarises some of the key concepts with regards to identifying a site for the conservation of marine megafuana, particularly through a KBA approach. "],["data-needs-datagroup-unit-of-analysis.html", "15 Data needs: dataGroup (unit of analysis) 15.1 Example dataGroup for analysing tracking data to identify an important site", " 15 Data needs: dataGroup (unit of analysis) The movement patterns and spatial distributions of highly mobile species often change across seasons. Protocols in the toolkit are designed to typically identify important sites for a source population during a specific seasonal life-cycle stage. It is important that input data represents periods in which the animals in the source population are moving or distributed in a similar manner to one another. Further details regarding the dataGroup are also explained under the relevant analytical sections. 15.1 Example dataGroup for analysing tracking data to identify an important site First, we want to consider data that represents the unique period of movements from a source population; this is what we refer to as the dataGroup. To consider this explanation of the dataGroup a little further, let’s take the example of these black-browed albatrosses breeding on the archipelago of the Falklands Islands in the South West Atlantic Ocean. We know these birds breed at multiple locations across the archipelago. We also know that these birds have different movements patterns at different times of year. Here we can see some simple illustrations of where birds move depending on whether they are Chick rearing (CR) Incubating eggs (I) Or dispersing in the non-breeding season (NB) To define a dataGroup in this instance, the focus of the analysis happens at the level of: A specific species From a specific breeding location During a specific life-cycle stage of the species, or unique movement period, such as when the birds are incubating eggs. So, for analysing tracking data with the track2kba R package (See tracking section of toolkit), the animal tracking data from this population is the data that would be considered initially for use with track2kba in order to identify a site for assessment. "],["breeding-location-abundance-data-single-species-single-site.html", "16 Breeding location (abundance data): single species, single site", " 16 Breeding location (abundance data): single species, single site Chapter under final construction This chapter will help you analyse spatial data (a polygon) with an associated abundance estimate to identify an important site. "],["breeding-location-abundance-data-single-species-multiple-sites.html", "17 Breeding location (abundance data): single species, multiple sites", " 17 Breeding location (abundance data): single species, multiple sites Chapter under final construction This chapter will help you analyse spatial data (multiple polygons with associated abundance estimates) to identify a network of important sites. "],["breeding-location-abundance-data-multi-species-multiple-sites.html", "18 Breeding location (abundance data): multi species, multiple sites", " 18 Breeding location (abundance data): multi species, multiple sites Chapter under final construction This chapter will help you analyse spatial data (multiple overlapping polygons with associated abundance estimates from different species) to identify a network of important sites. "],["seaward-extension-introduction.html", "19 Seaward Extension: Introduction", " 19 Seaward Extension: Introduction This document was last updated on 2024-02-23 This chapter provides guidance and code for delineating a seaward extension boundary from a colony of breeding seabirds. SEAWARD EXTENSION DEFINITION: These are marine areas immediately surrounding seabird breeding colonies. The areas are typically used for ecologically relevant behaviours such as rafting, preening, bathing, foraging or transiting between foraging trips, depending on a species. CAUTION: Defining seaward extensions around seabird breeding colonies should consider the ecology of the species. In other words: it is generally unsuitable to try and delineate important sites using this method that are artificially large. For example, it would likely be unsuitable to use this method to derive a foraging area for albatross; tracking data would be better suited for defining a foraging area for albatross. See further examples in the Marine Toolkit. This tutorial uses the example data for Adelie Penguins. For information on the original study, see Handley et al. 2021 Marine Important Bird and Biodiversity Areas for Penguins in Antarctica, Targets for Conservation Action. Frontiers in Marine Science 7: 602972. https://doi.org/10.3389/fmars.2020.602972 While this tutorial is designed to allow minimal input from the user, users should understand the consequence of choices to input parameters while using the functions provided. What does this tutorial cover: Creating a suitable background raster (grid file) for use in the seaward extension method Producing a raster density grid and a polygon site boundary output for a seabird colony Producing raster density grids and polygon site boundary outputs for multiple seabird colonies and combining them to produce a raster stack as the final output. Inputs to this tutorial: Polygon (shapefile) of land Seabird colony location(s) (latitude and longitude) Radius around the colony (distance in km) Colony size(s) (number of breeding pairs) [Link to input data csv template] Guidance for inputs: Polygon of land (shapefile) The resolution of this file will impact the final results, so it needs to be sufficiently fine scale compared to the scale of distance used in the method. Shapefiles can be downloaded from https://gadm.org/data.html [Also r natural earth?] 2. Seabird colony location (latitude and longitude) - The accuracy of the location will impact the results, so it is recommended to check the location before running the method. - For island colonies, if the colony covers the entire island, the centre of the island is suitable. If not, it is better to use a location on the correct side of the island. 3. Radius around the colony (distance in km) - [Possible distances: maxium, mean maximum, mean] - [Could be from tracking (e.g. if sample size is too small to use track2KBA)] - [Could be informed by at sea surveys?] 4. Colony size (number of breeding pairs) - Could also use Apparently Occupied Sites/Nests - If the count is a range, could use mean. [Could also run for upper and lower estimate to include uncertainty] Output(s) from this tutorial, can be used to: assess data against relevant criteria, such as: IBA criteria: http://datazone.birdlife.org/site/ibacriteria KBA criteria: https://www.keybiodiversityareas.org/working-with-kbas/proposing-updating/criteria or, for identification of sites from animal tracking data to be used in alternate spatial planning exercises. References Original workflow adapted from Critchley et al. 2018: https://doi.org/10.1016/j.biocon.2018.06.007 with adaptations for Handley et al. 2021: https://doi.org/10.3389/fmars.2020.602972 "],["seaward-extension-single-colony.html", "20 Seaward Extension: single colony 20.1 Summary 20.2 Load required R packages: 20.3 Supply input data 20.4 Format colony location as spatial objects 20.5 Create a background raster 20.6 Calculate distance by sea from the colony per cell 20.7 Calculate estimate number of birds from the colony using each cell 20.8 Save raster output 20.9 Calculate IBA raster 20.10 Calculate IBA polygon 20.11 Plot and save the final IBA polygon 20.12 Record the metadata", " 20 Seaward Extension: single colony This analysis was performed in R version 4.3.2 (2023-10-31 ucrt) This document was last updated on 2024-02-23 20.1 Summary What does this section cover: Create a seaward extension raster and polygon for a colony of breeding seabirds Input data: Seabird breeding colony location (latitude and longitude) Abundance estimate for seabird breeding colony Global abundance estimate for seabird species Estimate of appropriate distance traveled from the colony for behaviour of interest (foraging, or behaviours near to the colony such as rafting, bathing, preening, collecting nesting material). This is usually an estimate from tracking data for the species collected at different site. [add guidance on how to find this information] Outputs: A polygon of the site that meets IBA criteria Metadata needed for the IBA form 20.2 Load required R packages: If the packages fail to load, you will need to install them. If the install script fails, try downloading a new version of R here: https://cran.rstudio.com/index.html If that fails try installing Rtools. #If needed remove the &quot;#&quot; and run the code below to install the packages. This only needs to be done once. #install.packages(&quot;sf&quot;) #install.packages(&quot;terra&quot;) #install.packages(&quot;rnaturalearth&quot;) #install.packages(&quot;smoothr&quot;) #install.packages(&quot;tidyverse&quot;) #install.packages(&quot;stringr&quot;) #Load the libraries. This needs to done every time R is restarted. library(sf) #for handling spatial points and polygons library(terra) #for handling rasters library(smoothr)#for filling holes in polygons library(rnaturalearth)# rnaturalearth package for geographic basemaps library(tidyverse) #for plots and data wrangling library(stringr) #for text edits #If it shows, the following warning can be ignored: #The legacy packages maptools, rgdal, and rgeos, underpinning this package #will retire shortly. Please refer to R-spatial evolution reports on #https://r-spatial.org/r/2023/05/15/evolution4.html for details. #This package is now running under evolution status 0 #Support for Spatial objects (`sp`) will be deprecated in {rnaturalearth} and will be removed in a future release of the package. Please use `sf` objects with #{rnaturalearth}. For example: `ne_download(returnclass = &#39;sf&#39;)` 20.3 Supply input data This script imports a polygon of the land directly into R using the rnaturaleath package. This resolution is generally suitable, but if you want to use a different basemap (e.g. high resolution and/or a particular projection), go to appendix # and this script will give an example. #go to the iucn red list page for the species. #Our example is the Adelie Penguin https://www.iucnredlist.org/species/22697758/157660553 common_name &lt;- &quot;Adelie Penguin&quot; scientific_name &lt;- &quot;Pygoscelis adeliae&quot; site_name &lt;- &quot;Spindrift Rocks Seaward Extension&quot; #Global population size (this is not the real value, just used for the example!) min_global_estimate &lt;- NA max_global_estimate &lt;- NA best_global_estimate &lt;- 150000 #this can be the mean of min &amp; max if another best estimate is not available using the code below: #best_global_estimate &lt;- mean(c(min_global_estimate,max_global_estimate)) #where can partner&#39;s get the global estimate # - we can get data through BirdLife if not available on the red list #make sure it is mature individuals - not breeding pairs! #first place to look is red list #Red List category to know for IBA &amp; KBA criteria red_list_category &lt;- &quot;LC&quot; #LC = Least Concern, NT = Near Threatened, VU = Vulnerable, #EN = Endangered, CR = Critically Endangered #DD = Deficient (only uses number based thresholds, not %) #Red list criteria (not applicable for LC) red_list_criteria &lt;- NA #if they are globally threatened, only need 20 mature individuals #For KBAs, also can assess more criteria #red_list_critera &lt;- c(&quot;A2ace&quot;,&quot;3bce&quot;,&quot;4ace&quot;) #[add some images for how to get this from iucnredlist.org] ## Colony location latitude &lt;- -60.683 longitude &lt;- -45.644 #Colony size colony_size &lt;- 3046 #[add guidance, bp?] ## Maximum colony radius distance (m) max_colony_radius &lt;- 149000 #add in red list #if they are globally threatened, only need 20 mature individuals ## Specified resolution of grid cell (m) grid_res &lt;- 1000 #[For Marine Toolkit, need to provide guidance on choice of resolution. 5km aligned with same scale as the #Critchley et al. 2018 paper, changed to 1km as failed during the example because the birds could cross diagonally through land] ## Land polygon #Include the name of the country you wish to import a map for #To include multiple countries use for example &quot;country = c(&quot;Antarctica&quot;,&quot;Chile&quot;)&quot; land &lt;- ne_countries(scale = &quot;large&quot;, returnclass = &quot;sf&quot;, country = &quot;Antarctica&quot;) %&gt;% st_make_valid() 20.4 Format colony location as spatial objects If the colony location is not projected into an equal areas crs with metres (m) as the unit, this will need to be done before calculating the distance. [add link to page on projections] #The script requires the spatial data to be projected into an equal areas projection with meters (m) as a unit #To do this, we create a custom projection centered around the data basemap &lt;- st_transform(land, crs = paste0(&quot;+proj=laea +x_0=0 +y_0=0 +lon_0=&quot;,longitude,&quot; +lat_0=&quot;,latitude)) dev.off() ## null device ## 1 plot(basemap[1], main = &quot;Basemap&quot;) #format colony location as dataframe df &lt;- data.frame(cbind(latitude,longitude,colony_size)) #Set coordinate reference system (CRS) for colony locations (example for lat/lon, WGS84) col_locs &lt;- st_as_sf(df,coords = c(&quot;longitude&quot;,&quot;latitude&quot;), crs = 4326) #Make sure colony data is projected to the basemap crs col_locs_proj &lt;- st_transform(col_locs, crs = st_crs(basemap)) 20.5 Create a background raster Create a raster (grid) that can be used for delineation of a seaward extension boundary from a colony of breeding seabirds. This raster will: Have a specified cell size (resolution). Cover the location of the colony or colonies with a buffer greater than the maximum radius distance. Specify cells at either marine or terrestrial (ice can be classified as terrestrial). #First set a buffer (m) around the colony/colonies + the resolution of the grid to make sure the grid is large enough. raster_buffer &lt;- max_colony_radius + grid_res #Find the extent of the colony locations bounds &lt;- st_bbox(col_locs_proj) #Create the blank raster grid with the crs of the land polygon ras &lt;- terra::rast(xmin = bounds[[1]] - raster_buffer, ymin = bounds[[2]] - raster_buffer, xmax = bounds[[3]] + raster_buffer, ymax = bounds[[4]] + raster_buffer, resolution = grid_res, crs = st_crs(basemap)$wkt) #Convert the basemap, currently in polygon format, to a raster and then overlay with the blank raster basemap_vector &lt;- vect(basemap) mask &lt;- terra::rasterize(basemap_vector, ras) mask[is.na(mask)] &lt;- 2 mask[mask == 1] &lt;- NA mask[mask == 2] &lt;- 1 ras &lt;- mask dev.off() ## null device ## 1 plot(ras) 20.6 Calculate distance by sea from the colony per cell Calculate distances from the colony to each cell travelling only through marine cells, because the birds are expected to travel around land masses rather than over them to reach marine destinations. For each raster, the script will provide a note to say whether the calculation is successful and advice on what to do if it is not. [add info about the distance calc successful messages] ## Extract the cell location of the colony pp &lt;- terra::extract(ras,vect(col_locs_proj), cells=TRUE) ## convert that cell to a value of 2 ras[pp$cell] &lt;- 2 ## You now have a raster with colony cell = 2, land cells = NA and sea cells = 1 ## Calculate distance from colony via sea, cell values of NA are avoided while determining distance DistSea &lt;- terra::gridDist(x=ras, # x specifies which raster to use target=2) # target specifies which cell to determine distance from #Add the minimum grid resolution DistSea &lt;- DistSea + grid_res if(terra::minmax(DistSea)[2] == 0) print(&quot;WARNING: Check for NAs in final output. Your origin(colony) may be to far in land. Therefore, your origin is completely buffered by omit cells (land cells), and no distance calculation for cells at sea can be performed&quot;) else print( &quot;Distance calculation successful&quot;) ## [1] &quot;Distance calculation successful&quot; dev.off() ## null device ## 1 plot(DistSea) 20.7 Calculate estimate number of birds from the colony using each cell Set any cells that are further than the provided maximum distance from the colony to NA Normalise to 0 and 1 probability of occurrence instead of distance using a log decay function Multiply by colony size ## Set any cell further than maximum distance to NA DistSea[DistSea &gt; max_colony_radius] &lt;- NA ## Normalise to 0 and 1 probability of occurrence ProbOccurence &lt;- -1*(DistSea/max_colony_radius)+1 #Apply logarithmic decay function as done in Critchley et al. 2020. #https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.04653 #Skipping this step will result in a linear decay. Other decay functions could be input here if justified. ProbOccurenceLog &lt;- ProbOccurence*(1/log(DistSea)) #Rescale to between 0 and 1 ProbOccurenceLog &lt;- ProbOccurenceLog/ max(values(ProbOccurenceLog), na.rm =T) #Multiply by population size PopRaster &lt;- ProbOccurenceLog*colony_size dev.off() ## null device ## 1 plot(PopRaster) 20.8 Save raster output #create a folder to contain the outputs outputs &lt;- &quot;/seaward_extension_outputs&quot; dir.create(paste0(wd,outputs)) #save #terra::writeRaster(PopRaster,paste0(wd,outputs,&quot;/seaward-ext-single-col-dist-ne.tif&quot;), overwrite=T) 20.9 Calculate IBA raster If the species is not Threatened (Red List category of Least Concern, Near Threatened or Vulnerable), filter out cells containing less than 1% of the global population if(red_list_category %in% c(&quot;LC&quot;,&quot;NT&quot;,&quot;VU&quot;)){ #Convert to with more (1) or less (0) than 1% of global population IBA_raster &lt;- PopRaster IBA_raster[IBA_raster &lt; best_global_estimate/100] &lt;- 0 IBA_raster[IBA_raster &gt;= best_global_estimate/100] &lt;- 1 #plot to check plot(IBA_raster) #set to NA cells IBA_raster[IBA_raster == 0] &lt;- NA } #need to save min and max value for IBA forms 20.10 Calculate IBA polygon Convert to polygon format Simplify the polygon to a more usable shape Fill in small holes between the land and simplified polygon Cut out the area covered by land Plot the output Also, compare to the foraging radius approach. #convert raster to a polygon format IBA_poly_ras &lt;- IBA_raster %&gt;% terra::as.polygons() %&gt;% sf::st_as_sf() #simplify the polygon to a more usable shape IBA_poly &lt;- IBA_poly_ras %&gt;% sf::st_simplify(dTolerance = res(IBA_raster)[1]*2) #get local part of basemap max_dist_buffer &lt;- st_buffer(col_locs_proj, dist = max_colony_radius) land &lt;- basemap %&gt;% st_crop(st_bbox(max_dist_buffer)) %&gt;% st_union() #fill in holes in the polygon, and holes between the coastline and the polygon, #then trim out the areas covered by land IBA_poly_trim &lt;- smoothr::fill_holes(IBA_poly, threshold = st_area(IBA_poly)) %&gt;% st_union(.,land) %&gt;% smoothr::fill_holes(threshold = st_area(IBA_poly)) %&gt;% st_difference(land) #plot the result ggplot(IBA_poly_trim)+ geom_sf(data = IBA_poly_ras, fill = &quot;lightblue&quot;, color = NA)+ geom_sf(data = land, fill = &quot;grey&quot;, colour = NA)+ geom_sf(fill = NA, color = &quot;red&quot;) + ggtitle(&quot;IBA polygon (red) and IBA raster (blue)&quot;) #plot the final polygon with foraging radius approach ggplot(max_dist_buffer)+ geom_sf(fill = NA, col = &quot;purple&quot;)+ geom_sf(data = IBA_poly_trim, fill = &quot;#fcba0350&quot;, col = &quot;red&quot;)+ geom_sf(data = land, fill = &quot;grey&quot;, colour = NA) + ggtitle(&quot;IBA polygon (red) and foraging radius (purple)&quot;) 20.11 Plot and save the final IBA polygon Plot the site and save the polygon as a shapefile (.shp) #plot the result ggplot(IBA_poly_trim)+ geom_sf(data = land, fill = &quot;grey&quot;, colour = NA)+ geom_sf(fill = &quot;#fcba0350&quot;, color = &quot;red&quot;) + ggtitle(site_name) #save the polygon #st_write(IBA_poly_trim, paste0(wd,outputs,&quot;/IBA_polygon&quot;,gsub(&quot; &quot;,&quot;_&quot;,site_name),&quot;.shp&quot;)) 20.12 Record the metadata This is needed for the submission of the site in the WBDB. Many variables have already been input or generated by the script so far. Some need to be calculated: - Area - Coordinates of the mid point - Min/best/max estimate of number of mature individuals in the site (not pairs) #Calculate the area of the site. area_hectare &lt;- round(as.numeric(st_area(IBA_poly_trim)/10000)) area_km2 &lt;- round(area_hectare/100) #Calculate the midpoint of the site and record in the different formats midpoint &lt;- st_centroid(IBA_poly_trim) %&gt;% st_transform(4326) lat_midpoint_decdeg &lt;- midpoint$geometry[[1]][2] lat_mid_deg &lt;- gsub(&quot;-&quot;,&quot;&quot;,gsub(&quot;\\\\..*&quot;,&quot;&quot;,lat_midpoint_decdeg)) lat_mid_decmin &lt;- as.numeric(paste0(&quot;0.&quot;,strsplit(as.character(lat_midpoint_decdeg), split = &quot;[.]&quot;)[[1]][2]))*60 lat_mid_north_or_south &lt;- ifelse(substr(lat_midpoint_decdeg,1,1) == &quot;-&quot;, &quot;South&quot;, &quot;North&quot;) lon_midpoint_decdeg &lt;- midpoint$geometry[[1]][1] lon_mid_deg &lt;- gsub(&quot;-&quot;,&quot;&quot;,gsub(&quot;\\\\..*&quot;,&quot;&quot;,lon_midpoint_decdeg)) lon_mid_decmin &lt;- as.numeric(paste0(&quot;0.&quot;,strsplit(as.character(lon_midpoint_decdeg), split = &quot;[.]&quot;)[[1]][2]))*60 lon_mid_east_or_west &lt;- ifelse(substr(lat_midpoint_decdeg,1,1) == &quot;-&quot;, &quot;West&quot;, &quot;East&quot;) #collate the metadata already input or generate in this script metadata &lt;- as.data.frame(cbind(site_name, area_km2, area_hectare, lat_midpoint_decdeg, lat_mid_deg, lat_mid_decmin, lat_mid_north_or_south, lon_midpoint_decdeg, lon_mid_deg, lon_mid_decmin, lon_mid_east_or_west, common_name, scientific_name, colony_size, best_global_estimate, red_list_category, red_list_criteria)) knitr::kable(metadata[,1:3], caption = &quot;IBA metadata: Site area&quot;) Table 20.1: IBA metadata: Site area site_name area_km2 area_hectare Spindrift Rocks Seaward Extension 2396 239569 knitr::kable(metadata[,4:11], caption = &quot;IBA metadata: Site midpoint location&quot;) Table 20.1: IBA metadata: Site midpoint location lat_midpoint_decdeg lat_mid_deg lat_mid_decmin lat_mid_north_or_south lon_midpoint_decdeg lon_mid_deg lon_mid_decmin lon_mid_east_or_west -60.7830933042941 60 46.985598257646 South -45.7017784558613 45 42.106707351678 West knitr::kable(metadata[,12:17], caption = &quot;IBA metadata: Species name &amp; conservation status&quot;) Table 20.1: IBA metadata: Species name &amp; conservation status common_name scientific_name colony_size best_global_estimate red_list_category red_list_criteria Adelie Penguin Pygoscelis adeliae 3046 150000 LC NA write.csv(metadata, paste0(wd,outputs,&quot;/IBA_metadata_&quot;,gsub(&quot; &quot;,&quot;_&quot;,site_name),&quot;.csv&quot;), row.names = F) "],["seaward-extension-multiple-colonies.html", "21 Seaward Extension: multiple colonies 21.1 Load required R packages: 21.2 Supply input data 21.3 Format colony locations as spatial objects 21.4 Create a background raster 21.5 Calculate distance by sea from the colony per cell 21.6 Inspect the output distance from colony rasters 21.7 For each colony, estimate number of birds that use each cell 21.8 Overlap the rasters and save raster outputs 21.9 Calculate IBA raster 21.10 Calculate IBA polygon 21.11 Split into separate IBA polygons and save metadata 21.12 Record the metadata", " 21 Seaward Extension: multiple colonies This analysis was performed in R version 4.3.2 (2023-10-31 ucrt) This document was last updated on 2024-02-23 What does this section cover: Create a seaward extension raster and polygon for multiple colonies of breeding seabirds Input data: - csv file containing: Seabird breeding colony location (latitude and longitude) Abundance estimate for seabird breeding colony Global abundance estimate for seabird species Estimate of appropriate distance travelled from the colony for behaviour of interest (foraging, or behaviours near to the colony such as rafting, bathing, preening, collecting nesting material). This is usually estimate from tracking data for the species collected at different site. [add guidance on how to find this information] IUCN Red List status Outputs: A polygon of each site that meets IBA criteria Metadata needed for the IBA form 21.1 Load required R packages: If the packages fail to load, you will need to install them. If the install script fails, try downloading a new version of R here: https://cran.rstudio.com/index.html If that fails try installing Rtools. #If needed remove the &quot;#&quot; and run the code below to install the packages. This only needs to be done once. #install.packages(&quot;sf&quot;) #install.packages(&quot;terra&quot;) #install.packages(&quot;rnaturalearth&quot;) #install.packages(&quot;smoothr&quot;) #install.packages(&quot;tidyverse&quot;) #install.packages(&quot;stringr&quot;) #Load the libraries. This needs to done every time R is restarted. library(sf) #for handling spatial points and polygons library(terra) #for handling rasters library(smoothr)#for filling holes in polygons library(rnaturalearth)# rnaturalearth package for geographic basemaps library(tidyverse) #for plots and data wrangling library(stringr) #for text edits #If it shows, the following warning can be ignored: #The legacy packages maptools, rgdal, and rgeos, underpinning this package #will retire shortly. Please refer to R-spatial evolution reports on #https://r-spatial.org/r/2023/05/15/evolution4.html for details. #This package is now running under evolution status 0 #Support for Spatial objects (`sp`) will be deprecated in {rnaturalearth} and will be removed in a future release of the package. Please use `sf` objects with #{rnaturalearth}. For example: `ne_download(returnclass = &#39;sf&#39;)` 21.2 Supply input data This script imports a polygon of the land directly into R using the rnaturaleath package. This resolution is generally suitable, but if you want to use a different basemap (e.g. high resolution and/or a particular projection), go to appendix # and this script will give an example. ## Colony data: location, abundance estimate df &lt;- read.csv(paste0(wd,&quot;/data-input-files-bookdown/AdeliePenguin_example_dataset_62.csv&quot;)) head(df) ## colony_name colony_size colony_size_min colony_size_max latitude ## 1 Acuna Island 3079 1880 3079 -60.7612 ## 2 Ambush Bay 17621 17621 17621 -63.1840 ## 3 Amphibolite Point 7660 5000 7660 -60.6840 ## 4 Ardley Island 260 260 1331 -62.2130 ## 5 Beagle Island 284535 96892 284535 -63.4139 ## 6 Cape Bowles 395 60 395 -61.3160 ## longitude ## 1 -44.6370 ## 2 -55.3930 ## 3 -45.3390 ## 4 -58.9330 ## 5 -54.6675 ## 6 -54.0910 #[add guidance, bp?] #Global population size (this is not the real value, just used for the example!) min_global_estimate &lt;- NA max_global_estimate &lt;- NA best_global_estimate &lt;- 10000000 #this can be the mean of min &amp; max if another best estimate is not available using the code below: #best_global_estimate &lt;- mean(c(min_global_estimate,max_global_estimate)) #where can partner&#39;s get the global estimate? # - we can get data through BirdLife if not available on the red list #make sure it is mature individuals - not breeding pairs! #first place to look is red list #Red List category to know for IBA &amp; KBA criteria red_list_category &lt;- &quot;LC&quot; #LC = Least Concern, NT = Near Threatened, VU = Vulnerable, #EN = Endangered, CR = Critically Endangered #DD = Deficient (only uses number based thresholds, not %) #if they are globally threatened, only need 20 mature individuals #For KBAs, also can assess more criteria #red_list_codes &lt;- c(&quot;A2ace&quot;,&quot;3bce&quot;,&quot;4ace&quot;) #[add some images for how to get this from iucnredlist.org] ## Maximum colony radius distance (m) max_colony_radius &lt;- 149000 ## Specified resolution of grid cell (m) grid_res &lt;- 1000 #[For Marine Toolkit, need to provide guidance on choice of resolution. 5km aligned with same scale as the #Critchley et al. 2018 paper, changed to 1km as failed during the example because the birds could cross diagonally through land] ## Land polygon #Include the name of the country you wish to import a map for #To include multiple countries use for example &quot;country = c(&quot;Antarctica&quot;,&quot;Chile&quot;)&quot; land &lt;- ne_countries(scale = &quot;large&quot;, returnclass = &quot;sf&quot;, country = &quot;Antarctica&quot;) %&gt;% st_make_valid() 21.3 Format colony locations as spatial objects If the colony locations are not projected into an equal areas crs with metres (m) as the unit, this will need to be done before calculating the distance. [add link to page on projections] #The script requires the spatial data to be projected into an equal areas projection with meters (m) as a unit #To do this, we create a custom projection centered around the data basemap &lt;- st_transform(land, crs = paste0(&quot;+proj=laea +x_0=0 +y_0=0 +lon_0=&quot;,mean(df$longitude), &quot; +lat_0=&quot;,mean(df$latitude))) dev.off() ## null device ## 1 plot(basemap[1], main = &quot;Basemap&quot;) #Set coordinate reference system (CRS) for colony locations (example for lat/lon, WGS84) col_locs &lt;- st_as_sf(df,coords = c(&quot;longitude&quot;,&quot;latitude&quot;), crs = 4326) #Make sure colony data is projected to the basemap crs col_locs_proj &lt;- st_transform(col_locs, crs = st_crs(basemap)) 21.4 Create a background raster Create a raster (grid) that can be used for delineation of a seaward extension boundary from a colony of breeding seabirds. This raster will: - Have a specified cell size (resolution). - Cover the location of the colony or colonies with a buffer greater than the maximum radius distance. - Specify cells at either marine or terrestrial (ice can be classified as terrestrial). #First set a buffer (m) around the colony/colonies + the resolution of the grid to make sure the grid is large enough. raster_buffer &lt;- max_colony_radius + grid_res #Find the extent of the colony locations bounds &lt;- st_bbox(col_locs_proj) #Create the blank raster grid with the crs of the land polygon ras &lt;- terra::rast(xmin = bounds[[1]] - raster_buffer, ymin = bounds[[2]] - raster_buffer, xmax = bounds[[3]] + raster_buffer, ymax = bounds[[4]] + raster_buffer, resolution = grid_res, crs = st_crs(basemap)$wkt) #Convert the basemap, currently in polygon format, to a raster and then overlay with the blank raster basemap_vector &lt;- vect(basemap) mask &lt;- terra::rasterize(basemap_vector, ras) mask[is.na(mask)] &lt;- 2 mask[mask == 1] &lt;- NA mask[mask == 2] &lt;- 1 ras &lt;- mask dev.off() ## null device ## 1 plot(ras) 21.5 Calculate distance by sea from the colony per cell Calculate distances from the colony to each cell travelling only through marine cells, because the birds are expect to travel around land masses rather than over them to reach marine destinations. For each raster, the script will provide a note to say whether the calculation is successful and advice on what to do if it is not. [add info about the distance calc successful messages] #Create a loop to apply the same method to each colony for(i in c(1:nrow(df))){ colony &lt;- subset(col_locs_proj,colony_name == df$colony_name[i]);colony ## Extract the cell location of the colony pp &lt;- terra::extract(ras,vect(colony), cells=TRUE) ## convert that cell to a value of 2 colony_ras &lt;- ras colony_ras[pp$cell] &lt;- 2 ## You now have a raster with colony cell = 2, land cells = NA and sea cells = 1 ## Calculate distance from colony via sea, cell values of NA are avoided while determining distance DistSea &lt;- terra::gridDist(x=colony_ras, # x specifies which raster to use target=2) # specifies which cell to determine distance from distance #Add the minimum grid resolution DistSea &lt;- DistSea + grid_res #Add colony name to raster names(DistSea) &lt;- df$colony_name[i] #Check calculation is successful if(terra::minmax(DistSea)[2] == 0) print(&quot;WARNING: Check for NAs in final output. Your origin(colony) may be to far in land. Therefore, your origin is completely buffered by omit cells (land cells), and no distance calculation for cells at sea can be performed&quot;) else print(paste(i, &quot;Distance calculation successful&quot;)) #Save rasters if(i == 1){ ColonyStack &lt;- DistSea } else { ColonyStack &lt;- c(ColonyStack,DistSea) } } ## [1] &quot;1 Distance calculation successful&quot; ## [1] &quot;2 Distance calculation successful&quot; ## [1] &quot;3 Distance calculation successful&quot; ## [1] &quot;4 Distance calculation successful&quot; ## [1] &quot;5 Distance calculation successful&quot; ## [1] &quot;6 Distance calculation successful&quot; ## [1] &quot;7 Distance calculation successful&quot; ## [1] &quot;8 Distance calculation successful&quot; ## [1] &quot;9 Distance calculation successful&quot; ## [1] &quot;10 Distance calculation successful&quot; ## [1] &quot;11 Distance calculation successful&quot; ## [1] &quot;12 Distance calculation successful&quot; ## [1] &quot;13 Distance calculation successful&quot; ## [1] &quot;14 Distance calculation successful&quot; ## [1] &quot;15 Distance calculation successful&quot; ## [1] &quot;16 Distance calculation successful&quot; ## [1] &quot;17 Distance calculation successful&quot; ## [1] &quot;18 Distance calculation successful&quot; ## [1] &quot;19 Distance calculation successful&quot; ## [1] &quot;20 Distance calculation successful&quot; ## [1] &quot;21 Distance calculation successful&quot; ## [1] &quot;22 Distance calculation successful&quot; ## [1] &quot;23 Distance calculation successful&quot; ## [1] &quot;24 Distance calculation successful&quot; ## [1] &quot;25 Distance calculation successful&quot; ## [1] &quot;26 Distance calculation successful&quot; ## [1] &quot;27 Distance calculation successful&quot; ## [1] &quot;28 Distance calculation successful&quot; ## [1] &quot;29 Distance calculation successful&quot; ## [1] &quot;30 Distance calculation successful&quot; ## [1] &quot;31 Distance calculation successful&quot; ## [1] &quot;32 Distance calculation successful&quot; ## [1] &quot;33 Distance calculation successful&quot; ## [1] &quot;34 Distance calculation successful&quot; ## [1] &quot;35 Distance calculation successful&quot; ## [1] &quot;36 Distance calculation successful&quot; ## [1] &quot;37 Distance calculation successful&quot; ## [1] &quot;38 Distance calculation successful&quot; ## [1] &quot;39 Distance calculation successful&quot; ## [1] &quot;40 Distance calculation successful&quot; ## [1] &quot;41 Distance calculation successful&quot; ## [1] &quot;42 Distance calculation successful&quot; ## [1] &quot;43 Distance calculation successful&quot; ## [1] &quot;44 Distance calculation successful&quot; ## [1] &quot;45 Distance calculation successful&quot; ## [1] &quot;46 Distance calculation successful&quot; ## [1] &quot;47 Distance calculation successful&quot; ## [1] &quot;48 Distance calculation successful&quot; ## [1] &quot;49 Distance calculation successful&quot; ## [1] &quot;50 Distance calculation successful&quot; ## [1] &quot;51 Distance calculation successful&quot; ## [1] &quot;52 Distance calculation successful&quot; ## [1] &quot;53 Distance calculation successful&quot; ## [1] &quot;54 Distance calculation successful&quot; ## [1] &quot;55 Distance calculation successful&quot; ## [1] &quot;56 Distance calculation successful&quot; ## [1] &quot;57 Distance calculation successful&quot; ## [1] &quot;58 Distance calculation successful&quot; ## [1] &quot;59 Distance calculation successful&quot; ## [1] &quot;60 Distance calculation successful&quot; ## [1] &quot;61 Distance calculation successful&quot; ## [1] &quot;62 Distance calculation successful&quot; 21.6 Inspect the output distance from colony rasters Look at the object and plot examples #Output is a stack of rasters containing a layer for each colony ColonyStack ## class : SpatRaster ## dimensions : 640, 1075, 62 (nrow, ncol, nlyr) ## resolution : 1000, 1000 (x, y) ## extent : -467720.8558, 607279.1442, -329322.1032, 310677.8968 (xmin, xmax, ymin, ymax) ## coord. ref. : +proj=laea +lat_0=-62.2587353064516 +lon_0=-52.8170365645161 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs ## source(s) : memory ## names : Acuna Island, Ambush Bay, Amphi~Point, Ardle~sland, Beagl~sland, Cape Bowles, ... ## min values : 1000.000, 1000.0000, 1000.000, 1000.000, 1000.0000, 1000.0000, ... ## max values : 1130910.822, 909312.8419, 1099295.598, 1060033.621, 882253.9674, 855354.4725, ... print(paste(nlyr(ColonyStack),&quot;raster layers&quot;)) ## [1] &quot;62 raster layers&quot; #To plot a particular raster use the index number plot(ColonyStack[[1]], main = df$colony_name[1]) plot(ColonyStack[[2]], main = df$colony_name[2]) plot(ColonyStack[[3]], main = df$colony_name[3]) plot(ColonyStack[[4]], main = df$colony_name[4]) 21.7 For each colony, estimate number of birds that use each cell Set any cells that are further that the provided maximum distance from the colony to NA Normalise to 0 and 1 probability of occurrence instead of distance using a log decay function Multiply by colony size Save ouputs to another raster stack Plot examples #Loop through colonies for(i in 1:nrow(df)){ DistSea &lt;- ColonyStack[[i]] ## Set any cell further than maximum distance to NA DistSea[DistSea &gt; max_colony_radius] &lt;- NA ## Normalise to 0 and 1 probability of occurrence ProbOccurence &lt;- -1*(DistSea/max_colony_radius)+1 #Apply logarithmic decay function as done in Critchley et al. 2020. #https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.04653 #Skipping this step will result in a linear decay. Other decay functions could be input here if justified. ProbOccurenceLog &lt;- ProbOccurence*(1/log(DistSea)) #Rescale to between 0 and 1 ProbOccurenceLog &lt;- ProbOccurenceLog/ max(values(ProbOccurenceLog), na.rm =T) #Multiply by population size PopRaster &lt;- ProbOccurenceLog*df$colony_size[i] #Add colony name to raster names(PopRaster) &lt;- df$colony_name[i] #Save rasters if(i == 1){ ColonyStack_pop &lt;- PopRaster } else { ColonyStack_pop &lt;- c(ColonyStack_pop,PopRaster) } } #To plot a particular raster use the index number plot(ColonyStack_pop[[1]], main = df$colony_name[1]) plot(ColonyStack_pop[[2]], main = df$colony_name[2]) plot(ColonyStack_pop[[3]], main = df$colony_name[3]) plot(ColonyStack_pop[[4]], main = df$colony_name[4]) 21.8 Overlap the rasters and save raster outputs If rasters from multiple colonies overlap, you can combine the rasters This means that if two nearby colonies don’t trigger IBA criteria individually, they may do in the areas they overlap all_sites_raster &lt;- sum(ColonyStack_pop, na.rm = T) plot(all_sites_raster) #create a folder to contain the outputs outputs &lt;- &quot;/seaward_extension_outputs&quot; dir.create(paste0(wd,outputs)) #save #terra::writeRaster(all_sites_raster,paste0(wd,outputs,&quot;/seaward-ext-multi-col-dist.tif&quot;), overwrite=T) 21.9 Calculate IBA raster If the species is not Threatened (Red List category of Least Concern, Near Threatened or Vulnerable), filter out cells containing less than 1% of the global population #turn abundance raster to dataframe. use IBA criteria function #test each iba criteria cell by cell, record whether meets each critirea (only global) #Waterbird or seabird? #Can we use lists from datazone #Jono will follow up with Ian B #Sometimes we need to know what red list criteria was applied to applu IBA/KBA sub criteria. #We can&#39;t share the BL database with this info. #red list api R #stored: #Science (W:) &gt; 2 Species data &gt; 2022 Red List datasets &gt; 2022-12 &gt; BL_Population_2022-12 if(red_list_category %in% c(&quot;LC&quot;,&quot;NT&quot;,&quot;VU&quot;)){ #Convert to with more (1) or less (0) than 1% of global population IBA_raster &lt;- all_sites_raster IBA_raster[IBA_raster &lt; best_global_estimate/100] &lt;- 0 IBA_raster[IBA_raster &gt;= best_global_estimate/100] &lt;- 1 #plot to check plot(IBA_raster) #set to NA cells IBA_raster[IBA_raster == 0] &lt;- NA } #There are other IBA and KBA criteria, you can look these up, but we are not able to include codes to assess all criteria in this toolkit. 21.10 Calculate IBA polygon Convert to polygon format Simplify the polygon to a more usable shape Fill in small holes between the land and simplified polygon Cut out the area covered by land Save the output #convert raster to a polygon format IBA_poly_ras &lt;- IBA_raster %&gt;% terra::as.polygons() %&gt;% sf::st_as_sf() #simplify the polygon IBA_poly &lt;- IBA_poly_ras %&gt;% sf::st_simplify(dTolerance = 2*res(IBA_raster)[1]) ##Make buffer to crop to local part of basemap max_dist_buffer &lt;- st_buffer(col_locs_proj, dist = max_colony_radius) land &lt;- basemap %&gt;% st_crop(st_bbox(max_dist_buffer)) %&gt;% st_union() #fill in holes in the polygon, and holes between the coatline and the polygon, #then trim out the areas covered by land IBA_poly_trim &lt;- smoothr::fill_holes(IBA_poly, threshold = st_area(IBA_poly)) %&gt;% st_union(.,land) %&gt;% smoothr::fill_holes(threshold = st_area(IBA_poly)) %&gt;% st_difference(land) #plot the result ggplot(IBA_poly_trim)+ geom_sf(data = IBA_poly_ras, fill = &quot;lightblue&quot;, color = NA)+ geom_sf(data = land, fill = &quot;grey&quot;, colour = NA)+ geom_sf(fill = NA, color = &quot;red&quot;) 21.11 Split into separate IBA polygons and save metadata #next task is to split the mulitpolygon into 2 separate polygons then for each polygon, min, max polys_df &lt;- create column for each criteria and polygon ID number #Split multipolygon into separate polygons polys &lt;- st_cast(IBA_poly_trim, to = &quot;POLYGON&quot;) #Warning message is ok #Many polygons? nrow(polys) #2 ## [1] 2 #for(i in 1:nrow(polys)){ # IBA_poly_single &lt;- polys[i,] # plot(IBA_poly_single) #abudance_raster_IBA &lt;- terra::mask(all_sites_raster, IBA_poly_ras_single) #polys_df$min_abundance[i] &lt;- round(min(values(abudance_raster_IBA),na.rm = T)) #polys_df$max_abundance[i] &lt;- round(max(values(abudance_raster_IBA),na.rm = T)) #record all the criteria met (unique in each cells) #then 1 row of data per polgyons #subspecies can be used a regional IBA criteria #Olivia&#39;s current scripts don&#39;t use regional pop est. criteria #Add text to say that we aren&#39;t considering regional criteria, but they do exist #area #centroid #species #numbers are not in a good order #would be good to order north to south or clockwise, or left to right #add the polygon number to the plot #} #plot the final polygon with foraging radius approach #colony &lt;- subset(col_locs_proj,colony_name == df$colony_name[i]);colony #max_dist_buffer &lt;- st_buffer(col_locs_proj, dist = max_colony_radius) %&gt;% # st_union() #plot the result #ggplot(IBA_poly_trim)+ # geom_sf(data = land, fill = &quot;grey&quot;, colour = NA)+ # geom_sf(fill = &quot;#fcba0350&quot;, color = &quot;red&quot;) #ggplot(max_dist_buffer)+ # geom_sf(fill = NA, col = &quot;blue&quot;)+ # geom_sf(data = IBA_poly_trim, fill = &quot;#fcba0350&quot;, col = &quot;red&quot;)+ # geom_sf(data = land, fill = &quot;grey&quot;, color = NA) + # ggtitle(&quot;All colonies&quot;) #add metadata to the polygon before saving #add metadata to the plot #if different cells meet different criteria, we can draw a polygon around the entire area #Jono removed polygons that are less than 1 cell large - but for this we will not drop any polygons - instead add guidance that they should. #site_name &lt;- &quot;Spindrift Rocks Seaward Extension&quot; #plot the result #ggplot(IBA_poly_trim)+ # geom_sf(data = land, fill = &quot;grey&quot;, colour = NA)+ # geom_sf(fill = &quot;#fcba0350&quot;, color = &quot;red&quot;) + # ggtitle(site_name) #save the polygon #st_write(IBA_poly_trim, paste0(getwd(),&quot;\\\\outputs\\\\IBA_polygon&quot;,gsub(&quot; #&quot;,&quot;_&quot;,site_name),&quot;.shp&quot;)) 21.12 Record the metadata This is needed for the submission of the site in the WBDB. Many variables have already been input or generated by the script so far. Some need to be calculated: - Area - Coordinates of the mid point - Min/best/max estimate of number of mature individuals in the site (not pairs) #Calculate the area of the site. #area_km2 &lt;- as.numeric(st_area(IBA_poly_trim)/1000000) #area_hectare &lt;- area_km2*100 #Calculate the midpoint of the site and record in the different formats #midpoint &lt;- st_centroid(IBA_poly_trim) %&gt;% # st_transform(4326) #lat_midpoint_decdeg &lt;- midpoint$geometry[[1]][2] #lat_mid_deg &lt;- gsub(&quot;-&quot;,&quot;&quot;,gsub(&quot;\\\\..*&quot;,&quot;&quot;,lat_midpoint_decdeg)) #lat_mid_decmin &lt;- as.numeric(paste0(&quot;0.&quot;,strsplit(as.character(lat_midpoint_#decdeg), split = &quot;[.]&quot;)[[1]][2]))*60 #lat_mid_north_or_south &lt;- ifelse(substr(lat_midpoint_decdeg,1,1) == &quot;-&quot;, #&quot;South&quot;, &quot;North&quot;) #lon_midpoint_decdeg &lt;- midpoint$geometry[[1]][1] #lon_mid_deg &lt;- gsub(&quot;-&quot;,&quot;&quot;,gsub(&quot;\\\\..*&quot;,&quot;&quot;,lon_midpoint_decdeg)) #lon_mid_decmin &lt;- as.numeric(paste0(&quot;0.&quot;,strsplit(as.character(lon_midpoint_#decdeg), split = &quot;[.]&quot;)[[1]][2]))*60 #lon_mid_north_or_south &lt;- ifelse(substr(lat_midpoint_decdeg,1,1) == &quot;-&quot;, #&quot;West&quot;, &quot;East&quot;) #collate the metadat already input or generate in this script #metadata &lt;- as.data.frame(cbind(site_name, area_km2, area_hectare, # lat_midpoint_decdeg, lat_mid_deg, #lat_mid_decmin, lat_mid_north_or_south, # lon_midpoint_decdeg, lon_mid_deg, #lon_mid_decmin, lon_mid_north_or_south, # common_name, scientific_name, colony_size, # best_global_estimate, red_list_category, #red_list_criteria)) #write.csv(metadata, paste0(&quot;IBA_metadata_&quot;,gsub(&quot; &quot;,&quot;_&quot;,site_name),&quot;.csv&quot;), # row.names = F) "],["tracking-data-brief-introduction.html", "22 Tracking data: Brief introduction 22.1 Animal tracking data considered in this toolkit 22.2 General introduction to animal tracking data", " 22 Tracking data: Brief introduction This chapter was built with R version 4.3.2 (2023-10-31 ucrt) The chapter was last updated on 2024-02-23 22.1 Animal tracking data considered in this toolkit This toolkit focuses on the analysis of data primarily from GPS and PTT devices. Some of the analyses may be extended to data from GLS devices. For all devices, we encourage users to understand the limitations of each device and how these limitations can affect interpretation of animal movement patterns. 22.2 General introduction to animal tracking data Distribution data can be obtained from observations collected during surveys within a predetermined spatio-temporal frame of reference or by sampling locations of individual animals using animal‐borne tracking devices. The former provide an area-based sampling perspective, also referred to as a Eulerian perspective in the oceanographic literature, whereas the latter provides an individual based sampling perspective, also referred to as a Langragian perspective (Phillips et al. (2019)). Area-based or Eulerian survey designs sample across a predetermined survey area using predetermined sampling locations or transects, which may or may not be replicated through time. The primary objective of this sampling approach is to obtain animal distribution and abundance data in a predefined area and time period. For seabirds, at-sea such surveys are generally conducted using ships or aircraft (Buckland et al. (2012); Camphuysen et al. (2004); Tasker et al. (1984)), although land-based surveys may be used to cover near-shore environments (Arranz et al. (2014); Smith et al. (2015)). Individual-based or Lagrangian survey designs track the locations of seabirds and other marine megafauna through space and time using data logging or tracking devices attached to individuals (Burger and Shaffer (2008); Hays et al. (2019)). Location data may be received in near real-time from transmitting or satellite-linked devices, or obtained by downloading stored location data using base-stations or after device retrieval. Depending on the mobility of a species, individual-based sampling may increase the spatial extent and resolution of the survey area compared to area-based surveys, or even identify colony location and/or at-sea habitats if no a priori information about species movements are available (Bolton (2021)). Modern tracking methods provide high‐resolution data (generally with sub-km precision) at an individual level, but device cost and the logistical challenges of tag deployment usually limit the number of tags deployed, as well as the number of locations at which tags are deployed. So while the spatial extent of survey coverage achieved by animal-borne devices is determined by individual’s movements, and not a priori defined by the surveyor, achieved coverage of the wider marine environment will generally not be independent of the locations at which tracking devices are deployed. Tag deployment further depends on the accessibility and/or catchability of individuals, therefore tracking data sets often exhibit individual-level heterogeneity, which may be related to sex, age, breeding status and/or colony-affiliation (Gutowsky et al. (2015); Krietsch et al. (2017)) and may complicate population‐level inferences. Some of the limitations identified above should be accounted for by users when defining the “dataGroup” for analysese following the track2kba protocol outlined in this toolkit. "],["tracking-data-sampling-strategy.html", "23 Tracking data: Sampling strategy 23.1 Sampling strategy when collecting animal tracking data for seabirds 23.2 How many birds should you track? 23.3 How many years of tracking data should you collect? 23.4 How many years of tracking data should you collect for KBA or IBA identification? 23.5 Which locations should you track animals from? 23.6 Sampling strategy general recommendations", " 23 Tracking data: Sampling strategy This chapter was built with R version 4.3.2 (2023-10-31 ucrt) The chapter was last updated on 2024-02-23 23.1 Sampling strategy when collecting animal tracking data for seabirds Animal tracking technology has evolved with respect to size and cost of devices. Hence, the opportunities for collecting tracking data have changed too. In the past - when devices were much larger and much more expensive - it was likely that few birds were tracked. Tracking typically occurred from sites that were more accessible than others, as opposed to sites specifically being chosen for their larger source populations. While this type of sampling strategy (selecting sites for accessibility) is often dictated by pragmatic choices needing to be made, or alternate research questions being addressed, outputs from these studies may not necessarily lend themselves well to the identification of globally important sites such as IBAs and KBAs. Researchers must take sampling strategy into account when considering the type of question they wish to answer in their studies. Of course, data collected from one study may be used in a different study in future. But the utility of such data being considered for retrospective analyses should be considered appropriately. 23.2 How many birds should you track? There is no precise answer to this question. The answer in part depends on what kind of question you are trying to answer about a particular species. If you are tracking a globally threatened species with an extremely small population size, or are tracking a species highly sensitive to devices being deployed on it, then a small number of individuals being tracked may be sufficient to identify where an important site might be. However, we suggest that at least 10 birds from a unique dataGroup are tracked before inferring movement patterns about a particular source population. dataGroup: learn more about how to define a dataGroup in the dataGroup chapter. 23.3 How many years of tracking data should you collect? Again, there is no precise answer to this question. Evidence, from Beal et al. (2023) based on GPS tracking of 23 chick-rearing seabird species, suggests that: tracking chick-rearing seabirds across years improves the estimation of at-sea spatial distributions. However, in most cases the information gain is marginal. samples collected in only one or two years can be useful for the identification of important sites. of key importance when considering tracking data for questions related to area-based conservation is whether the sample of tracked individuals is representative at the population level. when only one or two years of tracking data are available for important site identification, using independent evidence to assess whether conditions were typical of the region and time of year is critical for interpretation of results. if conditions were atypical, then further years of sampling may be warranted. One to two years of tracking data may be sufficient to inform area-based conservation decisions. However, long-term studies will still be critical to inform how seabirds may respond to envrionmental perturbation. 23.4 How many years of tracking data should you collect for KBA or IBA identification? At a minimum, you will need tracking information from 10 animals, ideally from a single year, to consider the relevant outputs in the context of KBA or IBA identification. 23.5 Which locations should you track animals from? A number of factors may dictate which locations you track animals from. Broadly speaking, these factors may include: sites selected depending on the research question you wish to address sites selected owing to feasibility of accessing sites sites selected according to species known ecology, and hence ability to capture and deploy (and / or retrieve where necessary) devices on animals In the context of the marine toolkit, where identification of globally important marine sites is often linked to individuals tracked from a particular source location (i.e. the dataGroup): we advise investigators to track animals from source locations where those sites themselves would liekly trigger relevant KBA or IBA criteria. 23.6 Sampling strategy general recommendations In general, to support identification of an important site at sea from animal tracking data, we suggest the following: A minimum of 10 individual animals are tracked; all from the same source population Data from the 10 individual animals that are tracked should all represent data from the same life-cycle stage, within a given year, when it is expected that animals are moving in a similar manner to one another. (e.g. for penguins, you should have tracking information for all 10 individuals from within the chick-guard period) "],["tracking-data-merge-files-together-for-analysis.html", "24 Tracking data: Merge files together for analysis 24.1 What this chapter covers: 24.2 Where you can get example data for the chapter: 24.3 Load packages 24.4 Define object names for chapter 24.5 Storing, reading, and formatting raw tracking data 24.6 Example data summary: Yelkouan Shearwaters (Puffinus yelkouan), Croatia 24.7 Loading example data: Yelkouan Shearwaters (Puffinus yelkouan)", " 24 Tracking data: Merge files together for analysis Analyses outlined in this chapter were performed in R version 4.3.2 (2023-10-31 ucrt) This chapter was last updated on 2024-02-23 24.1 What this chapter covers: Read in raw tracking data into R (assuming data is in *.csv file format). Combine data into a single data frame. Save the single data frame as a *.csv file for further analyses 24.2 Where you can get example data for the chapter: This tutorial uses example data from a project led by the BirdLife International partner in Croatia: BIOM The citation for this data is: Zec et al. 2023 Example data is available upon request 24.3 Load packages Load required R packages for use with codes in this chapter: If the package(s) fails to load, you will need to install the relevant package(s). ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Load libraries -------------------------------------------------------------- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## sf package for spatial data analyses (i.e. vector files such as points, lines, polygons) library(sf) ## Tidyverse for data manipulation library(tidyverse) ## ggplot2 for plotting opionts library(ggplot2) ## rnaturalearth package for geographic basemaps in R library(rnaturalearth) ## leaflet package for interactive maps in R library(leaflet) ## lubridate for date time library(lubridate) ## track2kba for the analysis of important site identification library(track2KBA) ## speed filter library(trip) ## linear interpolation library(adehabitatLT) ## library(raster) ## library(viridis) ## library(readxl) library(xlsx) 24.4 Define object names for chapter Typically, if your data follows the same format as the examples in the chapter, then below should be the only thing(s) you need to change. ## Define your species name (avoid spaces by using hashes instead. This can help with later coding steps) species.name &lt;- &quot;Puffinus-yelkouan&quot; ## Define your colony name colony.name &lt;- &quot;Z&quot; ## Set file path to where tracking data is stored ## If you are less familiar with R, it can be easier to specify the entire file path. fpath.tracks &lt;- &quot;C:\\\\Users\\\\jonathan.handley\\\\OneDrive - BirdLife International\\\\JonoHandley_BirdLife\\\\PROJECTS\\\\Marine Toolkit\\\\GitHub_MarineToolkit_JH3\\\\MarMeCo-Toolkit-R-Beta-JH3\\\\data-testing\\\\tracking-data\\\\Puffinus-yelkouan-raw-csv-tracking\\\\Z&quot; Pro Tip: navigate to the folder where your tracking data is stored. Copy the file path from within the file explorer. Then type the readClipboard() function in R to print the file path. Copy and paste the file path into the code above. 24.5 Storing, reading, and formatting raw tracking data 24.5.1 Storing raw tracking data The type of animal tracking device you use will dictate what format your raw tracking data is stored in. Typically, raw outputs from animal tracking devices have been stored as *.csv files. Good file management is critical when working with large tracking datasets. 24.5.2 Reading raw tracking data into R / Rstudio Depending on your file structure, type of raw data, and size of your overall data, we recommend reading data into R in a way that produces a single data file for all your data required for a specific analysis. Reading all your data in at once is greatly facilitated when each data file is stored in a stardised format. 24.6 Example data summary: Yelkouan Shearwaters (Puffinus yelkouan), Croatia Summary of the example dataset used in this tutorial: Species tracked: Yelkouan Shearwater (Puffinus yelkouan) Colony tracked from: Zaklopatica (Z), Croatia Site / source population birds tracked from: Lastovo SPA, Croatia Life-cycle stage when birds were tracked: chick-rearing Years birds were tracked over: 2019, 2020 Devices birds were tracked with: GPS Device model type: PathTrack nanoFix GPS/UHF transmitters (≤ 5.5 g) 24.7 Loading example data: Yelkouan Shearwaters (Puffinus yelkouan) 24.7.1 Load example data: First, exploring the data on your machine ## Check where your current working directory is set up to go to: getwd() ## [1] &quot;C:/Users/jonathan.handley/OneDrive - BirdLife International/JonoHandley_BirdLife/PROJECTS/Marine Toolkit/GitHub_MarineToolkit_JH6&quot; In the examples below, you can see different levels at which we have explored what is inside each folder. You will note: A top level folder called Puffinus-yelkouan-raw-csv-tracking Within this folder, different colonies worth of tracking data: Zaklopatica (Z), Veli Maslovnjak (VM). Within each colony folder of tracking data, uniquely named .csv files relating to each unique deployment on a bird. This format of broadly storing data by Species -&gt; Colony is aligned with the format used for inputting data into the Seabird Tracking Database. We recognise that more granular (finer) levels of data storage may be chosen. ## [1] &quot;_book&quot; ## [2] &quot;_main.Rmd&quot; ## [3] &quot;_main_files&quot; ## [4] &quot;01-01-Executive-Summary.html&quot; ## [5] &quot;01-01-Executive-Summary.Rmd&quot; ## [6] &quot;01-02-Toolkit-Offers.Rmd&quot; ## [7] &quot;01-03-Toolkit-NOT-Offers.Rmd&quot; ## [8] &quot;01-04-Contribute.Rmd&quot; ## [9] &quot;01-05-Theory-Of-Change.html&quot; ## [10] &quot;01-05-Theory-Of-Change.Rmd&quot; ## [11] &quot;01-06-Project-Management.html&quot; ## [12] &quot;01-06-Project-Management.Rmd&quot; ## [13] &quot;01-07-Before_IBA-KBA-Consider.Rmd&quot; ## [14] &quot;02-01-Site-Concept-AreaBasedConservation.Rmd&quot; ## [15] &quot;02-02-Sites-KBAs-IBAs.Rmd&quot; ## [16] &quot;02-03-Sites-Seabirds.html&quot; ## [17] &quot;02-03-Sites-Toolkit.Rmd&quot; ## [18] &quot;02-04-Sites-Method-Consider.Rmd&quot; ## [19] &quot;02-04-Sites-Seabirds-Method-Summary.html&quot; ## [20] &quot;02-05-Sites-Seabirds-Cons-Summary.Rmd&quot; ## [21] &quot;02-06-Sites-Seabirds-PolAdvoc-Summary.Rmd&quot; ## [22] &quot;03-01-Data-Required-Seabird-Sites.Rmd&quot; ## [23] &quot;03-02-DataGroups-Defining.html&quot; ## [24] &quot;03-02-DataGroups-Defining.Rmd&quot; ## [25] &quot;03-03-Colony-Single-Assessment.Rmd&quot; ## [26] &quot;03-04-Colony-Multi-Assessment.Rmd&quot; ## [27] &quot;03-05-Colony-MultiSpecies-Assessment.Rmd&quot; ## [28] &quot;04-01_Seaward_extension_introduction.Rmd&quot; ## [29] &quot;04-02-Seaward_extension_background_single_ne.Rmd&quot; ## [30] &quot;04-03_Seaward_extension_multi_ne.Rmd&quot; ## [31] &quot;05-01-TrackingData-IntroToTracking.Rmd&quot; ## [32] &quot;05-02-TrackingData-SamplingStrategy.Rmd&quot; ## [33] &quot;05-06-TrackingData-FormatAndMergeCSVfiles.Rmd&quot; ## [34] &quot;05-07-TrackingData-STDB-format.Rmd&quot; ## [35] &quot;05-08-TrackingData-Intro-Plot-ReviewTabular.Rmd&quot; ## [36] &quot;05-09-TrackingData-CleaningData.Rmd&quot; ## [37] &quot;06-01-Track2KBA-Intro.Rmd&quot; ## [38] &quot;06-02-Track2KBA-CPF-CleanSummariseData.Rmd&quot; ## [39] &quot;06-03-Track2KBA-CPF-Analysis.Rmd&quot; ## [40] &quot;06-04-Track2KBA-Non-CPF-Example.Rmd&quot; ## [41] &quot;07-01-Prelim-Sites-AssessCriteria.Rmd&quot; ## [42] &quot;07-02-Prelim-Sites-KBA-Considerations.Rmd&quot; ## [43] &quot;07-03-Prelim-Sites-Merging-Layers.Rmd&quot; ## [44] &quot;07-04-Prelim-Sites-RefineFinalBoundaries.Rmd&quot; ## [45] &quot;08-01-SuppData-AtSeaSurveys.Rmd&quot; ## [46] &quot;08-02-SuppData-Modelling.Rmd&quot; ## [47] &quot;09-01-Sites-Proposing-KBA.Rmd&quot; ## [48] &quot;10-01-Sites-Monitoring.Rmd&quot; ## [49] &quot;10-02-Sites-Conservation.Rmd&quot; ## [50] &quot;10-03-Sites-Policy-Advocacy.html&quot; ## [51] &quot;10-03-Sites-Policy-Advocacy.Rmd&quot; ## [52] &quot;91-02-Sites-Proposing-IBA.Rmd&quot; ## [53] &quot;91-04-Appendix-InterpolationMethodsCompare.html&quot; ## [54] &quot;91-04-Appendix-InterpolationMethodsCompare.Rmd&quot; ## [55] &quot;91-05-Contact.Rmd&quot; ## [56] &quot;91-06-References.Rmd&quot; ## [57] &quot;AllZoteroReferences.bib&quot; ## [58] &quot;CHAPTERS-Temp-folder&quot; ## [59] &quot;data-input-files-bookdown&quot; ## [60] &quot;data-input-files-tracking&quot; ## [61] &quot;data-testing&quot; ## [62] &quot;docs&quot; ## [63] &quot;GitHub_MarineToolkit_JH6.Rproj&quot; ## [64] &quot;index.Rmd&quot; ## [65] &quot;LICENSE&quot; ## [66] &quot;photos-for-book&quot; ## [67] &quot;photos-for-book-NonGitHub&quot; ## [68] &quot;presentations-toolkit&quot; ## [69] &quot;R-RMarkdown-AdvocacyPolicy&quot; ## [70] &quot;R-RMarkdown-AtSea-Modelling&quot; ## [71] &quot;R-RMarkdown-BookdownChapters&quot; ## [72] &quot;R-RMarkdown-Conservation&quot; ## [73] &quot;R-RMarkdown-Jono&quot; ## [74] &quot;R-RMarkdown-TestFiles&quot; ## [75] &quot;R-Scripts-Chapters&quot; ## [76] &quot;R-Scripts-Chapters-MarineToolkit.zip&quot; ## [77] &quot;R-Scripts-RENDER-FromMarkdown.R&quot; ## [78] &quot;R-Scripts-SavingFromMarkdown.R&quot; ## [79] &quot;README.md&quot; ## [80] &quot;seaward_extension_outputs&quot; ## [81] &quot;tracking_CleanAndPrepareData2_AllTracks.R&quot; ## [1] &quot;VM&quot; &quot;Z&quot; ## [1] &quot;20_Tag17700_VM-13.csv&quot; &quot;20_Tag17717_VM-8.csv&quot; ## [3] &quot;20_Tag40014_VM-3 (2nd Parent).csv&quot; &quot;20_Tag40086_VM-3.csv&quot; ## [5] &quot;20_Tag40138_VM-18.csv&quot; &quot;20_Tag40536_VM-8 (2nd Parent).csv&quot; ## [7] &quot;20_Tag40615_VM-23.csv&quot; &quot;20_Tag40817_VM-12.csv&quot; dir(&quot;./data-testing/tracking-data/Puffinus-yelkouan-raw-csv-tracking/Z&quot;) ## [1] &quot;19_Tag17600_Z-9.csv&quot; ## [2] &quot;19_Tag17604_Z-7.csv&quot; ## [3] &quot;19_Tag17617_Z-4 (2nd Parent).csv&quot; ## [4] &quot;19_Tag17644_Z-13.csv&quot; ## [5] &quot;19_Tag17652_Z-2.csv&quot; ## [6] &quot;19_Tag17704_Z-11.csv&quot; ## [7] &quot;19_Tag17735_Z-3 (RAW DATA MISSING).csv&quot; ## [8] &quot;19_Tag40066_Z-14.csv&quot; ## [9] &quot;19_Tag40069_Z-6.csv&quot; ## [10] &quot;19_Tag40073_Z-1.csv&quot; ## [11] &quot;19_Tag40078_Z-3 (2nd Parent).csv&quot; ## [12] &quot;19_Tag40086_Z-11 (2nd Parent).csv&quot; ## [13] &quot;19_Tag40094_Z-16.csv&quot; ## [14] &quot;19_Tag40118_Z-2 (2nd Parent).csv&quot; ## [15] &quot;19_Tag40133_Z-15.csv&quot; ## [16] &quot;19_Tag40138_Z-17.csv&quot; ## [17] &quot;19_Tag40170_Z-12.csv&quot; ## [18] &quot;19_Tag40177_Z-17 (2nd Parent).csv&quot; ## [19] &quot;19_Tag40182_Z-4.csv&quot; ## [20] &quot;20_Tag17600_Z-170.csv&quot; ## [21] &quot;20_Tag17604_Z-95.csv&quot; ## [22] &quot;20_Tag17644_Z-106.csv&quot; ## [23] &quot;20_Tag17677_Z-170 (2nd Parent).csv&quot; ## [24] &quot;20_Tag17724_Z-106 (2nd Parent).csv&quot; ## [25] &quot;20_Tag40024_Z-178 (2nd Parent).csv&quot; ## [26] &quot;20_Tag40039_Z-15 (2nd Parent).csv&quot; ## [27] &quot;20_Tag40073_Z-131 (2nd Parent).csv&quot; ## [28] &quot;20_Tag40078_Z-178.csv&quot; ## [29] &quot;20_Tag40094_Z-131.csv&quot; ## [30] &quot;20_Tag40118_Z-175.csv&quot; ## [31] &quot;20_Tag40133_Z-1 (2nd Parent).csv&quot; ## [32] &quot;20_Tag40193_Z-13 (2nd Parent).csv&quot; ## [33] &quot;20_Tag40859_Z-179.csv&quot; ## [34] &quot;20_Tag41108_Z-95 (2nd Parent).csv&quot; 24.7.2 Load example data: Second, prepare the files for loading into R Preparing animal tracking data for merging into a single data frame may require some initial cleaning of the raw tracking data outputs. You will need to consider: Do all the devices I have collected data with have a common file format? (e.g. are the column names consistent across all devices?) Do all the devices I have collected data with have a common file type? (e.g. are the output files *.csv files, or are they custom to the device manufacturer?) A number of other factors may need to be considered. If the raw outputs from tracking devices vary across deployments, you may need to first standardise data from each deployment into a common format for subsequent merging. For example: If you deployed GPS device TYPE A in season 1 and the output was a csv file with 8 columns, and you then deployed GPS device TYPE B in season 2 and the output was a custom file type with 10 columns, you would need to standardise the data separately for each GPS device type and season combination, before being able to merge all the data into a single data frame. 24.7.3 Load example data: Third, load the files into a single data frame in R Here, we assume users have prepared their data into standardised *.csv files across each deployment, where each file has the same number of columns and matching column names. The number of columns and column names can be unique to your data. The key thing is that all column names, and the associated variables represented by each column, are matching. Notes on the example data: In the case of the example data for Yelkouan Shearwaters, the original output from the PathTrack nanoFix GPS/UHF transmitters (GPS devices) was a custom .pos file. These .pos files were prepared for analysis in a separate R script. 24.7.3.1 Produce list of file names with all your tracking data Produce a list of file names with all your tracking data ## specifying the files: folder directly track.list &lt;- list.files(path = fpath.tracks, ## Set recursive = TRUE to search through sub-folders if required. recursive = FALSE, pattern = &quot;.csv&quot;, full.names = T) Check how long the list of names is names that was read in using the list.files() function. ## Check how many deployments you are expecting to bind together. ## This code effectively says, how long is the list ## of names that were read in using the list.files function. length(track.list) ## [1] 34 If the number is too small or too large, and you expect more or less deployments to be considered, it may be the case that: there are additional *.csv files in your deployment folders that should not be there (i.e. too many deployments being considered / number too large) there are fewer deployments being considered than should be. (i.e. supposed *.csv files indicative of deployments are likely not being read correctly) Ultimately, if the number of deployments you think you have in total is not equivalent to this review, then check what the issue might be as per options considered above. Next, create a blank data frame to which you can bind on the tracking data from each unique deployment. Effectively, you can consider this step as preparing for sticking all your data together to make one big table (a data frame in R) with all of the data. 24.7.3.2 Merge tracking data together to create singe file ## specify a blank dataframe track.df &lt;- data.frame() Finally, use a for loop to read in each file from each unique deployment, and then bind them all together. Unsure how a for loop works? See numerous resources online. for(i in 1:length(track.list)){ ## read in a unique file temp &lt;- read.csv(track.list[i]) ## bind the unique file onto the data frame template track.df &lt;- rbind(track.df,temp) ## print some text to show progress of the loop and binding process print(paste(&quot;Deployment &quot;, i, &quot; of &quot;, length(track.list), &quot;being bound to the data frame.&quot;)) } ## [1] &quot;Deployment 1 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 2 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 3 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 4 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 5 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 6 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 7 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 8 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 9 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 10 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 11 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 12 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 13 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 14 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 15 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 16 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 17 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 18 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 19 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 20 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 21 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 22 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 23 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 24 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 25 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 26 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 27 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 28 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 29 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 30 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 31 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 32 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 33 of 34 being bound to the data frame.&quot; ## [1] &quot;Deployment 34 of 34 being bound to the data frame.&quot; 24.7.4 Review the data you have read into R Here you are doing some quick inspections to see if anything unexpected may have happened when reading your data into R. If you are unsure, or want to learn more about the different way data can be structured in R, consider doing an online R course which teaches the beginnger concepts of R. Also, see the latest “R for Data Science” book by Hadley Wickham and colleagues. ## Print the column names and first two rows of data - does everything look as it should? head(track.df,2) ## day month year hour minute second satellites latitude longitude altitude ## 1 24 5 19 0 49 9 5 42.811528 16.885531 -1.50 ## 2 24 5 19 1 9 3 5 42.812029 16.886907 5.25 ## time_offset accuracy voltage colony_code bird_id ## 1 2.910 4.70376e-07 4.12 Z 19_Tag17600_Z-9 ## 2 2.795 9.25368e-07 4.08 Z 19_Tag17600_Z-9 ## dttm deploy_year ## 1 2019-05-24 00:49:09 2019 ## 2 2019-05-24 01:09:03 2019 ## Print the LAST two rows of data - does everything look as it should? tail(track.df,2) ## day month year hour minute second satellites latitude longitude altitude ## 11353 30 5 20 16 33 5 6 43.197648 16.354861 61.25 ## 11354 30 5 20 19 51 59 6 42.817527 16.766630 86.75 ## time_offset accuracy voltage colony_code ## 11353 -23.16 5.226000e-06 3.98 Z ## 11354 -23.31 2.183421e-06 4.02 Z ## bird_id dttm deploy_year ## 11353 20_Tag41108_Z-95 (2nd Parent) 2020-05-30 16:33:05 2020 ## 11354 20_Tag41108_Z-95 (2nd Parent) 2020-05-30 19:51:59 2020 ## Now check the structure of each column of data str(track.df,2) ## &#39;data.frame&#39;: 11354 obs. of 17 variables: ## $ day : int 24 24 24 24 24 24 24 24 24 24 ... ## $ month : int 5 5 5 5 5 5 5 5 5 5 ... ## $ year : int 19 19 19 19 19 19 19 19 19 19 ... ## $ hour : int 0 1 1 1 2 2 2 3 3 6 ... ## $ minute : int 49 9 29 49 9 29 49 9 29 47 ... ## $ second : int 9 3 3 9 5 6 9 5 5 38 ... ## $ satellites : int 5 5 5 4 6 7 4 6 5 6 ... ## $ latitude : num 42.8 42.8 42.8 42.8 42.8 ... ## $ longitude : num 16.9 16.9 16.9 16.9 16.9 ... ## $ altitude : num -1.5 5.25 143.5 143 98 ... ## $ time_offset: num 2.91 2.79 2.79 2.91 2.93 ... ## $ accuracy : num 4.70e-07 9.25e-07 3.52e-07 7.13e-07 4.87e-06 ... ## $ voltage : num 4.12 4.08 4.08 4.1 4.12 4.1 4.12 4.12 4.12 4.1 ... ## $ colony_code: chr &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; ... ## $ bird_id : chr &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## $ dttm : chr &quot;2019-05-24 00:49:09&quot; &quot;2019-05-24 01:09:03&quot; &quot;2019-05-24 01:29:03&quot; &quot;2019-05-24 01:49:09&quot; ... ## $ deploy_year: int 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 ... 24.7.5 Save the merged data ## Save the output file write.csv(track.df, paste0(&quot;./data-testing/tracking-data/&quot;, species.name, &quot;-&quot;,colony.name,&quot;-tracking-raw-merged.csv&quot;), row.names = F) "],["tracking-data-convert-files-into-format-of-seabird-tracking-database.html", "25 Tracking data: Convert files into format of Seabird Tracking Database 25.1 What this chapter covers: 25.2 Where you can get example data for the chapter: 25.3 Load packages 25.4 Define object names for chapter 25.5 Load file created from previous chapter 25.6 Seabird Tracking Database format 25.7 Loading the dataset template from Seabird Tracking Database 25.8 INPUT format: Seabird Tracking Database 25.9 OUTPUT format: Seabird Tracking Database", " 25 Tracking data: Convert files into format of Seabird Tracking Database Analyses outlined in this chapter were performed in R version 4.3.2 (2023-10-31 ucrt) This chapter was last updated on 2024-02-23 25.1 What this chapter covers: Convert merged data into the INPUT and OUTPUT format of the Seabird Tracking Database: https://www.seabirdtracking.org/. NOTE: if your dataset is already hosted on the Seabird Tracking Database, you can download it from there directly and skip the steps below. 25.2 Where you can get example data for the chapter: This tutorial uses example data from a project led by the BirdLife International partner in Croatia: BIOM The citation for this data is: Zec et al. 2023 Example data is available upon request A description of the example data is given in a separate chapter 25.3 Load packages Load required R packages for use with codes in this chapter: If the package(s) fails to load, you will need to install the relevant package(s). ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Load libraries -------------------------------------------------------------- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## sf package for spatial data analyses (i.e. vector files such as points, lines, polygons) library(sf) ## Tidyverse for data manipulation library(tidyverse) ## ggplot2 for plotting opionts library(ggplot2) ## rnaturalearth package for geographic basemaps in R library(rnaturalearth) ## leaflet package for interactive maps in R library(leaflet) ## lubridate for date time library(lubridate) ## track2kba for the analysis of important site identification library(track2KBA) ## speed filter library(trip) ## linear interpolation library(adehabitatLT) ## library(raster) ## library(viridis) ## library(readxl) library(xlsx) ## library(parsedate) 25.4 Define object names for chapter Typically, if your data follows the same format as the examples in the chapter, then below should be the only thing(s) you need to change. ## Define your species name (avoid spaces by using hashes instead. This can help with later coding steps) species.name &lt;- &quot;Puffinus-yelkouan&quot; ## Define your colony name colony.name &lt;- &quot;Z&quot; 25.5 Load file created from previous chapter ## Read the csv file of all the merged data and name the object the same as in the relevant chapter track.df &lt;- read.csv(&quot;./data-testing/tracking-data/Puffinus-yelkouan-Z-tracking-raw-merged.csv&quot;) 25.6 Seabird Tracking Database format Having data standardised into the same format greatly improves reproducible research, and also the ability for data to be used in other studies. The primary format we recommend is that of BirdLife International’s Seabird Tracking Database: - https://www.seabirdtracking.org/ When you visit the Seabird Tracking Database website, you will find the Instructions page, which: provides information about the standardised format of data used in this global database, and provides a dataset template that you can use to support formatting your data into the format used within the Seabird Tracking Database. For further details: See the data submission instructions. Download the dataset template from the Instructions page We recognise, however, that the format of the Seabird Tracking Database may not be appropriate for all analyses. Nevertheless, we encourage users to standardise their data into a common format. This will facilitate the ease through which data can be reformatted when necessary for other analyses. 25.7 Loading the dataset template from Seabird Tracking Database By loading the dataset template from the Seabird Tracking Database, this can facilitate what the format of your data should adhere to, to support analyses outlined in the Marine Toolkit. stdb.df.template &lt;- read_xlsx(&quot;./data-testing/tracking-data-stdb/Template_Datapoints.xlsx&quot;, sheet = &quot;Template&quot;) head(data.frame(stdb.df.template)) ## [1] BirdId Sex Age Breed.Stage TrackId ## [6] DateGMT TimeGMT Latitude Longitude Equinox ## [11] ArgosQuality ## &lt;0 rows&gt; (or 0-length row.names) ## dimensions of the seabird tracking database data template dim(stdb.df.template) ## [1] 0 11 You can see that the dataset template from the Seabird Tracking Database contains 11 columns. How you format your data to match that of the Seabird Tracking Database will be dependent on the type of animal tracking device used (i.e. GPS, PTT, GLS) SEE: within the Seabird Tracking Database template, the different example datasets for GPS, PTT, and GLS data. We will update the appendix to include examples of preparing data from different device types for the format of the Seabird Tracking Database. 25.8 INPUT format: Seabird Tracking Database 25.8.1 Formatting own data to align with Seabird Tracking Database INPUT format Typically, you will need three things to get data ready for the STDB: “Dataset” level information Metadata information “Data point” level information NOTE: Information stored in the STDB is organized into two levels – “Dataset” level and “Data points” level. The “dataset level” are provided by filling in an online form, and the “data points” level of information is submitted by uploading a csv file. Review the data submission instructions indicated above for further guidance. 25.8.1.1 “Dataset” level information required for STDB The “dataset level” information provides the broad background information about your dataset required for uploading the dataset to the STDB. It is the key information about any set of data that were collected for a given species, in a given colony, with a given type of device, and where data are owned by the same group of contributors. 25.8.1.2 Metadata information A metadata file is a set of data that describes and gives information about other data. In this tutorial we provide an example metadata file which helps describe the data associated with the tracking information for each individual bird. Users can adapt this example template as required. NOTE: To assist upload of your data to the Seabird Tracking Database, please ensure that entries in your relevant fields match the format used in the STDB. Review the data submission instructions indicated above for further guidance. ## Load the relevant metadata file - reading xlsx files can be fiddly - may require different packages #df_meta &lt;- read_xlsx(&quot;./data-testing/tracking-data/Puffinus-yelkouan-metadata/PUFYEL-Z-Metadata.xlsx&quot;, # sheet = &quot;Sheet1&quot;) df_meta &lt;- read.xlsx(file=&quot;./data-testing/tracking-data/Puffinus-yelkouan-metadata/PUFYEL-Z-Metadata.xlsx&quot;, sheetName=&quot;Sheet1&quot;) ## View the contents of the metadata file head(data.frame(df_meta),2) ## data_co.owners dataset_name ## 1 BIOM-Croatia, name surname PUFYEL-Z-GPS-Chick-rearing-2019-2020 ## 2 BIOM-Croatia, name surname PUFYEL-Z-GPS-Chick-rearing-2019-2020 ## species common_name bird_id site_location ## 1 Puffinus yelkouan Yelkouan Shearwater 19_Tag17600_Z-9 Lastovo SPA ## 2 Puffinus yelkouan Yelkouan Shearwater 19_Tag17604_Z-7 Lastovo SPA ## colony_code colony_latitude colony_longitude sex age_deployment_start ## 1 Z 42.774893 16.875649 unknown adult ## 2 Z 42.774893 16.875649 unknown adult ## breed_stage_deployment_start tracking_device_type ## 1 chick-rearing GPS ## 2 chick-rearing GPS ## tracking_device_model tracking_data_interpolation ## 1 PathTrack nanoFix GPS/UHF transmitters no ## 2 PathTrack nanoFix GPS/UHF transmitters no ## device_deployment_date_UTC device_deployment_time_UTC ## 1 dd/mm/yyyy hh:mm:ss AM/PM ## 2 dd/mm/yyyy hh:mm:ss AM/PM ## device_retrieval_rate_UTC device_retrieval_time_UTC deployment_mass_kg ## 1 dd/mm/yyyy hh:mm:ss AM/PM 0.41 ## 2 dd/mm/yyyy hh:mm:ss AM/PM 0.41 ## retrieval_mass_kg other_1 other_2 aux_file_1 aux_file_2 notes ## 1 0.42 bloods isotopes images tdr any relevant details ## 2 0.42 bloods isotopes images tdr any relevant details Check how many distinct entries you have. This number should match that of the number of unique birds tagged as part of this relevant dataset. ## Check how many distinct entries you have nrow(df_meta) ## [1] 34 25.8.1.3 Obtain point data file for “Data points” level information required for STDB First remind yourself of what the template STDB format looks like: head(data.frame(stdb.df.template),2) ## [1] BirdId Sex Age Breed.Stage TrackId ## [6] DateGMT TimeGMT Latitude Longitude Equinox ## [11] ArgosQuality ## &lt;0 rows&gt; (or 0-length row.names) And also consider what your data looks like: head(track.df,2) ## day month year hour minute second satellites latitude longitude altitude ## 1 24 5 19 0 49 9 5 42.811528 16.885531 -1.50 ## 2 24 5 19 1 9 3 5 42.812029 16.886907 5.25 ## time_offset accuracy voltage colony_code bird_id ## 1 2.910 4.70376e-07 4.12 Z 19_Tag17600_Z-9 ## 2 2.795 9.25368e-07 4.08 Z 19_Tag17600_Z-9 ## dttm deploy_year ## 1 2019-05-24 00:49:09 2019 ## 2 2019-05-24 01:09:03 2019 Then align own data with input format required by STDB. Do this by using your supporting metadata. REMINDER: Within the Seabird Tracking Database template, you should recognise the options available to specify arguments within some fields. e.g. When specifying Age, this can only be specified as: adult, immature, juvenile fledgling, OR, unknown. Inputs for fields are case sensitive. The below code primarily is based around three functions in R: select mutate relocate Understand how these work if needed. NOTE: You will need to change the names of your columns if they differ to the example data below. 25.8.1.3.1 Timestamp column A common problem many people encounter when learning to analyse animal tracking data is dealing with the column that relates to the timestamp of the tracking device. Typically, this information will be stored as a date and time - in a single column - from tracking devices. Timestamps typically need to be in the format of a POSIXct object. The parse_date function from the parsedate package, attempts to provide a simple option for standardising timestamp data which can come in multiple different formats. Understand and review the requirements of timestampe data for processing animal tracking data if required. ## Use the parse_date function to try and standardise a timestamp column #str(track.df$dttm) track.df$dttm &lt;- parse_date(track.df$dttm) #str(track.df$dttm) Continue with preparing data ## First, select relevant columns of information from your existing datapoint information needed to match the STDB format. df_stdb &lt;- track.df %&gt;% dplyr::select(bird_id, dttm, latitude, longitude) ## Then, modify and create relevant columns of information - where you have these in your data - to align with STDB format. ## the mutate functions allows you to add a new column of information. ## add the new columns and rename the object to a more standardised name. df_stdb &lt;- df_stdb %&gt;% dplyr::mutate(BirdId = bird_id, TrackId = bird_id, DateGMT = date(dttm), TimeGMT = format(df_stdb$dttm, format = &quot;%H:%M:%S&quot;), Latitude = latitude, Longitude = longitude, Equinox = NA, ArgosQuality = NA) %&gt;% ## remove the original columns (note the minus sign &quot;-&quot; in front of each column name you are removing) dplyr::select(-bird_id, -dttm, -latitude, -longitude) ## Now GET THE relevant metadata information for your tracking data &quot;datapoints&quot; information ## Ensure that your link column has the same name (in this case: it is the BirdID column above) df_meta_points &lt;- df_meta %&gt;% ## select the relevant columns dplyr::select(bird_id, sex, age_deployment_start, breed_stage_deployment_start) %&gt;% ## rename the columns if need be to match the format of the STDB rename(BirdId = bird_id, Sex = sex, Age = age_deployment_start, Breed.Stage = breed_stage_deployment_start) ## Now bind the relevant metadata onto your datapoints data #head(df_stdb,2) df_stdb &lt;- left_join(df_stdb, df_meta_points, by = &quot;BirdId&quot;) ## review the bind worked #head(df_stdb,2) ## Reorder the column names to match the format of the STDB df_stdb &lt;- df_stdb %&gt;% relocate(BirdId, Sex, Age, Breed.Stage, TrackId, DateGMT, TimeGMT, Latitude, Longitude, Equinox, ArgosQuality) 25.8.1.4 Review of the INPUT format for the Seabird Tracking Database ## Compare your data, to the STDB data template head(df_stdb,2) ## BirdId Sex Age Breed.Stage TrackId DateGMT ## 1 19_Tag17600_Z-9 unknown adult chick-rearing 19_Tag17600_Z-9 2019-05-24 ## 2 19_Tag17600_Z-9 unknown adult chick-rearing 19_Tag17600_Z-9 2019-05-24 ## TimeGMT Latitude Longitude Equinox ArgosQuality ## 1 00:49:09 42.811528 16.885531 NA NA ## 2 01:09:03 42.812029 16.886907 NA NA head(data.frame(stdb.df.template)) ## [1] BirdId Sex Age Breed.Stage TrackId ## [6] DateGMT TimeGMT Latitude Longitude Equinox ## [11] ArgosQuality ## &lt;0 rows&gt; (or 0-length row.names) For the columns highlighted above, you may notice a few things: BirdId, and TrackId, are specified with the same code. This is because when data is formatted to align with the format of the STDB: we have a code that relates to the bird that was tracked (BirdId) we have a unique code that relates to each trip undertaken by the bird, when multiple trips are recorded (TrackId). However, it is often the case that users do not provide data which has been pre-split into unique trips. Therefore, it is often the case that all entries relating to TrackId match that of BirdId Equinox and ArgosQuality are both specified as NA. This is because our data relates to GPS data which does not have an ArgosQuality estimate (typical of PTT devices) or a measure relating to the Equinox (typical of GLS devices). see the Seabird Tracking Database data template for examples of how to specify Equinox and ArgosQuality when necessary. 25.8.2 INPUT STDB format: saving You should now have a key file: A single file (a data frame called df_stdb) with all your data standardised into a common format. The common format of your data should reflect that of the INPUT files associated with uploading data to the Seabird Tracking Database. PLEASE NOTE: While it is not mandatory to upload your data to the Seabird Tracking Database to perform analyses outlined in this toolkit, we greatly encourage users to do so given the many benefits of curating data in centralised repositories. ## Save the output file write.csv(df_stdb, paste0(&quot;./data-testing/tracking-data/&quot;, species.name, &quot;-&quot;,colony.name,&quot;-tracking-STDB-input.csv&quot;), row.names = F) 25.9 OUTPUT format: Seabird Tracking Database Formatting data to align with the input format of the seabird tracking database supports your ability to curate your data in a secure online repository. Typically though, the data file one might use for analysis, will reflect the output format of data from the seabird tracking database. Here, instead of requiring users to upload data and then download again, we provide code to convert data from the input format of the seabird tracking database to the output format. 25.9.1 Load STDB output template Load and view the structure of the data according to the output format of the STDB. ## Load the template stdb.df.template.output &lt;- read.csv(&quot;./data-testing/tracking-data-stdb/Template_Datapoints_Output_Format.csv&quot;) ## View the column names of the template head(stdb.df.template.output) ## [1] dataset_id scientific_name common_name site_name ## [5] colony_name lat_colony lon_colony device ## [9] bird_id track_id original_track_id age ## [13] sex breed_stage breed_status date_gmt ## [17] time_gmt latitude longitude argos_quality ## [21] equinox ## &lt;0 rows&gt; (or 0-length row.names) 25.9.2 Convert data to STDB output template Converting data to the output format of the STDB in this tutorial requires two things: A metadata file aligned to the format provided in the example earlier A single data frame matching the input format for the STDB (as created above) ## First, convert the basis of the input format to the output format. ## Essentially, you are just changing columns names here to match the output format df_stdb_output &lt;- df_stdb %&gt;% dplyr::select(bird_id = BirdId, sex = Sex, age = Age, breed_stage = Breed.Stage, track_id = TrackId, date_gmt = DateGMT, time_gmt = TimeGMT, latitude = Latitude, longitude = Longitude, equinox = Equinox, argos_quality = ArgosQuality) ## Second, get the relevant metadata from your metadata file ## Here you are selecting the key metadata, and renaming columns accordingly ## If your columns names differ, you will need to change the relevant inputs here. df_meta_output &lt;- df_meta %&gt;% dplyr::select(bird_id = bird_id, scientific_name = species, common_name = common_name, site_name = site_location, colony_name = colony_code, lat_colony = colony_latitude, lon_colony = colony_longitude, device = tracking_device_type) ## Third, some columns for the STDB output are populated automatically when uploading data ## Here we create the necessary columns of STDB metadata for the purpose of the tutorial, but we populate ## the columns with dummy data only. df_meta_output &lt;- df_meta_output %&gt;% mutate(dataset_id = &quot;populated-upon-upload-STDB&quot;, original_track_id = &quot;populated-upon-upload-STDB&quot;, breed_status = &quot;populated-upon-upload-STDB&quot;) ## Next, we bind the relevant metadata onto the overall tracking data dataframe df_stdb_output &lt;- left_join(df_stdb_output, df_meta_output, by = &quot;bird_id&quot;) ## Finally, we reorder the columns to match the output format of the STDB df_stdb_output &lt;- df_stdb_output %&gt;% relocate(colnames(stdb.df.template.output)) ## review and compare the column names and order between your data and STDB output example data.frame(stdb.output.example = colnames(stdb.df.template.output), data.example = colnames(df_stdb_output)) ## stdb.output.example data.example ## 1 dataset_id dataset_id ## 2 scientific_name scientific_name ## 3 common_name common_name ## 4 site_name site_name ## 5 colony_name colony_name ## 6 lat_colony lat_colony ## 7 lon_colony lon_colony ## 8 device device ## 9 bird_id bird_id ## 10 track_id track_id ## 11 original_track_id original_track_id ## 12 age age ## 13 sex sex ## 14 breed_stage breed_stage ## 15 breed_status breed_status ## 16 date_gmt date_gmt ## 17 time_gmt time_gmt ## 18 latitude latitude ## 19 longitude longitude ## 20 argos_quality argos_quality ## 21 equinox equinox 25.9.3 OUTPUT STDB format: saving You should now have another key file: df_stdb_output The format of this file matches that of the output format of the STDB. i.e. the format of the data when you download it from the STDB. NOTE: if your dataset is already hosted on the Seabird Tracking Database, you can download it from there directly and skip the steps above. ## Save the output file write.csv(df_stdb_output, paste0(&quot;./data-testing/tracking-data/&quot;, species.name, &quot;-&quot;,colony.name,&quot;-tracking-STDB-output.csv&quot;), row.names = F) "],["tracking-data-plotting-tracks-and-reviewing-tabular-data.html", "26 Tracking data: Plotting tracks and reviewing tabular data 26.1 What this chapter covers: 26.2 Where you can get example data for the chapter: 26.3 Load packages 26.4 Define object names for chapter 26.5 Load file (or file created from previous chapter) 26.6 Explore the tabular data 26.7 Review of summary output 26.8 Arrange data and remove duplicate entries 26.9 Visualise all the location data 26.10 Review of overall plot for all data points 26.11 Save all the location data as a shapefile 26.12 Save all the location data as a plot 26.13 Visualise individual animal tracks 26.14 When to remove or salvage data from a tracked individual(s)", " 26 Tracking data: Plotting tracks and reviewing tabular data Analyses outlined in this chapter were performed in R version 4.3.2 (2023-10-31 ucrt) This chapter was last updated on 2024-02-23 26.1 What this chapter covers: Tabular data review: Review basic details about your data. i.e. what information is in each column of data Spatial data review: Plot your data and perform some basic checks to make sure it is formatted correctly for further analyses Consideration: When to remove or salvage data from a tracked individual(s) 26.2 Where you can get example data for the chapter: This tutorial uses example data from a project led by the BirdLife International partner in Croatia: BIOM The citation for this data is: Zec et al. 2023 Example data is available upon request A description of the example data is given in a separate chapter 26.3 Load packages Load required R packages for use with codes in this chapter: If the package(s) fails to load, you will need to install the relevant package(s). ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Load libraries -------------------------------------------------------------- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## sf package for spatial data analyses (i.e. vector files such as points, lines, polygons) library(sf) ## Tidyverse for data manipulation library(tidyverse) ## ggplot2 for plotting opionts library(ggplot2) ## rnaturalearth package for geographic basemaps in R library(rnaturalearth) ## leaflet package for interactive maps in R library(leaflet) ## lubridate for date time library(lubridate) ## track2kba for the analysis of important site identification library(track2KBA) ## speed filter library(trip) ## linear interpolation library(adehabitatLT) ## library(raster) ## library(viridis) ## library(readxl) library(xlsx) 26.4 Define object names for chapter Typically, if your data follows the same format as the examples in the chapter (and previous chapters), then below should be the only thing(s) you need to change. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Specify projections / store needed CRS definitions as variables ---- ## SEE: https://epsg.io/ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## world - unprojected coordinates wgs84 &lt;- st_crs(&quot;EPSG:4326&quot;) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Source a relevant basemap (download / or load your own) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Source a world map from the rnaturalearth R package ## see details of function to change the type of map you get ## If you can&#39;t download this map - you may need to load a separate shapefile ## depicting a suitable basemap worldmap &lt;- rnaturalearth::ne_download(scale = &quot;large&quot;, type = &quot;countries&quot;, category = &quot;cultural&quot;, destdir = tempdir(), load = TRUE, returnclass = &quot;sf&quot;) ## Reading layer `ne_10m_admin_0_countries&#39; from data source ## `C:\\Users\\jonathan.handley\\AppData\\Local\\Temp\\Rtmp6L566o\\ne_10m_admin_0_countries.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 258 features and 168 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -180 ymin: -90 xmax: 180 ymax: 83.63410065 ## Geodetic CRS: WGS 84 26.5 Load file (or file created from previous chapter) ## Read the csv file of merged tracking data that follows the output / download format ## of the Seabird Tracking Database df_stdb_output &lt;- read.csv(&quot;./data-testing/tracking-data/Puffinus-yelkouan-Z-tracking-STDB-output.csv&quot;) 26.5.1 Simplify object names if need be Sometimes, you may have created different object names in previous scripts (R codes) and you may wish to simplify the names to a shorter name for the purpose of a new script. ## Copy the object and give it a new name df.stdb &lt;- df_stdb_output ## Remove the old object from your R environment rm(df_stdb_output) 26.6 Explore the tabular data This step can be particularly useful when you have not only combined data from a single species and colony, but when you have combined many datasets from many species and colonies. Before you plot any data, it can be a good idea to broadly explore the data. While you might know which species you tracked, and from which colonies, and from which years, it can often be worth checking over these (and other) aspects of your data. Checking the data helps refresh your view on what data you have, and also helps you pick up any errors that may have arisen when inputting data. ## Reminder on what the data looks like so far head(data.frame(df.stdb),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-24 00:49:09 42.811528 16.885531 ## 2 populated-upon-upload-STDB 2019-05-24 01:09:03 42.812029 16.886907 ## argos_quality equinox ## 1 NA NA ## 2 NA NA ## Review the main columns of data separately. This helps check for errors associated ## with data entry. E.g. perhaps you typed chick-rearing and CHICK-rearing. Because ## of the difference in lower-case vs. upper-case text, you might accidentally consider ## these as separate components of your dataset. ## the table function is useful to check the unique number of entries per unique input table(df.stdb$scientific_name) ## ## Puffinus yelkouan ## 11354 table(df.stdb$site_name) ## ## Lastovo SPA ## 11354 table(df.stdb$colony_name) ## ## Z ## 11354 table(df.stdb$breed_status) ## ## populated-upon-upload-STDB ## 11354 table(df.stdb$breed_stage) ## ## chick-rearing ## 11354 table(df.stdb$age) ## ## adult ## 11354 table(df.stdb$sex) ## ## unknown ## 11354 ## Summarise the data by species, site_name, colony_name, year, breed_status (if you have this), breed_stage, age, sex. ## First we add a new year column by splitting the date column so we can get information about years df_overview &lt;- df.stdb %&gt;% mutate(year = year(date_gmt)) %&gt;% ## then we group the data by relevant columns group_by(scientific_name, site_name, colony_name, year, #breed_status, # if you downloaded data from the STDB, you should have this info. breed_stage, age, sex) %&gt;% ## then we continue to summarise by the distinct number of entries per group summarise(n_birds = n_distinct(bird_id), n_tracks = n_distinct(track_id)) ## review the summary output df_overview ## # A tibble: 2 × 9 ## # Groups: scientific_name, site_name, colony_name, year, ## # breed_stage, age [2] ## scientific_name site_name colony_name year breed_stage age sex n_birds ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Puffinus yelkouan Lastovo S… Z 2019 chick-rear… adult unkn… 19 ## 2 Puffinus yelkouan Lastovo S… Z 2020 chick-rear… adult unkn… 15 ## # ℹ 1 more variable: n_tracks &lt;int&gt; 26.7 Review of summary output From the summary output above we can see the following: scientific_name: we have tracking data from one species site_name: we have tracking data from one general site colony_name: we have tracking data from one colony year: data comes from between 2019 and 2020 breed_stage: all data relates to birds during the chick-rearing life-cycle stage. age and sex: data is from adult birds of unknown sex n_birds, n_tracks: because n_birds = n_tracks, it indicates that: either the tracking data from each individual bird has not been separated into unique trips (in which case it needs to be), or the tracking data from each individual bird is only representative of a single trip to sea (during the breeding period when birds may be exhibiting central place foraging behaviour) 26.8 Arrange data and remove duplicate entries Once you have formatted your data into a standardised format and ensured that parts of your data are inputted correctly, it is also worth ensuring your data is ordered (arranged) correctly chronologically. An artifact of manipulating spatial data is that sometimes the data can become un-ordered with respect to time, or, given the way various devices interact with satellites, you can also end up with duplicated entries according to timestamps. This can be a first problem, causing your track to represent unrealistic movement patterns of the animal. We need to ensure our data is ordered correctly and also remove any duplicate timestamps. ## review your OVERALL data again head(data.frame(df.stdb),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-24 00:49:09 42.811528 16.885531 ## 2 populated-upon-upload-STDB 2019-05-24 01:09:03 42.812029 16.886907 ## argos_quality equinox ## 1 NA NA ## 2 NA NA (str(df.stdb)) ## &#39;data.frame&#39;: 11354 obs. of 21 variables: ## $ dataset_id : chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ scientific_name : chr &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; ... ## $ common_name : chr &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; ... ## $ site_name : chr &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; ... ## $ colony_name : chr &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; ... ## $ lat_colony : num 42.8 42.8 42.8 42.8 42.8 ... ## $ lon_colony : num 16.9 16.9 16.9 16.9 16.9 ... ## $ device : chr &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; ... ## $ bird_id : chr &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## $ track_id : chr &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## $ original_track_id: chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ age : chr &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; ... ## $ sex : chr &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; ... ## $ breed_stage : chr &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; ... ## $ breed_status : chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ date_gmt : chr &quot;2019-05-24&quot; &quot;2019-05-24&quot; &quot;2019-05-24&quot; &quot;2019-05-24&quot; ... ## $ time_gmt : chr &quot;00:49:09&quot; &quot;01:09:03&quot; &quot;01:29:03&quot; &quot;01:49:09&quot; ... ## $ latitude : num 42.8 42.8 42.8 42.8 42.8 ... ## $ longitude : num 16.9 16.9 16.9 16.9 16.9 ... ## $ argos_quality : logi NA NA NA NA NA NA ... ## $ equinox : logi NA NA NA NA NA NA ... ## NULL ## merge the date and time columns df.stdb$dttm &lt;- with(df.stdb, ymd(date_gmt) + hms(time_gmt)) ## first check how many duplicate entries you may have. If there are many, it ## is worth exploring your data further to understand why. n_duplicates &lt;- df.stdb %&gt;% group_by(bird_id, track_id) %&gt;% arrange(dttm) %&gt;% dplyr::filter(duplicated(dttm) == T) ## review how many duplicate entries you may have. Print the message: print(paste(&quot;you have &quot;,nrow(n_duplicates), &quot; duplicate records in a dataset of &quot;, nrow(df.stdb), &quot; records.&quot;, sep =&quot;&quot;)) ## [1] &quot;you have 11 duplicate records in a dataset of 11354 records.&quot; ## remove duplicates entries if no further exploration is deemed necessary df.stdb &lt;- df.stdb %&gt;% ## first group data by individual animals and unique track_ids group_by(bird_id, track_id) %&gt;% ## then arrange by timestamp arrange(dttm) %&gt;% ## then if a timestamp is duplicated (TRUE), then don&#39;t select this data entry. ## only select entries where timestamps are not duplicated (i.e. FALSE) dplyr::filter(duplicated(dttm) == F) 26.9 Visualise all the location data Using the leaflet package in R, you can easily visualise your tracking data interactively within RStudio. Note though, if you have very large datasets, this option may not always work smoothly. What should you look for when visualising the raw data? * Are your locations in realistic places? * Have you perhaps mixed up the latitude and longitude columns? * Does your data cross the international date line? Do you know how to deal with this? * Will you need to remove sections of the data that do not represent a time when the animal was tagged? (e.g. perhaps you set the device to start recording locations before deploying on the animal. So the tag might have recorded while you were travelling to the deployment location. Therefore, removing these sections of the track will facilitate your overall analysis.) ## review your OVERALL data again #head(data.frame(df.stdb),2) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## visualise all data ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## number of datapoints nrow(df.stdb) ## [1] 11343 ## interactive plot map.alldata &lt;- leaflet() %&gt;% ## start leaflet plot ## select background imagery addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies addCircleMarkers(data = df.stdb, ## size of points radius = 3, ## colour of points fillColor = &quot;cyan&quot;, ## transparency of points fillOpacity = 0.5, ## set stroke = F to remove borders around points stroke = F) ## generate the plot map.alldata 26.10 Review of overall plot for all data points Based on the interactive plot, you can see that generally the data looks good. Generally, all the locations are in the Adriatic Sea area (something we would anticipate based on what we know about Yelkouan Shearwaters breeding in Croatia). We can conclude the following: Locations appear to be in realistic places. It’s unlikely that we have mixed up the latitude and longitude columns. The data does not cross the international date line. Regarding removing sections of the data that do not represent a time when the animal was tagged: Later filtering steps may remove these parts of the track if locations are near the vicinity of the colony (see details of the tripSplit() function). However, if there are broader location data associated with these types of locations, you will need to remove these sections of the track. For example, if the device remained on and you continued to receive location data while you were travelling away from a site. You might need to remove this data with some more manual data cleaning steps. 26.11 Save all the location data as a shapefile Visualising all the location data in R can be a simpler starting point. You may also want to save this data as a shapefile (.shp) for viewing in GIS software such as QGIS or ArcGIS. Note: saving all data as a single shapefile can be a memory intensive task (i.e. if you have a lot of data, then your computer might take a long time to save the file, or the file will be big and slow to work with) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## First add a simplified unique id and create the sf spatial object ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Review data head(data.frame(df.stdb),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## 2 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-01 21:40:41 42.815077 16.890582 ## 2 populated-upon-upload-STDB 2019-05-01 22:00:41 42.837505 16.897495 ## argos_quality equinox dttm ## 1 NA NA 2019-05-01 21:40:41 ## 2 NA NA 2019-05-01 22:00:41 ## add a simplified animal ID column - a simple number for each unique animal tracked df.stdb$bird_id_num &lt;- as.numeric(factor(df.stdb$bird_id, levels = unique(df.stdb$bird_id))) ## Review data again (tail function prints the end of the dataframe so you can ## check if the last unique number matches the number of animals you tracked.) head(data.frame(df.stdb),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## 2 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-01 21:40:41 42.815077 16.890582 ## 2 populated-upon-upload-STDB 2019-05-01 22:00:41 42.837505 16.897495 ## argos_quality equinox dttm bird_id_num ## 1 NA NA 2019-05-01 21:40:41 1 ## 2 NA NA 2019-05-01 22:00:41 1 tail(data.frame(df.stdb),2) ## dataset_id scientific_name common_name ## 11342 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater ## 11343 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater ## site_name colony_name lat_colony lon_colony device bird_id ## 11342 Lastovo SPA Z 42.774893 16.875649 GPS 20_Tag40118_Z-175 ## 11343 Lastovo SPA Z 42.774893 16.875649 GPS 20_Tag40118_Z-175 ## track_id original_track_id age sex breed_stage ## 11342 20_Tag40118_Z-175 populated-upon-upload-STDB adult unknown chick-rearing ## 11343 20_Tag40118_Z-175 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 11342 populated-upon-upload-STDB 2020-06-10 16:32:49 43.236809 16.543461 ## 11343 populated-upon-upload-STDB 2020-06-10 16:52:51 43.190585 16.343547 ## argos_quality equinox dttm bird_id_num ## 11342 NA NA 2020-06-10 16:32:49 27 ## 11343 NA NA 2020-06-10 16:52:51 27 ## create the sf spatial object df.stdb_sf &lt;- df.stdb %&gt;% ## first create new columns of lon and lat again so you keep this location ## information in tabular format. mutate(lon_device = longitude, lat_device = latitude) %&gt;% ## then convert object to sf spatial object st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = wgs84) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Save raw tracking data as shapefile for viewing in GIS software ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Option allows for multispecies data ## Or the loop will only run once if you have single species data for(i in unique(df.stdb$scientific_name)){ ## subset the data taking the track information for each unique species temp_species &lt;- df.stdb_sf %&gt;% dplyr::filter(scientific_name == i) ## create new folder within current working directory where you will save data ## first create the name of the species and the file path you need ## also use gsub to replace spaces within character strings (words) with a &quot;-&quot; species_name &lt;- gsub(&quot; &quot;, &quot;-&quot;, temp_species$scientific_name[1]) ## print the name for checking print(species_name) ## then create the new folder within current working directory path_to_folder &lt;- paste(&quot;./data-testing/tracking-data/&quot;, species_name,&quot;-shapefiles-all-tracks&quot;, sep=&quot;&quot;) ## print the file path name for checking print(path_to_folder) ## Check if folder exists, and if it does not, then make a new folder if (!file.exists(path_to_folder)) { # If it does not exist, create a new folder dir.create(path_to_folder) print(paste(&quot;Created folder:&quot;, path_to_folder)) } else { # do nothing, but let us know the folder exists already print(paste(&quot;Folder already exists:&quot;, path_to_folder)) } ## write the spatial data as a shapefile ## NOTE: For some GIS software, column names will be abbreviated upon saving ## NOTE: If you have very long file paths, this operation may fail. One solution ## is to save the shapefile elsewhere. Another solution is to instead save the file ## as a geopackage (.gpkg): simply replace the .shp text below with .gpkg st_write(df.stdb_sf, paste(path_to_folder,&quot;/&quot;, species_name, &quot;_AllTracks.shp&quot;, sep = &quot;&quot;), delete_layer = TRUE) ## remove the temporary file at the end of each loop rm(temp_species) } 26.12 Save all the location data as a plot This is a simple plot to look at all the point location data. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Save raw tracking data as simple plot ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Option allows for multispecies data ## Or the loop will only run once if you have single species data for(i in unique(df.stdb$scientific_name)){ ## subset the data taking the track information for each unique species temp_species &lt;- df.stdb_sf %&gt;% dplyr::filter(scientific_name == i) ## create new folder within current working directory where you will save data ## first create the name of the species and the file path you need ## also use gsub to replace spaces within character strings (words) with a &quot;-&quot; species_name &lt;- gsub(&quot; &quot;, &quot;-&quot;, temp_species$scientific_name[1]) ## print the name for checking print(species_name) ## then create the new folder within current working directory path_to_folder &lt;- paste(&quot;./data-testing/tracking-data/&quot;, species_name,&quot;-plots-all-tracks&quot;, sep=&quot;&quot;) ## print the file path name for checking print(path_to_folder) ## Check if folder exists, and if it does not, then make a new folder if (!file.exists(path_to_folder)) { # If it does not exist, create a new folder dir.create(path_to_folder) print(paste(&quot;Created folder:&quot;, path_to_folder)) } else { # do nothing, but let us know the folder exists already print(paste(&quot;Folder already exists:&quot;, path_to_folder)) } ## plot track information for each unique species plot_alltracks &lt;- ggplot() + ## Use the world map data as the underlying basemap geom_sf(data = worldmap, fill = &quot;grey&quot;) + ## Add the point data as transparent cyan circles geom_point(data = df.stdb_sf, aes(x = lon_device, y = lat_device), color = &quot;cyan&quot;, alpha = 0.5) + ## plot the basemap again, but this time superimpose only the country borders over the point data ## this is to help you see better which points might obviously be over land. geom_sf(data = worldmap, fill = NA, color = &quot;black&quot;) + ## Set the bounding box to only include the point locations coord_sf(xlim = range(df.stdb_sf$lon_device), ylim = range(df.stdb_sf$lat_device)) + ## Customize the x and y axis labels labs(x = &quot;Longitude&quot;, y = &quot;Latitude&quot;) + ## add a title to the plot ggtitle(paste(species_name, &quot;\\n&quot;, &quot;points-all-animals&quot;,sep=&quot;&quot;)) + theme(plot.title = element_text(hjust = 0.5)) ## the plot plot_alltracks ## save the plot ggsave(paste(path_to_folder, &quot;/&quot;, species_name, &quot;_all-points.png&quot;, sep = &quot;&quot;), plot_alltracks, ## when units in mm, then width = 160, height = 160, dpi = 300, units = &quot;mm&quot;) ## remove the temporary file at the end of each loop rm(temp_species) } 26.13 Visualise individual animal tracks Once you have reviewed the overall status of the tracking data you collected, it can be worth assessing the tracks of individual animals. This can give you a better idea of the quality of the data for each individual. Visualising tracking data from individual animals can help you understand which data you might remove, or which data you might try and salvage. Depending on the amount of data you have, you can often initially perform a static exploration of tracks from each individual (i.e. a simple plot of tracks from each individual), followed by an interactive exploration of tracks from all individuals, or only data from those individuals where interactive exploration is deemed necessary. Below, outlines options for visualising individual animal tracks. 26.13.1 Denote beginning and end of tracks for individual animals entire track ## reminder on data structure head(data.frame(df.stdb_sf),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## 2 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt argos_quality equinox ## 1 populated-upon-upload-STDB 2019-05-01 21:40:41 NA NA ## 2 populated-upon-upload-STDB 2019-05-01 22:00:41 NA NA ## dttm bird_id_num lon_device lat_device ## 1 2019-05-01 21:40:41 1 16.890582 42.815077 ## 2 2019-05-01 22:00:41 1 16.897495 42.837505 ## geometry ## 1 POINT (16.890582 42.815077) ## 2 POINT (16.897495 42.837505) head(data.frame(df.stdb),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## 2 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-01 21:40:41 42.815077 16.890582 ## 2 populated-upon-upload-STDB 2019-05-01 22:00:41 42.837505 16.897495 ## argos_quality equinox dttm bird_id_num ## 1 NA NA 2019-05-01 21:40:41 1 ## 2 NA NA 2019-05-01 22:00:41 1 #head(data.frame(df.stdb2),2) ## add a column indicating start and end of tracks for each individual animal df.stdb_sf &lt;- df.stdb_sf %&gt;% group_by(bird_id_num) %&gt;% mutate(nlocs = 1:length(bird_id_num)) %&gt;% mutate(track_segment = if_else(nlocs &lt;= 10, &quot;track.start&quot;,&quot;track.journey&quot;)) %&gt;% ## note: if you have a track with less than 20 points, then you will overwrite ## some of the previous data. mutate(track_segment = if_else(nlocs %in% (length(bird_id_num)-9):(length(bird_id_num)),&quot;track.end&quot;,track_segment)) %&gt;% ## add a column indicating colour for start and end of tracks ## colours from: https://colorbrewer2.org/#type=qualitative&amp;scheme=Set2&amp;n=3 mutate(track_colour = if_else(nlocs &lt;= 10, &quot;#66c2a5&quot;,&quot;#8da0cb&quot;)) %&gt;% mutate(track_colour = if_else(nlocs %in% (length(bird_id_num)-9):(length(bird_id_num)),&quot;#fc8d62&quot;,track_colour)) 26.13.2 Save individual tracks as static plots A simple plot to look at all the point location data for each individual tracked. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Save raw tracking data for each individual as a static plot ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## reminder on data structure head(data.frame(df.stdb_sf),2) for(i in 1:max(df.stdb_sf$bird_id_num)){ ## subset the data taking the track information for each unique bird tagged temp_individual &lt;- df.stdb_sf %&gt;% dplyr::filter(bird_id_num == i) ## create new folder (if needed) within current working directory where you will save data ## first create the name of the species and the file path you need ## also use gsub to replace spaces within character strings (words) with a &quot;-&quot; species_name &lt;- gsub(&quot; &quot;, &quot;-&quot;, temp_individual$scientific_name[1]) ## print the name for checking print(species_name) ## then create the new folder within current working directory path_to_folder &lt;- paste(&quot;./data-testing/tracking-data/&quot;, species_name, &quot;-plots-individual-tracks&quot;, sep=&quot;&quot;) ## print the file path name for checking print(path_to_folder) ## Check if folder exists, and if it does not, then make a new folder if (!file.exists(path_to_folder)) { # If it does not exist, create a new folder dir.create(path_to_folder) print(paste(&quot;Created folder:&quot;, path_to_folder)) } else { # do nothing, but let us know the folder exists already print(paste(&quot;Folder already exists:&quot;, path_to_folder)) } ## get animal id for naming plots animal_id &lt;- gsub(&quot; &quot;, &quot;-&quot;, temp_individual$bird_id[1]) ## plot track information for each unique species plot_individual_tracks &lt;- ggplot() + ## Use the world map data as the underlying basemap geom_sf(data = worldmap, fill = &quot;grey&quot;) + ## Add the point data as transparent cyan circles #geom_point(data = temp_individual, aes(x = lon_device, y = lat_device), color = &quot;cyan&quot;, alpha = 0.5) + ## Add the point data - get colours from object #geom_point(data = temp_individual, aes(x = lon_device, y = lat_device, color = track_colour), alpha = 0.5) + ## Add the journey locations geom_point(data = subset(temp_individual, track_segment == &quot;track.journey&quot;), aes(x = lon_device, y = lat_device, color = track_colour), alpha = 0.5) + ## Add the start locations geom_point(data = subset(temp_individual, track_segment == &quot;track.start&quot;), aes(x = lon_device, y = lat_device, color = track_colour), alpha = 0.5) + ## Add the end locations geom_point(data = subset(temp_individual, track_segment == &quot;track.end&quot;), aes(x = lon_device, y = lat_device, color = track_colour), alpha = 0.5) + ## plot the basemap again, but this time superimpose only the country borders over the point data ## this is to help you see better which points might obviously be over land. geom_sf(data = worldmap, fill = NA, color = &quot;black&quot;) + ## Set the bounding box to only include the point locations coord_sf(xlim = range(temp_individual$lon_device), ylim = range(temp_individual$lat_device)) + ## Customize the x and y axis labels labs(x = &quot;Longitude&quot;, y = &quot;Latitude&quot;) + ## add a title to the plot ggtitle(paste(&quot;points-individual:&quot;,&quot;\\n&quot;, animal_id, sep=&quot;&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + ## remove legend theme(legend.position = &quot;none&quot;) ## the plot plot_individual_tracks ## save the plot ggsave(paste(path_to_folder, &quot;/&quot;, animal_id, &quot;_points.png&quot;, sep = &quot;&quot;), plot_individual_tracks, ## when units in mm, then width = 160, height = 160, dpi = 300, units = &quot;mm&quot;) ## print a loop progress message print(paste(&quot;Loop &quot;, i, &quot; of &quot;, max(df.stdb_sf$bird_id_num), sep = &quot;&quot;)) ## remove the temporary file at the end of each loop rm(temp_individual) } 26.13.3 Save individual tracks as shapefiles ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Save raw tracking data for each individual as shapefile for viewing in GIS software ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## reminder on data structure head(data.frame(df.stdb_sf),2) for(i in 1:max(df.stdb_sf$bird_id_num)){ ## subset the data taking the track information for each unique bird tagged temp_individual &lt;- df.stdb_sf %&gt;% dplyr::filter(bird_id_num == i) ## create new folder (if needed) within current working directory where you will save data ## first create the name of the species and the file path you need ## also use gsub to replace spaces within character strings (words) with a &quot;-&quot; species_name &lt;- gsub(&quot; &quot;, &quot;-&quot;, temp_individual$scientific_name[1]) ## print the name for checking print(species_name) ## then create the new folder within current working directory path_to_folder &lt;- paste(&quot;./data-testing/tracking-data/&quot;, species_name,&quot;-shapefiles-individual-tracks&quot;, sep=&quot;&quot;) ## print the file path name for checking print(path_to_folder) ## Check if folder exists, and if it does not, then make a new folder if (!file.exists(path_to_folder)) { # If it does not exist, create a new folder dir.create(path_to_folder) print(paste(&quot;Created folder:&quot;, path_to_folder)) } else { # do nothing, but let us know the folder exists already print(paste(&quot;Folder already exists:&quot;, path_to_folder)) } ## write the spatial data. Label it by species and bird_id st_write(temp_individual, paste(path_to_folder, &quot;/tracks-individual-animals&quot;, species_name, &quot;_&quot;, temp_individual$bird_id[1], &quot;.shp&quot;, sep = &quot;&quot;), delete_layer = T) ## print a loop progress message print(paste(&quot;Loop &quot;, i, &quot; of &quot;, max(df.stdb_sf$bird_id_num), sep = &quot;&quot;)) ## remove the temporary file at the end of each loop rm(temp_individual) } 26.14 When to remove or salvage data from a tracked individual(s) We would welcome further examples and guidance on this topic. In some cases, an entire track may be worth disregarding or trying to salvage. However, it often might be the case that only certain trips from the entire period an animal was tracked may be worth removing. Ultimately, which data you keep or remove for a respective analysis can be somewhat subjective. Critically: it is important to ensure that the data you do keep / use for an analysis is suited to the type of question you may be investigating with your data For example: If you were just looking at any potential area an animal might visit, then you may wish to keep all your data and simply provide a descriptive summary of the data. (so long as it has been cleaned for erroneous / incorrect locations) However, if you were investigating detailed movement patterns of an animal, then if you have many poor quality tracks recorded you may wish to remove these (e.g. big gaps in timestamps between consecutive data points, or many likely incomplete tracks). Ultimately, it may be the case that further data collection is required depending on the type of question you wish to answer of your data. A suitably designed sampling strategy and programming of tracking devices prior to deployment will ensure that you are able to answer the best possible question(s) of your data. "],["tracking-data-cleaning-tracking-data.html", "27 Tracking data: Cleaning tracking data", " 27 Tracking data: Cleaning tracking data Chapter under final construction Whether cleaning tracking data for the purposes of analyses outlined in this toolkit or not, many practitioners are seeking advice about how to clean and prepare animal tracking data for analyses. The chapter “Track2KBA - Central Place Foragers: Clean and summarise data for analysis” outlines some steps users can undertake to clean tracking data. However, we aim to include additional tutorial content that can support users clean and prepare animal tracking data for a wide variety of analyses. "],["track2kba-introduction.html", "28 Track2KBA: Introduction", " 28 Track2KBA: Introduction Analyses outlined in this chapter were performed in R version 4.3.2 (2023-10-31 ucrt) This chapter was last updated on 2024-02-23 BirdLife Marine Science Team showcasing the track2kba R package, at the 7th International Bio-Logging Science Symposium "],["track2kba---central-place-foragers-clean-and-summarise-data-for-analysis.html", "29 Track2KBA - Central Place Foragers: Clean and summarise data for analysis 29.1 What this chapter covers: 29.2 Outputs and assumptions of data within this chapter: 29.3 Where you can get example data for the chapter: 29.4 Load packages 29.5 Define object names for chapter 29.6 Load file (or file created from previous chapter) 29.7 dataGroup: prepare relevant grouping of data for analyses 29.8 dataGroup inspection: visual review 29.9 Arrange data and remove duplicate entries 29.10 Speed filter GPS data: remove erroneous location points 29.11 Speed filter PTT data: remove erroneous location points 29.12 Speed filter data review: plotting 29.13 Data cleaning for CPF: n_locs, sampling interval, interpolation 29.14 track2KBA: format data for use 29.15 track2KBA: Split tracks into trips 29.16 track2kba: What trip data to use (complete or incomplete trips) 29.17 track2KBA: Use only at-sea sections of trips 29.18 track2KBA: Number of locations filter 29.19 track2KBA: tripSummary() 29.20 track2KBA: Sampling interval assessment 29.21 track2KBA: Interpolating data for analysis 29.22 Save data", " 29 Track2KBA - Central Place Foragers: Clean and summarise data for analysis Analyses outlined in this chapter were performed in R version 4.3.2 (2023-10-31 ucrt) This chapter was last updated on 2024-02-23 29.1 What this chapter covers: Suggested steps to cleaning data from central place foraging animals (e.g. seabirds during the breeding period that regularly return to nests) Cleaning central place foraging data and preparing for the purpose of analysing the data using the Track2KBA R package Deriving basic summary statistics about tracks of central place foraging animals 29.2 Outputs and assumptions of data within this chapter: Two key outputs are derived: A data frame of tracking data which has had tracks split into individual trips. The trip data has been cleaned via a speed filter and linear interpolation. Only complete trips are kept for further analyses. A summary data frame of basic statistics about the tracking data A key assumption: The use of complete trips only does not bias final outcomes. 29.3 Where you can get example data for the chapter: This tutorial uses example data from a project led by the BirdLife International partner in Croatia: BIOM The citation for this data is: Zec et al. 2023 Example data is available upon request The example data: See chapter about merging tracking data A description of the example data is given in a separate chapter 29.4 Load packages Load required R packages for use with codes in this chapter: If the package(s) fails to load, you will need to install the relevant package(s). ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Load libraries -------------------------------------------------------------- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ &quot;Had to install R version: R version 4.2.2 (2022-10-31 ucrt) for aniMotum&quot; ## [1] &quot;Had to install R version: R version 4.2.2 (2022-10-31 ucrt) for aniMotum&quot; &quot;Animotum and CRAWL style interpolation in Appendix - not default comparison&quot; ## [1] &quot;Animotum and CRAWL style interpolation in Appendix - not default comparison&quot; ## Options to install aniMotum package for animal track interpolation ## aniMotum: https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14060 #install.packages(&#39;aniMotum&#39;, repos = c(&#39;https://ianjonsen.r-universe.dev&#39;, &#39;https://cloud.r-project.org&#39;)) # may need to install aniMotum after downloading using: devtools::install_local(package.zip) #install.packages(&#39;TMB&#39;, type = &#39;source&#39;) #library(&quot;aniMotum&quot;) ## sf package for spatial data analyses (i.e. vector files such as points, lines, polygons) library(sf) ## Tidyverse for data manipulation library(tidyverse) ## ggplot2 for plotting opionts library(ggplot2) ## rnaturalearth package for basemaps in R library(rnaturalearth) ## leaflet package for interactive maps in R #install.packages(&quot;leaflet&quot;) library(leaflet) ## library(purrr) library(furrr) #install.packages(&quot;track2KBA&quot;) library(track2KBA) ## for date time library(lubridate) ## for stats library(stats) ## speed filter library(trip) ## linear interpolation library(adehabitatLT) 29.5 Define object names for chapter Typically, if your data follows the same format as the examples in the chapter (and previous chapters), then below should be the only thing(s) you need to change. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Specify projections / store needed CRS definitions as variables ---- ## SEE: https://epsg.io/ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## world - unprojected coordinates # wgs84 &lt;- st_crs(&quot;EPSG:4326&quot;) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Source a relevant basemap (download / or load your own) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Source a world map from the rnaturalearth R package ## see details of function to change the type of map you get ## If you can&#39;t download this map - you may need to load a separate shapefile ## depicting a suitable basemap # worldmap &lt;- rnaturalearth::ne_download(scale = &quot;large&quot;, # type = &quot;countries&quot;, # category = &quot;cultural&quot;, # destdir = tempdir(), # load = TRUE, # returnclass = &quot;sf&quot;) 29.6 Load file (or file created from previous chapter) ## Read the csv file of merged tracking data that follows the output / download format ## of the Seabird Tracking Database df_stdb_output &lt;- read.csv(&quot;./data-testing/tracking-data/Puffinus-yelkouan-Z-tracking-STDB-output.csv&quot;) NOTE: The example data used here is in the format of data downloaded from the Seabird Tracking Database. Your own data might not follow this format. However, many of the steps outlined below should be readily adaptable to your data so long as you modify column names or respective inputs accordingly. 29.7 dataGroup: prepare relevant grouping of data for analyses See previous chapter which introduces the dataGroup concept - ensure your data is group accordingly when deriving a final output using the Track2KBA R package. ## Reminder on what the data looks like so far head(data.frame(df_stdb_output),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-24 00:49:09 42.811528 16.885531 ## 2 populated-upon-upload-STDB 2019-05-24 01:09:03 42.812029 16.886907 ## argos_quality equinox ## 1 NA NA ## 2 NA NA ## Review the main columns of data separately. This helps check for errors associated ## with data entry. E.g. perhaps you typed chick-rearing and CHICK-rearing. Because ## of the difference in lower-case vs. upper-case text, you might accidentally consider ## these as separate components of your dataset. ## the table function is useful to check the unique number of entries per unique input table(df_stdb_output$scientific_name) ## ## Puffinus yelkouan ## 11354 table(df_stdb_output$site_name) ## ## Lastovo SPA ## 11354 table(df_stdb_output$colony_name) ## ## Z ## 11354 table(df_stdb_output$breed_status) ## ## populated-upon-upload-STDB ## 11354 table(df_stdb_output$breed_stage) ## ## chick-rearing ## 11354 table(df_stdb_output$age) ## ## adult ## 11354 table(df_stdb_output$sex) ## ## unknown ## 11354 ## Summarise the data by species, site_name, colony_name, year, breed_status (if you have this), breed_stage, age, sex. ## First we add a new year column by splitting the date column so we can get information about years df_overview &lt;- df_stdb_output %&gt;% mutate(year = year(date_gmt)) %&gt;% ## then we group the data by relevant columns group_by(scientific_name, site_name, colony_name, year, #breed_status, # if you downloaded data from the STDB, you should have this info. breed_stage, age, sex, device) %&gt;% ## then we continue to summarise by the distinct number of entries per group summarise(n_birds = n_distinct(bird_id), n_tracks = n_distinct(track_id)) ## review the summary output df_overview ## # A tibble: 2 × 10 ## # Groups: scientific_name, site_name, colony_name, year, ## # breed_stage, age, sex [2] ## scientific_name site_name colony_name year breed_stage age sex device ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Puffinus yelkouan Lastovo SPA Z 2019 chick-rear… adult unkn… GPS ## 2 Puffinus yelkouan Lastovo SPA Z 2020 chick-rear… adult unkn… GPS ## # ℹ 2 more variables: n_birds &lt;int&gt;, n_tracks &lt;int&gt; 29.7.1 dataGroup: Defining the dataGroup for the tutorial From the summary above, we can see that we have data for: One species One colony adult birds only tracks from the chick-rearing period only all tracked with GPS devices tracked for two seasons [From preliminary data exploration, we decided to pool tracks from the two years given birds were utilising the same areas] [Insert Martin’s new paper about sample size / years of tracking data] dataGroup for the tutorial is therefore defined as: Adult Puffinus yelkouan, tracked from colony Z, during the chick-rearing period. See the separate chapter about defining your dataGroup for analyses for further details. 29.7.2 dataGroup: extracting data for the analyses Note, if you had already merged data for multiple species, colonies, or breeding stages, and you were using this data as your input file, here is where you would need to separate your data into unique dataGroups for further analyses. 29.8 dataGroup inspection: visual review Here, we visually inspect the overall data to double check it generally looks correct. A reminder on initial pre-filtering which may need to happen: What should you look for when visualising the raw data? * Are your locations in realistic places? * Have you perhaps mixed up the latitude and longitude columns? * Does your data cross the international date line? Do you know how to deal with this? * Will you need to remove sections of the data that do not represent a time when the animal was tagged? (e.g. perhaps you set the device to start recording locations before deploying on the animal. So the tag might have recorded while you were travelling to the deployment location. Therefore, removing these sections of the track will facilitate your overall analysis.) ## quick plot of all data for a quick overview dataGroup.plot &lt;- st_as_sf(df_stdb_output, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs=4326) # 4326 = geographic WGS84 plot(st_geometry(dataGroup.plot), cex = 0.5, pch = 1) ## number of datapoints nrow(df_stdb_output) ## [1] 11354 ## interactive plot leaflet() %&gt;% ## start leaflet plot addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies ## Colour accordingly. addCircleMarkers(data = df_stdb_output, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) 29.9 Arrange data and remove duplicate entries Once you have formatted your data into a standardised format and ensured that parts of your data is inputted correctly, it is also worth ensuring your data is ordered (arranged) correctly chronologically. An artifact of manipulating spatial data is that sometimes the data can become un-ordered with respect to time, or, given the way various devices interact with satellites, you can also end up with duplicated entries according to timestamps. This can be a first problem, causing your track to represent unrealistic movement patterns of the animal. We need to ensure our data is ordered correctly and also remove any duplicate timestamps. ## review your OVERALL data again head(data.frame(df_stdb_output),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2 Z 42.774893 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-24 00:49:09 42.811528 16.885531 ## 2 populated-upon-upload-STDB 2019-05-24 01:09:03 42.812029 16.886907 ## argos_quality equinox ## 1 NA NA ## 2 NA NA (str(df_stdb_output)) ## &#39;data.frame&#39;: 11354 obs. of 21 variables: ## $ dataset_id : chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ scientific_name : chr &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; ... ## $ common_name : chr &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; ... ## $ site_name : chr &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; ... ## $ colony_name : chr &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; ... ## $ lat_colony : num 42.8 42.8 42.8 42.8 42.8 ... ## $ lon_colony : num 16.9 16.9 16.9 16.9 16.9 ... ## $ device : chr &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; ... ## $ bird_id : chr &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## $ track_id : chr &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## $ original_track_id: chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ age : chr &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; ... ## $ sex : chr &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; ... ## $ breed_stage : chr &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; ... ## $ breed_status : chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ date_gmt : chr &quot;2019-05-24&quot; &quot;2019-05-24&quot; &quot;2019-05-24&quot; &quot;2019-05-24&quot; ... ## $ time_gmt : chr &quot;00:49:09&quot; &quot;01:09:03&quot; &quot;01:29:03&quot; &quot;01:49:09&quot; ... ## $ latitude : num 42.8 42.8 42.8 42.8 42.8 ... ## $ longitude : num 16.9 16.9 16.9 16.9 16.9 ... ## $ argos_quality : logi NA NA NA NA NA NA ... ## $ equinox : logi NA NA NA NA NA NA ... ## NULL ## merge the date and time columns df_stdb_output$dttm &lt;- with(df_stdb_output, ymd(date_gmt) + hms(time_gmt)) ## first check how many duplicate entries you may have. If there are many, it ## is worth exploring your data further to understand why. n_duplicates &lt;- df_stdb_output %&gt;% group_by(bird_id, track_id) %&gt;% arrange(dttm) %&gt;% dplyr::filter(duplicated(dttm) == T) ## review how many duplicate entries you may have. Print the message: print(paste(&quot;you have &quot;,nrow(n_duplicates), &quot; duplicate records in a dataset of &quot;, nrow(df_stdb_output), &quot; records.&quot;, sep =&quot;&quot;)) ## [1] &quot;you have 11 duplicate records in a dataset of 11354 records.&quot; ## remove duplicates entries if no further exploration is deemed necessary df_stdb_output &lt;- df_stdb_output %&gt;% ## first group data by individual animals and unique track_ids group_by(bird_id, track_id) %&gt;% ## then arrange by timestamp arrange(dttm) %&gt;% ## then if a timestamp is duplicated (TRUE), then don&#39;t select this data entry. ## only select entries where timestamps are not duplicated (i.e. FALSE) dplyr::filter(duplicated(dttm) == F) 29.10 Speed filter GPS data: remove erroneous location points It’s often the case that some location points will be in artificial places (i.e. the wrong places). This can happen for many reasons. To automatically remove some of these artifical locaiton points prior to analyses, one can apply a speed filter. Here we use the McConnel Speed Filter. ## review head(data.frame(df_stdb_output),2) ## dataset_id scientific_name common_name site_name ## 1 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 populated-upon-upload-STDB Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony device bird_id track_id ## 1 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## 2 Z 42.774893 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 ## original_track_id age sex breed_stage ## 1 populated-upon-upload-STDB adult unknown chick-rearing ## 2 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt latitude longitude ## 1 populated-upon-upload-STDB 2019-05-01 21:40:41 42.815077 16.890582 ## 2 populated-upon-upload-STDB 2019-05-01 22:00:41 42.837505 16.897495 ## argos_quality equinox dttm ## 1 NA NA 2019-05-01 21:40:41 ## 2 NA NA 2019-05-01 22:00:41 ## reminder on total number of animals tracked length(unique(df_stdb_output$bird_id)) ## [1] 34 ## Define maximum speed in km/h (kilometers per hour) speed.filter.threshold &lt;- 100 ## Important number to change depending on whether you have flying or non-flying seabirds ## create blank data frame to capture filtered tracks and summary data tracks_speed &lt;- data.frame() tracks_speed_summary &lt;- data.frame() ## for(i in 1:length(unique(df_stdb_output$bird_id))){ temp &lt;- df_stdb_output %&gt;% dplyr::filter(bird_id == unique(df_stdb_output$bird_id)[i]) ## remove any erroneous locations due to speed use the McConnel Speed Filter ##from the trip package trip_obj &lt;- temp %&gt;% group_by(bird_id) %&gt;% dplyr::select(x = latitude, y = longitude, dttm, everything()) %&gt;% trip() ## McConnel Speedilter ----- ## apply speedfilter and create data frame trip_obj$Filter &lt;- speedfilter(trip_obj, max.speed = speed.filter.threshold) # speed in km/h trip_obj &lt;- data.frame(trip_obj) #head(trip_obj,2) #dim(trip_obj) ## Keep only filtered coordinates - after checking dimensions of other outputs again trip_obj &lt;- subset(trip_obj,trip_obj$Filter==TRUE) ## bind back onto dataframe tracks_speed &lt;- rbind(tracks_speed, trip_obj) ## Populate summary data temp_summary &lt;- data.frame(bird_id = temp$bird_id[1], n_points_PreFilter = nrow(temp), n_points_PostFilter = nrow(trip_obj), points_removed = ifelse(nrow(temp)-nrow(trip_obj) &gt; 0, &quot;Yes&quot;, &quot;No&quot;)) ## bind on summary information tracks_speed_summary &lt;- rbind(tracks_speed_summary, temp_summary) ## remove temporary items before next loop iteration rm(temp,trip_obj, temp_summary) ## Print loop progress print(paste(&quot;Track &quot;, i, &quot; of &quot;, length(unique(df_stdb_output$bird_id)), &quot; processed&quot;)) } ## [1] &quot;Track 1 of 34 processed&quot; ## [1] &quot;Track 2 of 34 processed&quot; ## [1] &quot;Track 3 of 34 processed&quot; ## [1] &quot;Track 4 of 34 processed&quot; ## [1] &quot;Track 5 of 34 processed&quot; ## [1] &quot;Track 6 of 34 processed&quot; ## [1] &quot;Track 7 of 34 processed&quot; ## [1] &quot;Track 8 of 34 processed&quot; ## [1] &quot;Track 9 of 34 processed&quot; ## [1] &quot;Track 10 of 34 processed&quot; ## [1] &quot;Track 11 of 34 processed&quot; ## [1] &quot;Track 12 of 34 processed&quot; ## [1] &quot;Track 13 of 34 processed&quot; ## [1] &quot;Track 14 of 34 processed&quot; ## [1] &quot;Track 15 of 34 processed&quot; ## [1] &quot;Track 16 of 34 processed&quot; ## [1] &quot;Track 17 of 34 processed&quot; ## [1] &quot;Track 18 of 34 processed&quot; ## [1] &quot;Track 19 of 34 processed&quot; ## [1] &quot;Track 20 of 34 processed&quot; ## [1] &quot;Track 21 of 34 processed&quot; ## [1] &quot;Track 22 of 34 processed&quot; ## [1] &quot;Track 23 of 34 processed&quot; ## [1] &quot;Track 24 of 34 processed&quot; ## [1] &quot;Track 25 of 34 processed&quot; ## [1] &quot;Track 26 of 34 processed&quot; ## [1] &quot;Track 27 of 34 processed&quot; ## [1] &quot;Track 28 of 34 processed&quot; ## [1] &quot;Track 29 of 34 processed&quot; ## [1] &quot;Track 30 of 34 processed&quot; ## [1] &quot;Track 31 of 34 processed&quot; ## [1] &quot;Track 32 of 34 processed&quot; ## [1] &quot;Track 33 of 34 processed&quot; ## [1] &quot;Track 34 of 34 processed&quot; ## review overall head(tracks_speed,2) ## x y dttm dataset_id ## 1 42.815077 16.890582 2019-05-01 21:40:41 populated-upon-upload-STDB ## 2 42.837505 16.897495 2019-05-01 22:00:41 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device bird_id track_id original_track_id ## 1 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 populated-upon-upload-STDB ## 2 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 populated-upon-upload-STDB ## age sex breed_stage breed_status date_gmt time_gmt ## 1 adult unknown chick-rearing populated-upon-upload-STDB 2019-05-01 21:40:41 ## 2 adult unknown chick-rearing populated-upon-upload-STDB 2019-05-01 22:00:41 ## argos_quality equinox Filter optional ## 1 NA NA TRUE TRUE ## 2 NA NA TRUE TRUE ## review summary tracks_speed_summary ## bird_id n_points_PreFilter n_points_PostFilter ## 1 19_Tag17652_Z-2 498 498 ## 2 19_Tag40073_Z-1 641 641 ## 3 19_Tag17617_Z-4 (2nd Parent) 177 177 ## 4 19_Tag40069_Z-6 287 287 ## 5 19_Tag40170_Z-12 418 418 ## 6 19_Tag40078_Z-3 (2nd Parent) 65 65 ## 7 19_Tag17704_Z-11 227 226 ## 8 19_Tag17604_Z-7 152 152 ## 9 19_Tag40133_Z-15 133 133 ## 10 19_Tag40118_Z-2 (2nd Parent) 373 373 ## 11 19_Tag40066_Z-14 209 209 ## 12 19_Tag40182_Z-4 308 308 ## 13 19_Tag17735_Z-3 (RAW DATA MISSING) 502 502 ## 14 19_Tag40138_Z-17 337 337 ## 15 19_Tag17600_Z-9 310 310 ## 16 19_Tag40094_Z-16 228 228 ## 17 19_Tag40177_Z-17 (2nd Parent) 596 596 ## 18 19_Tag40086_Z-11 (2nd Parent) 351 351 ## 19 19_Tag17644_Z-13 243 243 ## 20 20_Tag40193_Z-13 (2nd Parent) 65 65 ## 21 20_Tag41108_Z-95 (2nd Parent) 502 502 ## 22 20_Tag17604_Z-95 274 274 ## 23 20_Tag17600_Z-170 267 267 ## 24 20_Tag40094_Z-131 462 462 ## 25 20_Tag40073_Z-131 (2nd Parent) 469 469 ## 26 20_Tag40133_Z-1 (2nd Parent) 641 641 ## 27 20_Tag40118_Z-175 746 745 ## 28 20_Tag17677_Z-170 (2nd Parent) 147 147 ## 29 20_Tag40078_Z-178 270 270 ## 30 20_Tag17724_Z-106 (2nd Parent) 4 4 ## 31 20_Tag40024_Z-178 (2nd Parent) 490 490 ## 32 20_Tag40039_Z-15 (2nd Parent) 571 571 ## 33 20_Tag17644_Z-106 345 345 ## 34 20_Tag40859_Z-179 35 35 ## points_removed ## 1 No ## 2 No ## 3 No ## 4 No ## 5 No ## 6 No ## 7 Yes ## 8 No ## 9 No ## 10 No ## 11 No ## 12 No ## 13 No ## 14 No ## 15 No ## 16 No ## 17 No ## 18 No ## 19 No ## 20 No ## 21 No ## 22 No ## 23 No ## 24 No ## 25 No ## 26 No ## 27 Yes ## 28 No ## 29 No ## 30 No ## 31 No ## 32 No ## 33 No ## 34 No ## update column names in speed filtered tracks tracks_speed &lt;- tracks_speed %&gt;% mutate(latitude = x, longitude = y) 29.11 Speed filter PTT data: remove erroneous location points Examples to be added to appendix showcasing how to speed filter PTT data. 29.12 Speed filter data review: plotting Plot the track of an animal with speed filtered data versus non-filtered data. Note: plotting with the leaflet package in RStudio requires an internet connection. ## Get the ID of the first example track of animal with speed filtered data example_animal &lt;- tracks_speed_summary %&gt;% dplyr::filter(points_removed == &quot;Yes&quot;) %&gt;% slice(1) %&gt;% dplyr::select(bird_id) ## Get the original data non.speed.filtered &lt;- df_stdb_output %&gt;% dplyr::filter(bird_id == example_animal$bird_id) ## Get the speed filtered ata speed.filtered &lt;- tracks_speed %&gt;% dplyr::filter(bird_id == example_animal$bird_id) ## plot original vs speedfiltered data ## interactive plot leaflet() %&gt;% ## start leaflet plot addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies ## Colour accordingly. ## ORIGINAL TRACK addCircleMarkers(data = non.speed.filtered, radius = 3, fillColor = &quot;red&quot;, fillOpacity = 1, stroke = F) %&gt;% ## Plot lines between original track points addPolylines(lng = non.speed.filtered$longitude, lat = non.speed.filtered$latitude, weight = 1, color = &quot;red&quot;) %&gt;% ## SPEED FILTERED TRACK addCircleMarkers(data = speed.filtered, #label = bird_track$nlocs, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 1, stroke = F) %&gt;% ## plot lines between speed filtered points addPolylines(lng = speed.filtered$longitude, lat = speed.filtered$latitude, weight = 1, color = &quot;cyan&quot;) 29.13 Data cleaning for CPF: n_locs, sampling interval, interpolation So far, the following data cleaning steps have been applied: General review of spatial data Removing - if necessary - sections of tracks when animals were not tracked but devices were recording information (example code / procedures to be provided in future versions of toolkit) Arranging data chronologically and removing duplicate entries Speed filter for clearly erroneous location points Further cleaning of data will typically be necessary for many analyses. Steps may include: Removing data with too few location points Reviewing the sampling frequency of data (i.e. what frequncy you set your devices to record at versus what they actually recorded at) Interpolating data to generate tracking information that approximates an even sampling interval When to clean data with respect to the steps above may depend on the type of animal you tracked. 29.13.1 Data cleaning for CPF seabirds: tracks vs. trips If you have been tracking central place foraging animals, especially with modern tracking devices, it’s likely that you will have many trips recorded from an individual that was tracked. Defining trips: For the purpose of analysing central place foraging data with track2kba, we consider a unique trip to be the period of time from when an animal departs its colony (or particular nest), to the moment it returns to the colony (or particular nest). Therefore, if we have tracking information from individuals over sufficient time period, it’s likely you will have recorded information about multiple trips. We need to split the information into unique trips. Functions in the track2kba R package can help us do this. 29.13.2 Data cleaning for CPF seabirds: Nesting habitat considerations For CPF species that nest in burrows, forests, or other locations where satellite signals may become interrupted for extend periods of time, it can be worth first splitting the overall tracking information into individual trips before filtering or cleaning data further according to number of locations (n_locs) or recorded sampling frequency. EXAMPLE DATA CONSIDERATIONS (Burrow nesting species): Puffinus yelkouan is a burrow nesting species. Therefore, we expect to have long gaps in the tracking information while the birds are sitting on nests (because satellite signals with the tracking device will be interuppted). For this reason, we will first split the tracking information into individual trips, and then apply further filters. Otherwise, it may appear that there are artificially large gaps in your tracking data. If you have tracking information from a species where satellite signal is unlikely to be interuppted from permanent features such as burrows or trees, it may be suitable to filter your data further before splitting tracks into individual trips because data is unlikely to be as biased by the presence of permanent physical features. 29.14 track2KBA: format data for use 29.14.1 track2KBA::formatFields() This function will help format your data to align with that required of track2KBA. In other words: for the track2KBA functions to work, your data needs to have certain columns named in the appropriate way. This function will help with that. We apply the formatting to the most recently filtered data. ## Format the key data fields to the standard used in track2KBA dataGroup &lt;- formatFields( ## your input data.frame or tibble dataGroup = tracks_speed, ## ID of the animal you tracked fieldID = &quot;bird_id&quot;, ## date in GMT fieldDate = &quot;date_gmt&quot;, ## time in GMT fieldTime = &quot;time_gmt&quot;, ## longitude of device fieldLon = &quot;longitude&quot;, ## latitude of device fieldLat = &quot;latitude&quot; ) ## Check output. Output is a data.frame head(dataGroup,2) ## x y dttm dataset_id ## 1 42.815077 16.890582 2019-05-01 21:40:41 populated-upon-upload-STDB ## 2 42.837505 16.897495 2019-05-01 22:00:41 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id original_track_id ## 1 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 populated-upon-upload-STDB ## 2 16.875649 GPS 19_Tag17652_Z-2 19_Tag17652_Z-2 populated-upon-upload-STDB ## age sex breed_stage breed_status date_gmt time_gmt ## 1 adult unknown chick-rearing populated-upon-upload-STDB 2019-05-01 21:40:41 ## 2 adult unknown chick-rearing populated-upon-upload-STDB 2019-05-01 22:00:41 ## argos_quality equinox Filter optional Latitude Longitude DateTime ## 1 NA NA TRUE TRUE 42.815077 16.890582 2019-05-01 21:40:41 ## 2 NA NA TRUE TRUE 42.837505 16.897495 2019-05-01 22:00:41 str(dataGroup) ## &#39;data.frame&#39;: 11341 obs. of 27 variables: ## $ x : num 42.8 42.8 42.8 42.8 42.8 ... ## $ y : num 16.9 16.9 16.9 16.9 16.9 ... ## $ dttm : POSIXct, format: &quot;2019-05-01 21:40:41&quot; &quot;2019-05-01 22:00:41&quot; ... ## $ dataset_id : chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ scientific_name : chr &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; ... ## $ common_name : chr &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; ... ## $ site_name : chr &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; ... ## $ colony_name : chr &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; ... ## $ lat_colony : num 42.8 42.8 42.8 42.8 42.8 ... ## $ lon_colony : num 16.9 16.9 16.9 16.9 16.9 ... ## $ device : chr &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; ... ## $ ID : chr &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17652_Z-2&quot; ... ## $ track_id : chr &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17652_Z-2&quot; ... ## $ original_track_id: chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ age : chr &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; ... ## $ sex : chr &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; ... ## $ breed_stage : chr &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; ... ## $ breed_status : chr &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## $ date_gmt : chr &quot;2019-05-01&quot; &quot;2019-05-01&quot; &quot;2019-05-01&quot; &quot;2019-05-01&quot; ... ## $ time_gmt : chr &quot;21:40:41&quot; &quot;22:00:41&quot; &quot;22:20:41&quot; &quot;22:40:41&quot; ... ## $ argos_quality : logi NA NA NA NA NA NA ... ## $ equinox : logi NA NA NA NA NA NA ... ## $ Filter : logi TRUE TRUE TRUE TRUE TRUE TRUE ... ## $ optional : logi TRUE TRUE TRUE TRUE TRUE TRUE ... ## $ Latitude : num 42.8 42.8 42.8 42.8 42.8 ... ## $ Longitude : num 16.9 16.9 16.9 16.9 16.9 ... ## $ DateTime : POSIXct, format: &quot;2019-05-01 21:40:41&quot; &quot;2019-05-01 22:00:41&quot; ... 29.15 track2KBA: Split tracks into trips Splitting tracks into trips can be achieved with the tripSplit() function within track2kba. Suitable parameters must first be applied / considered. What does tripSplit() do: See the track2kba manuscript. When not to apply tripSplit(): If your data does not relate to a central place forager (CPF), OR a time when an animal may be exhibiting central place foraging behaviours, then applying tripSplit will not be appropriate. How tripSplit() helps: This step is often very useful to help automate the removal of location points on land, or near the vicinty of a colony. We don’t want these extra points to bias our interpretation of the data. General considerations when applying tripSplit(): The user must define ecologically sensible parameters to help automate the tripSplitting process. 29.15.1 Define colony of origin First define a colony of origin for each individual animal tracked. This can be achieved in several ways. Ultimately, you must take scale into account; with respect to species movement, and quality of data from a given device. ## ~~~ Option 1: Manually specify a unique colony location for all birds # colony &lt;- data.frame(Longitude = 16.875879, Latitude = 42.774843) ## ~~~ Option 2: Same unique colony for all birds - extracted from data ## Define the colony position based on the first longitude and latitude coordinates ## which SHOULD originate from the breeding colony if all birds tracked appropriately ## from the same colony. Unlikely to be possible for burrow nesting species. # colony &lt;- dataGroup %&gt;% # summarise( # Longitude = first(Longitude), # Latitude = first(Latitude)) ## ~~~ Option 3: Specify unique colony or unique nest per bird ## IF colony / nest locations vary more widely, then create unique dataframe ## for each bird / animal tracked. Specify a unique nesting location for each ## animal based on the first coordinate of the track. # colony_nest &lt;- dataGroup %&gt;% # group_by(ID) %&gt;% # summarise( # ID = first(ID), # Longitude = first(Longitude), # Latitude = first(Latitude) # ) %&gt;% # data.frame() ## Option 4: Define colony of origin based on associated metadata ## Note - this could also be a separate metadata table so long as the IDs can match up. colony_nest &lt;- dataGroup %&gt;% group_by(ID) %&gt;% summarise( ID = first(ID), Longitude = first(lon_colony), Latitude = first(lat_colony) ) %&gt;% data.frame() ## review colony_nest ## ID Longitude Latitude ## 1 19_Tag17600_Z-9 16.875649 42.774893 ## 2 19_Tag17604_Z-7 16.875649 42.774893 ## 3 19_Tag17617_Z-4 (2nd Parent) 16.875649 42.774893 ## 4 19_Tag17644_Z-13 16.875649 42.774893 ## 5 19_Tag17652_Z-2 16.875649 42.774893 ## 6 19_Tag17704_Z-11 16.875649 42.774893 ## 7 19_Tag17735_Z-3 (RAW DATA MISSING) 16.875649 42.774893 ## 8 19_Tag40066_Z-14 16.875649 42.774893 ## 9 19_Tag40069_Z-6 16.875649 42.774893 ## 10 19_Tag40073_Z-1 16.875649 42.774893 ## 11 19_Tag40078_Z-3 (2nd Parent) 16.875649 42.774893 ## 12 19_Tag40086_Z-11 (2nd Parent) 16.875649 42.774893 ## 13 19_Tag40094_Z-16 16.875649 42.774893 ## 14 19_Tag40118_Z-2 (2nd Parent) 16.875649 42.774893 ## 15 19_Tag40133_Z-15 16.875649 42.774893 ## 16 19_Tag40138_Z-17 16.875649 42.774893 ## 17 19_Tag40170_Z-12 16.875649 42.774893 ## 18 19_Tag40177_Z-17 (2nd Parent) 16.875649 42.774893 ## 19 19_Tag40182_Z-4 16.875649 42.774893 ## 20 20_Tag17600_Z-170 16.875649 42.774893 ## 21 20_Tag17604_Z-95 16.875649 42.774893 ## 22 20_Tag17644_Z-106 16.875649 42.774893 ## 23 20_Tag17677_Z-170 (2nd Parent) 16.875649 42.774893 ## 24 20_Tag17724_Z-106 (2nd Parent) 16.875649 42.774893 ## 25 20_Tag40024_Z-178 (2nd Parent) 16.875649 42.774893 ## 26 20_Tag40039_Z-15 (2nd Parent) 16.875649 42.774893 ## 27 20_Tag40073_Z-131 (2nd Parent) 16.875649 42.774893 ## 28 20_Tag40078_Z-178 16.875649 42.774893 ## 29 20_Tag40094_Z-131 16.875649 42.774893 ## 30 20_Tag40118_Z-175 16.875649 42.774893 ## 31 20_Tag40133_Z-1 (2nd Parent) 16.875649 42.774893 ## 32 20_Tag40193_Z-13 (2nd Parent) 16.875649 42.774893 ## 33 20_Tag40859_Z-179 16.875649 42.774893 ## 34 20_Tag41108_Z-95 (2nd Parent) 16.875649 42.774893 29.15.2 Colony of origin review It can be worth plotting the colony of origin data to ensure colony location has been correctly assigned ## interactive plot - review where the individual colony location records ## were deemed to be. leaflet() %&gt;% ## start leaflet plot addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies ## Colour accordingly. addCircleMarkers(data = data.frame(dataGroup), radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot the colony locations from birds addCircleMarkers(data = data.frame(colony_nest), radius = 5, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) In the example above, we can see that the colony location for all nests is represented by a single point. We know the island is small compared to the scale at which these birds move and we deem the single colony location to sufficiently represent the nesting location all birds. 29.15.3 Apply tripSplit() ## First define your key parameters outside of the function. Useful for using them later again if needed. inner.buff.distance = 3 # km - defines distance an animal must travel to count as trip started return.buff.distance = 10 # km - defines distance an animal must be from the colony to have returned and thus completed a trip duration.time = 1 # hours - defines time an animal must have traveled away from the colony to count as a trip. helps remove glitches in data or very short trips that were likely not foraging trips. ## Input is a &#39;data.frame&#39; of tracking data and the central-place location(s). ## Output is a &#39;SpatialPointsDataFrame&#39;. trips &lt;- tripSplit( dataGroup = dataGroup, colony = colony_nest, # define source location. innerBuff = inner.buff.distance, returnBuff = return.buff.distance, duration = duration.time, nests = T, # specify nests = T if using unique colony locations per animal, gapLimit = NULL, # The period of time between points (in days) to be considered too large to be a contiguous tracking event rmNonTrip = F # If true, points not associated with a trip will be removed / if false, points not associated with a trip will be kept ) ## Review data after tripSplit() head(trips,2) ## x y dttm dataset_id ## 1200 42.811528 16.885531 2019-05-24 00:49:09 populated-upon-upload-STDB ## 2159 42.812029 16.886907 2019-05-24 01:09:03 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1200 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2159 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id ## 1200 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2159 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1200 populated-upon-upload-STDB adult unknown chick-rearing ## 2159 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt argos_quality equinox ## 1200 populated-upon-upload-STDB 2019-05-24 00:49:09 NA NA ## 2159 populated-upon-upload-STDB 2019-05-24 01:09:03 NA NA ## Filter optional Latitude Longitude DateTime tripID ## 1200 TRUE TRUE 42.811528 16.885531 2019-05-24 00:49:09 19_Tag17600_Z-9_01 ## 2159 TRUE TRUE 42.812029 16.886907 2019-05-24 01:09:03 19_Tag17600_Z-9_01 ## X Y Returns StartsOut ColDist ## 1200 16.885531 42.811528 Yes Yes 4149.301440 ## 2159 16.886907 42.812029 Yes Yes 4226.997952 str(trips) ## Formal class &#39;SpatialPointsDataFrame&#39; [package &quot;sp&quot;] with 5 slots ## ..@ data :&#39;data.frame&#39;: 11341 obs. of 33 variables: ## .. ..$ x : num [1:11341] 42.8 42.8 42.8 42.8 42.8 ... ## .. ..$ y : num [1:11341] 16.9 16.9 16.9 16.9 16.9 ... ## .. ..$ dttm : POSIXct[1:11341], format: &quot;2019-05-24 00:49:09&quot; &quot;2019-05-24 01:09:03&quot; ... ## .. ..$ dataset_id : chr [1:11341] &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## .. ..$ scientific_name : chr [1:11341] &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; &quot;Puffinus yelkouan&quot; ... ## .. ..$ common_name : chr [1:11341] &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; &quot;Yelkouan Shearwater&quot; ... ## .. ..$ site_name : chr [1:11341] &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; &quot;Lastovo SPA&quot; ... ## .. ..$ colony_name : chr [1:11341] &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; &quot;Z&quot; ... ## .. ..$ lat_colony : num [1:11341] 42.8 42.8 42.8 42.8 42.8 ... ## .. ..$ lon_colony : num [1:11341] 16.9 16.9 16.9 16.9 16.9 ... ## .. ..$ device : chr [1:11341] &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; &quot;GPS&quot; ... ## .. ..$ ID : chr [1:11341] &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## .. ..$ track_id : chr [1:11341] &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17600_Z-9&quot; ... ## .. ..$ original_track_id: chr [1:11341] &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## .. ..$ age : chr [1:11341] &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; &quot;adult&quot; ... ## .. ..$ sex : chr [1:11341] &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; &quot;unknown&quot; ... ## .. ..$ breed_stage : chr [1:11341] &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; &quot;chick-rearing&quot; ... ## .. ..$ breed_status : chr [1:11341] &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; &quot;populated-upon-upload-STDB&quot; ... ## .. ..$ date_gmt : chr [1:11341] &quot;2019-05-24&quot; &quot;2019-05-24&quot; &quot;2019-05-24&quot; &quot;2019-05-24&quot; ... ## .. ..$ time_gmt : chr [1:11341] &quot;00:49:09&quot; &quot;01:09:03&quot; &quot;01:29:03&quot; &quot;01:49:09&quot; ... ## .. ..$ argos_quality : logi [1:11341] NA NA NA NA NA NA ... ## .. ..$ equinox : logi [1:11341] NA NA NA NA NA NA ... ## .. ..$ Filter : logi [1:11341] TRUE TRUE TRUE TRUE TRUE TRUE ... ## .. ..$ optional : logi [1:11341] TRUE TRUE TRUE TRUE TRUE TRUE ... ## .. ..$ Latitude : num [1:11341] 42.8 42.8 42.8 42.8 42.8 ... ## .. ..$ Longitude : num [1:11341] 16.9 16.9 16.9 16.9 16.9 ... ## .. ..$ DateTime : POSIXct[1:11341], format: &quot;2019-05-24 00:49:09&quot; &quot;2019-05-24 01:09:03&quot; ... ## .. ..$ tripID : chr [1:11341] &quot;19_Tag17600_Z-9_01&quot; &quot;19_Tag17600_Z-9_01&quot; &quot;19_Tag17600_Z-9_01&quot; &quot;19_Tag17600_Z-9_01&quot; ... ## .. ..$ X : num [1:11341] 16.9 16.9 16.9 16.9 16.9 ... ## .. ..$ Y : num [1:11341] 42.8 42.8 42.8 42.8 42.8 ... ## .. ..$ Returns : chr [1:11341] &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; ... ## .. ..$ StartsOut : chr [1:11341] &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; ... ## .. ..$ ColDist : num [1:11341] 4149 4227 4182 4213 4487 ... ## ..@ coords.nrs : num(0) ## ..@ coords : num [1:11341, 1:2] 16.9 16.9 16.9 16.9 16.9 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:11341] &quot;1200&quot; &quot;2159&quot; &quot;3138&quot; &quot;4135&quot; ... ## .. .. ..$ : chr [1:2] &quot;dataGroup.Longitude&quot; &quot;dataGroup.Latitude&quot; ## ..@ bbox : num [1:2, 1:2] 12.4 41.9 19.1 45.7 ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:2] &quot;dataGroup.Longitude&quot; &quot;dataGroup.Latitude&quot; ## .. .. ..$ : chr [1:2] &quot;min&quot; &quot;max&quot; ## ..@ proj4string:Formal class &#39;CRS&#39; [package &quot;sp&quot;] with 1 slot ## .. .. ..@ projargs: chr &quot;+proj=longlat +datum=WGS84 +no_defs&quot; ## .. .. ..$ comment: chr &quot;GEOGCRS[\\&quot;unknown\\&quot;,\\n DATUM[\\&quot;World Geodetic System 1984\\&quot;,\\n ELLIPSOID[\\&quot;WGS 84\\&quot;,6378137,298.25722&quot;| __truncated__ table(trips$Returns) ## ## No Yes ## 560 905 9876 [“NOTE: the messages that may relate to ‘track …. does not return to the colony’, is actually referring to the individual trips from each animal tracked. The code for track2KBA package needs to be revised to display an ’_’ between the track ID and the individual trip ID. So instead of reading something like 693041, it should read 69304_1, to better refer to trip 1 of track 69304.”] 29.15.4 Review of tripSplit() output In the example above, we specified rmNonTrip = F so as not remove any points not deemed as associated with a trip. I.e. the points typically lying within the innerBuff distance and for those where the animal traveled for less than duration specified, Let’s review the general points we are not considering as part of trips. Split the locations into points to keep and those that will be removed (i.e. the points not associated with a trip) for visual plot of the tracks using leaflet package in R. Note: when specifying rmNonTrip = F, location points are assigned under the column Return as either: Yes (part of trip that animal returns to colony), No (part of a trip where animal does not return to colony), or Blank (location point that would be removed) ## Split the points points_to_keep &lt;- data.frame(trips) %&gt;% dplyr::filter(Returns %in% c(&quot;Yes&quot;, &quot;No&quot;)) ## points_to_remove &lt;- data.frame(trips) %&gt;% dplyr::filter(!Returns %in% c(&quot;Yes&quot;, &quot;No&quot;)) map &lt;- leaflet() %&gt;% ## start leaflet plot addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies ## Colour accordingly. addCircleMarkers(data = points_to_keep, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## addCircleMarkers(data = points_to_remove, radius = 3, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) map 29.15.5 Understanding what is happening in tripSplit() further Essentially, we are using a function that helps us bulk clean tracking data. The goal is to assign individual trips to multiple animals that have been tracked, and doing this in an automated way. Go back and change innerBuff and duration parameters in particular, and recreate the plot above showing the points not associated with a trip. See how changing the arguments impacts the likely data that will be removed for the analysis. You only want to remove (i.e. “clean up”) the points that are most likely not associated with a trip. 29.15.6 Review the individual trips for each tracked animal after applying tripSplit() A simple way to do this is with the mapTrips function. The plots show an overview of individual trips per bird. Only data for the first 25 birds is shown. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## track2KBA::mapTrips() ---- ## view data after splitting into trips ---- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## plot quick overview of trips recorded for individual birds (i.e. the plots show ## an overview of individual trips per bird). Only data for the first 25 birds is ## shown mapTrips(trips = trips, colony = colony_nest) ## If you want to map the trips from the next 25 animals tracked, use the IDs argument mapTrips(trips = trips, IDs = 26:50, colony = colony_nest) 29.15.7 Plot the individual trips for each tracked animal after applying tripSplit() If, after reviewing the simplified plots of individual trips for each tracked animal using the mapTrip() function you are not satisfied, then you should explore the relative data further. One way of exploring the trips outputted for individually tracked animals would be to rapidly review summary plots for each trip, showing start, journey, and end points, where the point locations are also joined together with a line. Consider the code in the chapter Tracking data: Plotting tracks and reviewing tabular data 29.16 track2kba: What trip data to use (complete or incomplete trips) Keeping points associated with complete trips only is the approach considered in the track2KBA online tutorial. But you may want to explore which trips you are keeping or not. There are no definitive rules about what counts as a track good enough, or too bad, for an analysis. Users will need to consider the quality of the data obtained in relation to the species that was tracked and the key question they are exploring. Users may wish to consider if too many individual trips have been removed. i.e. if you tracked 30 birds and you estimated to have approximately 3 trips recorded per bird, then you would have a total of 90 trips. But it’s likely that on some trips, that not the entire trip was recorded (for multiple reasons). Therefore, you might expect to rather have about 83 trips recorded across all birds because for 7 trips data might not have indicated birds returned to the colony. If you had a very high proportion of trips that did not return to the colony, then it’s likely that you have defined the parameters incorrectly for tripSplit() and you should reconsider better ecologically based estimates for these parameters. There is of course the chance that there are other issues (i.e. poor quality data obtained given device functionality) with your data which would warrant more detailed exploration. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Keep points associated with individual trips ---- ## Filter the data to only keep the points associated with individual trips that ## were recognised as complete trips. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Let&#39;s first check how many trips we record as Yes vs. No before filtering head(trips,2) ## x y dttm dataset_id ## 1200 42.811528 16.885531 2019-05-24 00:49:09 populated-upon-upload-STDB ## 2159 42.812029 16.886907 2019-05-24 01:09:03 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1200 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2159 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id ## 1200 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2159 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1200 populated-upon-upload-STDB adult unknown chick-rearing ## 2159 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt argos_quality equinox ## 1200 populated-upon-upload-STDB 2019-05-24 00:49:09 NA NA ## 2159 populated-upon-upload-STDB 2019-05-24 01:09:03 NA NA ## Filter optional Latitude Longitude DateTime tripID ## 1200 TRUE TRUE 42.811528 16.885531 2019-05-24 00:49:09 19_Tag17600_Z-9_01 ## 2159 TRUE TRUE 42.812029 16.886907 2019-05-24 01:09:03 19_Tag17600_Z-9_01 ## X Y Returns StartsOut ColDist ## 1200 16.885531 42.811528 Yes Yes 4149.301440 ## 2159 16.886907 42.812029 Yes Yes 4226.997952 ## summary of trips associated with Return or not totalTripsAll &lt;- data.frame(trips) %&gt;% group_by(tripID, Returns) %&gt;% summarise(count = n()) %&gt;% data.frame(.) ## view summary result table(totalTripsAll$Returns) ## ## No Yes ## 1 19 325 ## NOW, Filter to only include trips that return trips.return.yes &lt;- subset(trips, trips$Returns == &quot;Yes&quot; ) totalTripsYes &lt;- data.frame(trips.return.yes) %&gt;% group_by(tripID, Returns) %&gt;% summarise(count = n()) %&gt;% data.frame(.) ## view summary result table(totalTripsYes$Returns) ## ## Yes ## 325 ## Filter for trips that do not reutrn trips.return.no &lt;- subset(trips, trips$Returns == &quot;No&quot; ) totalTripsNo &lt;- data.frame(trips.return.no) %&gt;% group_by(tripID, Returns) %&gt;% summarise(count = n()) %&gt;% data.frame(.) ## view summary result table(totalTripsNo$Returns) ## ## No ## 19 ## CONSIDER and compare: total trips that returned vs. did not: table(totalTripsYes$Returns) ## ## Yes ## 325 table(totalTripsNo$Returns) ## ## No ## 19 29.16.1 track2KBA: Choice of complete trips only If you want to explore further the trips that were not considered to have returned, then use the object above, trips.return.no, to investigate the individual trips further. E.g. through individual plotting. For our example, we have 325 complete trips and 19 incomplete trips; a very small proportion of incomplete trips. We, therefore, deem our choice of input parameters as ecologically sensible for the tripSplit() function and use only the complete trips for further analyses. ## select, rename, and use only the complete trips for further analyses trips &lt;- trips.return.yes 29.17 track2KBA: Use only at-sea sections of trips Key considerations related to identifying IBAs / KBAs: when identifying an IBA or KBA for seabirds using the track2KBA protocol, you effectively need information about the source population (typically the colony) and distribution data (tracking data). This means that not only can you identify a pelagic site from tracking data, but you can also consider an IBA/KBA for the colony itself and a possible at-sea buffer (seaward extension) around the colony. Because you should typically consider identifying the seaward extension around the colony in addition to any potential pelagic / offshore sites supported by the tracking data, you can remove location points from the data within a suitable buffer distance (typically the inner buffer distance used in the tripSplit() function. ## remove locations near the vicinity of the colony - distance is in m (unlike innerBuff where distance was in km) head(trips,2) ## x y dttm dataset_id ## 1200 42.811528 16.885531 2019-05-24 00:49:09 populated-upon-upload-STDB ## 2159 42.812029 16.886907 2019-05-24 01:09:03 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1200 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2159 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id ## 1200 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2159 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1200 populated-upon-upload-STDB adult unknown chick-rearing ## 2159 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt argos_quality equinox ## 1200 populated-upon-upload-STDB 2019-05-24 00:49:09 NA NA ## 2159 populated-upon-upload-STDB 2019-05-24 01:09:03 NA NA ## Filter optional Latitude Longitude DateTime tripID ## 1200 TRUE TRUE 42.811528 16.885531 2019-05-24 00:49:09 19_Tag17600_Z-9_01 ## 2159 TRUE TRUE 42.812029 16.886907 2019-05-24 01:09:03 19_Tag17600_Z-9_01 ## X Y Returns StartsOut ColDist ## 1200 16.885531 42.811528 Yes Yes 4149.301440 ## 2159 16.886907 42.812029 Yes Yes 4226.997952 trips &lt;- trips[trips$ColDist &gt; inner.buff.distance*1000, ] ## Plot to review ## interactive plot - including colony location(s) leaflet() %&gt;% ## start leaflet plot addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies ## Colour accordingly. addCircleMarkers(data = data.frame(trips), radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot the colony locations from birds addCircleMarkers(data = data.frame(colony_nest), radius = 5, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) Note: in the plot above, you may need to zoom into the colony of origin to ensure points have been removed accordingly. 29.18 track2KBA: Number of locations filter It is worth considering the total number of location points contributing to each trip after splitting tracks from animals. Even if you are not splitting tracks into trips, using location data from animals where you have very few data points may bias your results. Recommendation for the track2kba analytical approach is to use data with at least &gt;5 location points ## create data frame and find IDs of trips with &gt;5 locations; as required for track2KBA analysis trips_to_keep &lt;- data.frame(trips) %&gt;% group_by(tripID) %&gt;% summarise(triplocs = n()) %&gt;% dplyr::filter(triplocs &gt; 5) ## select the relevant tripIDs only and create new object trips_df &lt;- data.frame(trips) %&gt;% dplyr::filter(tripID %in% trips_to_keep$tripID) ## Compare how many trips you removed ## Before length(unique(trips$tripID)) ## [1] 325 ## After length(unique(trips_df$tripID)) ## [1] 305 29.19 track2KBA: tripSummary() This will give us a guide to summary statistics about the tracking data from central place foraging animals. ## tripSummary() ---- sumTrips &lt;- tripSummary(trips = trips_df, colony = colony_nest, nests = T) ## Check you only have complete trips here (if that is what you are aiming for) table(sumTrips$complete) ## ## complete trip ## 305 ## filter for only complete trips if needed #sumTrips &lt;- sumTrips %&gt;% dplyr::filter(complete= &quot;complete trip&quot;) ## view output head(sumTrips ,10) ## # A tibble: 10 × 10 ## # Groups: ID [2] ## ID tripID n_locs departure return duration ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dttm&gt; &lt;dbl&gt; ## 1 19_Tag17600_Z… 19_Ta… 46 2019-05-24 00:49:09 2019-05-30 06:27:14 150. ## 2 19_Tag17600_Z… 19_Ta… 9 2019-05-31 02:48:10 2019-05-31 12:28:30 9.67 ## 3 19_Tag17600_Z… 19_Ta… 12 2019-06-02 03:07:31 2019-06-02 19:21:36 16.2 ## 4 19_Tag17600_Z… 19_Ta… 73 2019-06-03 00:26:26 2019-06-08 16:19:49 136. ## 5 19_Tag17600_Z… 19_Ta… 9 2019-06-09 02:46:26 2019-06-09 11:47:30 9.02 ## 6 19_Tag17604_Z… 19_Ta… 29 2019-05-05 20:10:16 2019-05-06 19:13:59 23.1 ## 7 19_Tag17604_Z… 19_Ta… 17 2019-05-07 02:36:07 2019-05-07 15:32:41 12.9 ## 8 19_Tag17604_Z… 19_Ta… 19 2019-05-08 02:58:44 2019-05-10 10:35:26 55.6 ## 9 19_Tag17604_Z… 19_Ta… 8 2019-05-11 02:25:56 2019-05-12 03:44:00 25.3 ## 10 19_Tag17604_Z… 19_Ta… 20 2019-05-13 04:36:26 2019-05-15 20:35:03 64.0 ## # ℹ 4 more variables: total_dist &lt;dbl&gt;, max_dist &lt;dbl&gt;, direction &lt;dbl&gt;, ## # complete &lt;chr&gt; ## view unique individual ID unique(sumTrips$ID) ## [1] &quot;19_Tag17600_Z-9&quot; &quot;19_Tag17604_Z-7&quot; ## [3] &quot;19_Tag17617_Z-4 (2nd Parent)&quot; &quot;19_Tag17644_Z-13&quot; ## [5] &quot;19_Tag17652_Z-2&quot; &quot;19_Tag17704_Z-11&quot; ## [7] &quot;19_Tag17735_Z-3 (RAW DATA MISSING)&quot; &quot;19_Tag40066_Z-14&quot; ## [9] &quot;19_Tag40069_Z-6&quot; &quot;19_Tag40073_Z-1&quot; ## [11] &quot;19_Tag40078_Z-3 (2nd Parent)&quot; &quot;19_Tag40086_Z-11 (2nd Parent)&quot; ## [13] &quot;19_Tag40094_Z-16&quot; &quot;19_Tag40118_Z-2 (2nd Parent)&quot; ## [15] &quot;19_Tag40133_Z-15&quot; &quot;19_Tag40138_Z-17&quot; ## [17] &quot;19_Tag40170_Z-12&quot; &quot;19_Tag40177_Z-17 (2nd Parent)&quot; ## [19] &quot;19_Tag40182_Z-4&quot; &quot;20_Tag17600_Z-170&quot; ## [21] &quot;20_Tag17604_Z-95&quot; &quot;20_Tag17644_Z-106&quot; ## [23] &quot;20_Tag17677_Z-170 (2nd Parent)&quot; &quot;20_Tag40024_Z-178 (2nd Parent)&quot; ## [25] &quot;20_Tag40039_Z-15 (2nd Parent)&quot; &quot;20_Tag40073_Z-131 (2nd Parent)&quot; ## [27] &quot;20_Tag40078_Z-178&quot; &quot;20_Tag40094_Z-131&quot; ## [29] &quot;20_Tag40118_Z-175&quot; &quot;20_Tag40133_Z-1 (2nd Parent)&quot; ## [31] &quot;20_Tag40193_Z-13 (2nd Parent)&quot; &quot;20_Tag40859_Z-179&quot; ## [33] &quot;20_Tag41108_Z-95 (2nd Parent)&quot; ## number of individuals with tracking data length(unique(sumTrips$ID)) ## [1] 33 ## number of unique trips from all individuals length(unique(sumTrips$tripID)) ## [1] 305 29.19.1 Trip summary data review NOTE: These metrics are just summaries of summary data. Additional methods (to be updated in future) may help you summarise your data in greater detail. ## Visual summary of data ---- ## all data all_tracks_sum &lt;- sumTrips %&gt;% mutate(group = &quot;all_tracks&quot;) %&gt;% group_by(group) %&gt;% summarise(n_trips = n(), avg_triptime_h = round(mean(duration),2), med_triptime_h = round(median(duration),2), min_triptime_h = round(min(duration),2), max_triptime_h = round(max(duration),2), avg_totdist_km = round(mean(total_dist),2), med_totdist_km = round(median(total_dist),2), min_totdist_km = round(min(total_dist),2), max_totdist_km = round(max(total_dist),2), avg_maxdist_km = round(mean(max_dist),2), med_maxdist_km = round(median(max_dist),2), min_maxdist_km = round(min(max_dist),2), max_maxdist_km = round(max(max_dist),2)) %&gt;% data.frame() ## review all data summary all_tracks_sum ## group n_trips avg_triptime_h med_triptime_h min_triptime_h ## 1 all_tracks 305 35.31 17.06 2.66 ## max_triptime_h avg_totdist_km med_totdist_km min_totdist_km max_totdist_km ## 1 762.34 269.59 142.34 6.7 4609 ## avg_maxdist_km med_maxdist_km min_maxdist_km max_maxdist_km ## 1 84.66 44.05 5.12 444.01 ## by individual bird_sum &lt;- sumTrips %&gt;% group_by(ID) %&gt;% summarise(n_trips = n(), avg_triptime_h = round(mean(duration),2), med_triptime_h = round(median(duration),2), min_triptime_h = round(min(duration),2), max_triptime_h = round(max(duration),2), avg_totdist_km = round(mean(total_dist),2), med_totdist_km = round(median(total_dist),2), min_totdist_km = round(min(total_dist),2), max_totdist_km = round(max(total_dist),2), avg_maxdist_km = round(mean(max_dist),2), med_maxdist_km = round(median(max_dist),2), min_maxdist_km = round(min(max_dist),2), max_maxdist_km = round(max(max_dist),2)) %&gt;% data.frame() bird_sum ## ID n_trips avg_triptime_h med_triptime_h ## 1 19_Tag17600_Z-9 5 64.09 16.23 ## 2 19_Tag17604_Z-7 6 33.08 24.18 ## 3 19_Tag17617_Z-4 (2nd Parent) 5 24.15 22.81 ## 4 19_Tag17644_Z-13 2 216.26 216.26 ## 5 19_Tag17652_Z-2 11 36.41 19.62 ## 6 19_Tag17704_Z-11 7 64.81 19.07 ## 7 19_Tag17735_Z-3 (RAW DATA MISSING) 13 45.94 16.59 ## 8 19_Tag40066_Z-14 11 24.79 15.53 ## 9 19_Tag40069_Z-6 14 24.44 16.66 ## 10 19_Tag40073_Z-1 16 27.33 16.83 ## 11 19_Tag40078_Z-3 (2nd Parent) 1 23.16 23.16 ## 12 19_Tag40086_Z-11 (2nd Parent) 4 210.50 31.33 ## 13 19_Tag40094_Z-16 1 23.70 23.70 ## 14 19_Tag40118_Z-2 (2nd Parent) 12 23.33 17.13 ## 15 19_Tag40133_Z-15 7 22.07 12.62 ## 16 19_Tag40138_Z-17 4 152.82 110.77 ## 17 19_Tag40170_Z-12 11 17.45 16.00 ## 18 19_Tag40177_Z-17 (2nd Parent) 9 49.41 18.52 ## 19 19_Tag40182_Z-4 14 22.48 18.25 ## 20 20_Tag17600_Z-170 12 14.38 14.96 ## 21 20_Tag17604_Z-95 16 24.43 17.30 ## 22 20_Tag17644_Z-106 6 52.92 17.27 ## 23 20_Tag17677_Z-170 (2nd Parent) 3 70.22 46.93 ## 24 20_Tag40024_Z-178 (2nd Parent) 13 25.42 17.63 ## 25 20_Tag40039_Z-15 (2nd Parent) 13 31.86 17.68 ## 26 20_Tag40073_Z-131 (2nd Parent) 17 22.69 17.01 ## 27 20_Tag40078_Z-178 4 17.00 17.70 ## 28 20_Tag40094_Z-131 13 39.26 23.90 ## 29 20_Tag40118_Z-175 23 23.59 15.36 ## 30 20_Tag40133_Z-1 (2nd Parent) 13 33.49 18.40 ## 31 20_Tag40193_Z-13 (2nd Parent) 3 38.64 14.24 ## 32 20_Tag40859_Z-179 1 9.55 9.55 ## 33 20_Tag41108_Z-95 (2nd Parent) 15 26.96 17.30 ## min_triptime_h max_triptime_h avg_totdist_km med_totdist_km min_totdist_km ## 1 9.02 149.63 426.09 168.52 22.87 ## 2 12.94 63.98 179.21 164.26 59.56 ## 3 16.46 41.42 146.12 130.99 78.65 ## 4 150.66 281.87 1685.70 1685.70 910.72 ## 5 12.83 112.60 344.49 160.34 35.89 ## 6 6.52 167.63 346.52 166.97 33.23 ## 7 13.19 135.81 464.16 197.59 29.67 ## 8 10.24 53.81 112.70 71.57 19.51 ## 9 15.23 88.34 107.33 72.04 32.14 ## 10 14.85 89.87 395.80 183.63 73.79 ## 11 23.16 23.16 96.37 96.37 96.37 ## 12 17.00 762.34 1248.77 153.49 79.10 ## 13 23.70 23.70 23.11 23.11 23.11 ## 14 5.00 64.57 179.18 149.39 6.70 ## 15 2.66 85.67 122.93 70.61 17.08 ## 16 37.21 352.52 990.90 752.76 26.88 ## 17 15.00 23.00 111.00 104.56 52.84 ## 18 14.85 186.36 411.98 71.66 29.86 ## 19 12.05 66.83 114.22 87.89 26.74 ## 20 8.38 15.83 122.94 121.95 60.93 ## 21 8.31 84.67 132.59 134.70 56.13 ## 22 14.24 138.14 391.11 136.04 44.98 ## 23 25.97 137.75 553.84 148.70 83.45 ## 24 12.42 108.91 226.86 152.27 92.17 ## 25 16.09 137.00 261.92 183.71 107.62 ## 26 14.62 63.02 180.11 145.14 108.81 ## 27 13.97 18.64 135.35 133.90 111.50 ## 28 8.39 115.15 289.18 169.64 46.63 ## 29 12.50 138.11 220.88 168.03 83.02 ## 30 15.07 92.05 397.71 202.89 61.68 ## 31 14.09 87.59 113.34 32.54 26.45 ## 32 9.55 9.55 101.23 101.23 101.23 ## 33 15.35 68.34 197.54 154.83 113.21 ## max_totdist_km avg_maxdist_km med_maxdist_km min_maxdist_km max_maxdist_km ## 1 1097.52 188.32 67.41 11.57 437.62 ## 2 359.36 61.76 49.14 41.48 97.23 ## 3 237.45 38.51 37.91 30.35 48.82 ## 4 2460.68 365.05 365.05 318.96 411.13 ## 5 1266.72 114.76 41.47 16.36 378.81 ## 6 747.55 154.87 44.56 18.56 344.23 ## 7 1364.57 166.73 35.96 17.13 433.62 ## 8 483.83 44.05 24.28 6.44 222.64 ## 9 422.01 32.82 29.26 13.33 101.08 ## 10 1153.72 144.03 47.03 32.69 425.27 ## 11 96.37 34.59 34.59 34.59 34.59 ## 12 4609.00 152.27 77.17 34.36 420.39 ## 13 23.11 12.89 12.89 12.89 12.89 ## 14 509.72 53.36 43.12 5.12 154.98 ## 15 311.77 42.16 29.61 9.36 109.13 ## 16 2431.23 235.06 243.36 13.02 440.52 ## 17 217.15 38.50 44.05 14.85 64.60 ## 18 1713.08 115.73 20.64 12.97 428.56 ## 19 306.02 33.40 30.36 13.65 107.76 ## 20 175.58 44.77 40.47 25.77 71.27 ## 21 299.72 43.12 39.48 25.27 75.57 ## 22 1063.64 136.68 51.19 22.62 397.89 ## 23 1429.38 168.92 46.91 37.19 422.66 ## 24 1165.62 88.33 66.00 33.81 420.96 ## 25 997.05 69.13 49.80 38.97 202.55 ## 26 490.06 54.26 40.83 35.35 113.39 ## 27 162.11 45.34 43.63 37.61 56.48 ## 28 1237.56 97.34 72.24 32.38 440.35 ## 29 987.00 64.10 49.95 29.89 171.85 ## 30 1420.50 143.15 54.44 24.22 444.01 ## 31 281.02 27.56 17.57 12.01 53.08 ## 32 101.23 76.57 76.57 76.57 76.57 ## 33 482.41 59.62 55.28 31.60 116.04 ## save the data as an excel sheet #write.xlsx(bird_sum, file = &quot;./Data/track2KBA_output/TrackingData_Summary.xlsx&quot;, # sheetName = &quot;Sheet1&quot;, # col.names = TRUE, row.names = T, append = FALSE) ## histograms - foraging trip duration p1 &lt;- ggplot(sumTrips , aes(duration)) + geom_histogram(colour = &quot;darkgrey&quot;, fill = &quot;cyan&quot;)+ theme( axis.text=element_text(size=14, color=&quot;black&quot;), axis.title=element_text(size=16), panel.background=element_rect(fill=&quot;white&quot;, colour=&quot;black&quot;)) + ylab(&quot;n tracks&quot;) + xlab(&quot;Duration (hours)&quot;) p1 ## total distance traveled from the colony p2 &lt;- ggplot(sumTrips , aes(total_dist)) + geom_histogram(colour = &quot;darkgrey&quot;, fill = &quot;cyan&quot;)+ theme( axis.text=element_text(size=14, color=&quot;black&quot;), axis.title=element_text(size=16), panel.background=element_rect(fill=&quot;white&quot;, colour=&quot;black&quot;)) + ylab(&quot;n tracks&quot;) + xlab(&quot;Total dist. travelled (km)&quot;) p2 ## maximum distance traveled from the colony p3 &lt;- ggplot(sumTrips , aes(max_dist)) + geom_histogram(colour = &quot;darkgrey&quot;, fill = &quot;cyan&quot;)+ theme( axis.text=element_text(size=14, color=&quot;black&quot;), axis.title=element_text(size=16), panel.background=element_rect(fill=&quot;white&quot;, colour=&quot;black&quot;)) + ylab(&quot;n tracks&quot;) + xlab(&quot;Max dist. from colony (km)&quot;) p3 ## save the plots #ggsave(filename = paste(&quot;./Plots/HistSummary_Duration.png&quot;,sep=&quot;&quot;), # p1, # dpi = 300, units = &quot;mm&quot;, width = 180,height = 130) #ggsave(filename = paste(&quot;./Plots/HistSummary_TotDist.png&quot;,sep=&quot;&quot;), # p2, # dpi = 300, units = &quot;mm&quot;, width = 180,height = 130) #ggsave(filename = paste(&quot;./Plots/HistSummary_MaxDist.png&quot;,sep=&quot;&quot;), # p3, # dpi = 300, units = &quot;mm&quot;, width = 180,height = 130) 29.20 track2KBA: Sampling interval assessment To implement track2KBA fully, you need data approximating an even sampling interval i.e. location points must be regularly spaced in time. You must first determine how “gappy” the tracking data is (time intervals between location data) This is an important step for almost all tracking data analyses. If your data is not filtered / cleaned correctly, your ultimate results may be spurious. #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Check sampling interval ---- #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## data for summarising head(data.frame(trips_df),2) ## x y dttm dataset_id ## 1200 42.811528 16.885531 2019-05-24 00:49:09 populated-upon-upload-STDB ## 2159 42.812029 16.886907 2019-05-24 01:09:03 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1200 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2159 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id ## 1200 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2159 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1200 populated-upon-upload-STDB adult unknown chick-rearing ## 2159 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt argos_quality equinox ## 1200 populated-upon-upload-STDB 2019-05-24 00:49:09 NA NA ## 2159 populated-upon-upload-STDB 2019-05-24 01:09:03 NA NA ## Filter optional Latitude Longitude DateTime tripID ## 1200 TRUE TRUE 42.811528 16.885531 2019-05-24 00:49:09 19_Tag17600_Z-9_01 ## 2159 TRUE TRUE 42.812029 16.886907 2019-05-24 01:09:03 19_Tag17600_Z-9_01 ## X Y Returns StartsOut ColDist dataGroup.Longitude ## 1200 16.885531 42.811528 Yes Yes 4149.301440 16.885531 ## 2159 16.886907 42.812029 Yes Yes 4226.997952 16.886907 ## dataGroup.Latitude optional.1 ## 1200 42.811528 TRUE ## 2159 42.812029 TRUE ## double type of trips points are associated with table(trips_df$Returns) ## ## Yes ## 9511 ## Determine difference between consecutive timestamps ## (NB: consecutive order of timestamps is critical here!) ## Doing this by tripID, not individual ID - change the group_by argument if needed timeDiff &lt;- trips_df %&gt;% data.frame() %&gt;% group_by(tripID) %&gt;% arrange(DateTime) %&gt;% mutate(delta_secs = as.numeric(difftime(DateTime, lag(DateTime, default = first(DateTime)), units = &quot;secs&quot;))) %&gt;% slice(2:n()) head(data.frame(timeDiff),2) ## x y dttm dataset_id ## 1 42.812029 16.886907 2019-05-24 01:09:03 populated-upon-upload-STDB ## 2 42.811369 16.888280 2019-05-24 01:29:03 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id original_track_id ## 1 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 populated-upon-upload-STDB ## 2 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 populated-upon-upload-STDB ## age sex breed_stage breed_status date_gmt time_gmt ## 1 adult unknown chick-rearing populated-upon-upload-STDB 2019-05-24 01:09:03 ## 2 adult unknown chick-rearing populated-upon-upload-STDB 2019-05-24 01:29:03 ## argos_quality equinox Filter optional Latitude Longitude DateTime ## 1 NA NA TRUE TRUE 42.812029 16.886907 2019-05-24 01:09:03 ## 2 NA NA TRUE TRUE 42.811369 16.888280 2019-05-24 01:29:03 ## tripID X Y Returns StartsOut ColDist ## 1 19_Tag17600_Z-9_01 16.886907 42.812029 Yes Yes 4226.997952 ## 2 19_Tag17600_Z-9_01 16.888280 42.811369 Yes Yes 4181.804570 ## dataGroup.Longitude dataGroup.Latitude optional.1 delta_secs ## 1 16.886907 42.812029 TRUE 1194 ## 2 16.888280 42.811369 TRUE 1200 hist(timeDiff$delta_secs) ## plot histogram of timediff between all points &quot;This plot will take time depending on size of dataset!&quot; ## [1] &quot;This plot will take time depending on size of dataset!&quot; p4 &lt;- ggplot(timeDiff , aes(delta_secs)) + geom_histogram(colour = &quot;darkgrey&quot;, fill = &quot;cyan&quot;, binwidth = 200)+ theme( axis.text=element_text(size=14, color=&quot;black&quot;), axis.title=element_text(size=16), panel.background=element_rect(fill=&quot;white&quot;, colour=&quot;black&quot;)) + ylab(&quot;n locations&quot;) + xlab(&quot;Time diff between locations (secs)&quot;) p4 ## Summarise results by tripID SummaryTimeDiff &lt;- timeDiff %&gt;% group_by(tripID) %&gt;% summarise(mean_timegap_secs = mean(delta_secs), median_timegap_secs = median(delta_secs), min_timegap_secs = min(delta_secs), max_timegap_secs = max(delta_secs)) %&gt;% ## time in days mutate(max_timegap_days = max_timegap_secs / 86400) %&gt;% mutate(max_timegap_days = round(max_timegap_days,2)) %&gt;% data.frame() ## View results SummaryTimeDiff ## tripID mean_timegap_secs median_timegap_secs ## 1 19_Tag17600_Z-9_01 11970.777778 1205.0 ## 2 19_Tag17600_Z-9_02 4352.500000 3998.5 ## 3 19_Tag17600_Z-9_04 5313.181818 1484.0 ## 4 19_Tag17600_Z-9_05 6794.486111 1209.0 ## 5 19_Tag17600_Z-9_06 4058.000000 1729.0 ## 6 19_Tag17604_Z-7_01 2965.107143 1733.0 ## 7 19_Tag17604_Z-7_02 2912.125000 1318.0 ## 8 19_Tag17604_Z-7_03 11122.333333 1791.0 ## 9 19_Tag17604_Z-7_04 13012.000000 5800.0 ## 10 19_Tag17604_Z-7_05 12121.947368 8574.0 ## 11 19_Tag17604_Z-7_07 7920.500000 7955.0 ## 12 19_Tag17617_Z-4 (2nd Parent)_01 2415.029412 2400.0 ## 13 19_Tag17617_Z-4 (2nd Parent)_02 2547.454545 2403.0 ## 14 19_Tag17617_Z-4 (2nd Parent)_03 3823.846154 2405.0 ## 15 19_Tag17617_Z-4 (2nd Parent)_04 3291.722222 2504.0 ## 16 19_Tag17617_Z-4 (2nd Parent)_05 3539.823529 2499.0 ## 17 19_Tag17644_Z-13_01 7976.161765 1203.5 ## 18 19_Tag17644_Z-13_02 6112.746988 1214.0 ## 19 19_Tag17652_Z-2_01 1432.074074 1202.0 ## 20 19_Tag17652_Z-2_02 2007.417910 1226.0 ## 21 19_Tag17652_Z-2_03 3721.812500 2500.5 ## 22 19_Tag17652_Z-2_05 2717.000000 2406.0 ## 23 19_Tag17652_Z-2_06 2582.482759 2401.0 ## 24 19_Tag17652_Z-2_07 2891.789474 2493.0 ## 25 19_Tag17652_Z-2_08 4179.000000 3600.0 ## 26 19_Tag17652_Z-2_09 3972.941176 3605.0 ## 27 19_Tag17652_Z-2_10 4415.562500 3650.0 ## 28 19_Tag17652_Z-2_11 4004.151899 3605.0 ## 29 19_Tag17652_Z-2_12 3990.466667 3605.0 ## 30 19_Tag17704_Z-11_01 2451.392857 1203.5 ## 31 19_Tag17704_Z-11_02 2133.272727 1206.0 ## 32 19_Tag17704_Z-11_03 4387.333333 1204.0 ## 33 19_Tag17704_Z-11_05 12077.395833 3996.0 ## 34 19_Tag17704_Z-11_06 4914.666667 2815.0 ## 35 19_Tag17704_Z-11_07 10325.250000 2404.0 ## 36 19_Tag17704_Z-11_08 12840.085106 7194.0 ## 37 19_Tag17735_Z-3 (RAW DATA MISSING)_01 2923.529412 2442.0 ## 38 19_Tag17735_Z-3 (RAW DATA MISSING)_02 3404.714286 2458.5 ## 39 19_Tag17735_Z-3 (RAW DATA MISSING)_03 3934.333333 3676.0 ## 40 19_Tag17735_Z-3 (RAW DATA MISSING)_04 4123.571429 3753.0 ## 41 19_Tag17735_Z-3 (RAW DATA MISSING)_05 4593.000000 3738.0 ## 42 19_Tag17735_Z-3 (RAW DATA MISSING)_06 5386.000000 3656.0 ## 43 19_Tag17735_Z-3 (RAW DATA MISSING)_07 4984.802469 3768.0 ## 44 19_Tag17735_Z-3 (RAW DATA MISSING)_08 3468.666667 2604.0 ## 45 19_Tag17735_Z-3 (RAW DATA MISSING)_09 3653.384615 2562.0 ## 46 19_Tag17735_Z-3 (RAW DATA MISSING)_10 3906.681818 2636.0 ## 47 19_Tag17735_Z-3 (RAW DATA MISSING)_11 2677.000000 2429.0 ## 48 19_Tag17735_Z-3 (RAW DATA MISSING)_12 5232.819672 3884.0 ## 49 19_Tag17735_Z-3 (RAW DATA MISSING)_13 6697.438356 4153.0 ## 50 19_Tag40066_Z-14_01 1531.490196 1205.0 ## 51 19_Tag40066_Z-14_02 1716.656250 1214.0 ## 52 19_Tag40066_Z-14_03 7168.166667 6397.0 ## 53 19_Tag40066_Z-14_04 4608.500000 2838.5 ## 54 19_Tag40066_Z-14_05 11184.400000 3886.0 ## 55 19_Tag40066_Z-14_06 10592.615385 2476.0 ## 56 19_Tag40066_Z-14_07 4969.100000 4964.0 ## 57 19_Tag40066_Z-14_08 7770.000000 5633.0 ## 58 19_Tag40066_Z-14_09 21523.777778 9549.0 ## 59 19_Tag40066_Z-14_10 19439.285714 17101.0 ## 60 19_Tag40066_Z-14_12 10079.500000 6852.0 ## 61 19_Tag40069_Z-6_01 2968.600000 2452.0 ## 62 19_Tag40069_Z-6_02 5782.236364 2689.0 ## 63 19_Tag40069_Z-6_03 4578.769231 3821.0 ## 64 19_Tag40069_Z-6_04 4654.846154 3609.5 ## 65 19_Tag40069_Z-6_06 3654.333333 3602.0 ## 66 19_Tag40069_Z-6_07 4098.071429 3600.5 ## 67 19_Tag40069_Z-6_08 4646.615385 3622.0 ## 68 19_Tag40069_Z-6_09 5494.000000 5016.0 ## 69 19_Tag40069_Z-6_10 4677.923077 3931.0 ## 70 19_Tag40069_Z-6_11 5144.727273 4430.0 ## 71 19_Tag40069_Z-6_12 5017.454545 3779.0 ## 72 19_Tag40069_Z-6_13 5047.896552 3612.0 ## 73 19_Tag40069_Z-6_14 5311.916667 3870.5 ## 74 19_Tag40069_Z-6_15 9678.000000 5653.5 ## 75 19_Tag40073_Z-1_01 1451.047619 1201.0 ## 76 19_Tag40073_Z-1_02 1511.108108 1204.0 ## 77 19_Tag40073_Z-1_03 1505.897436 1208.0 ## 78 19_Tag40073_Z-1_04 3562.866667 2697.0 ## 79 19_Tag40073_Z-1_05 2896.500000 2449.0 ## 80 19_Tag40073_Z-1_06 2694.739130 2402.0 ## 81 19_Tag40073_Z-1_07 3116.105263 2592.0 ## 82 19_Tag40073_Z-1_08 2518.400000 2400.0 ## 83 19_Tag40073_Z-1_09 3352.277778 2408.5 ## 84 19_Tag40073_Z-1_10 3315.794521 2405.0 ## 85 19_Tag40073_Z-1_11 2535.458333 2401.0 ## 86 19_Tag40073_Z-1_12 2922.894737 2401.0 ## 87 19_Tag40073_Z-1_13 3423.294118 2663.0 ## 88 19_Tag40073_Z-1_14 3321.125000 2415.5 ## 89 19_Tag40073_Z-1_15 3332.421053 2848.0 ## 90 19_Tag40073_Z-1_16 3635.179775 2418.0 ## 91 19_Tag40078_Z-3 (2nd Parent)_01 1603.576923 1203.5 ## 92 19_Tag40086_Z-11 (2nd Parent)_01 2464.285714 1221.0 ## 93 19_Tag40086_Z-11 (2nd Parent)_02 4371.000000 1366.0 ## 94 19_Tag40086_Z-11 (2nd Parent)_03 9979.694545 2400.0 ## 95 19_Tag40086_Z-11 (2nd Parent)_06 13046.333333 6241.0 ## 96 19_Tag40094_Z-16_01 17066.600000 1800.0 ## 97 19_Tag40118_Z-2 (2nd Parent)_01 1200.000000 1200.0 ## 98 19_Tag40118_Z-2 (2nd Parent)_02 2647.428571 1296.0 ## 99 19_Tag40118_Z-2 (2nd Parent)_03 2923.326531 1252.0 ## 100 19_Tag40118_Z-2 (2nd Parent)_04 3005.500000 1925.0 ## 101 19_Tag40118_Z-2 (2nd Parent)_05 4280.500000 1715.5 ## 102 19_Tag40118_Z-2 (2nd Parent)_06 3202.526316 1206.0 ## 103 19_Tag40118_Z-2 (2nd Parent)_07 2554.318681 1205.0 ## 104 19_Tag40118_Z-2 (2nd Parent)_08 3185.150000 1200.0 ## 105 19_Tag40118_Z-2 (2nd Parent)_09 3469.722222 1205.5 ## 106 19_Tag40118_Z-2 (2nd Parent)_10 3698.214286 1204.5 ## 107 19_Tag40118_Z-2 (2nd Parent)_13 8984.571429 5934.0 ## 108 19_Tag40118_Z-2 (2nd Parent)_14 6705.600000 3642.0 ## 109 19_Tag40133_Z-15_01 1198.875000 1198.5 ## 110 19_Tag40133_Z-15_02 6351.166667 4269.5 ## 111 19_Tag40133_Z-15_03 9949.354839 2401.0 ## 112 19_Tag40133_Z-15_06 10099.000000 8972.0 ## 113 19_Tag40133_Z-15_08 3735.909091 2416.0 ## 114 19_Tag40133_Z-15_10 7574.666667 5371.5 ## 115 19_Tag40133_Z-15_11 12588.200000 2404.0 ## 116 19_Tag40138_Z-17_01 5195.703704 1208.0 ## 117 19_Tag40138_Z-17_03 7335.763006 2400.0 ## 118 19_Tag40138_Z-17_04 9568.785714 6034.5 ## 119 19_Tag40138_Z-17_05 6846.197917 3700.0 ## 120 19_Tag40170_Z-12_01 1217.691176 1200.0 ## 121 19_Tag40170_Z-12_02 1200.200000 1200.0 ## 122 19_Tag40170_Z-12_04 2504.391304 2400.0 ## 123 19_Tag40170_Z-12_05 2504.304348 2400.0 ## 124 19_Tag40170_Z-12_06 2399.875000 2400.0 ## 125 19_Tag40170_Z-12_07 2399.800000 2400.0 ## 126 19_Tag40170_Z-12_08 2504.260870 2400.0 ## 127 19_Tag40170_Z-12_09 2618.181818 2400.0 ## 128 19_Tag40170_Z-12_10 2495.760000 2399.0 ## 129 19_Tag40170_Z-12_11 3599.800000 3600.0 ## 130 19_Tag40170_Z-12_12 3599.700000 3600.0 ## 131 19_Tag40177_Z-17 (2nd Parent)_01 3154.833333 1272.0 ## 132 19_Tag40177_Z-17 (2nd Parent)_02 2760.090909 1950.0 ## 133 19_Tag40177_Z-17 (2nd Parent)_03 2969.222222 1467.5 ## 134 19_Tag40177_Z-17 (2nd Parent)_04 2592.692708 1204.0 ## 135 19_Tag40177_Z-17 (2nd Parent)_05 3397.650000 2262.5 ## 136 19_Tag40177_Z-17 (2nd Parent)_06 3159.500000 2204.0 ## 137 19_Tag40177_Z-17 (2nd Parent)_07 3174.857143 1751.0 ## 138 19_Tag40177_Z-17 (2nd Parent)_08 4109.000000 2080.0 ## 139 19_Tag40177_Z-17 (2nd Parent)_09 2879.343348 1203.0 ## 140 19_Tag40182_Z-4_01 2400.151515 2400.0 ## 141 19_Tag40182_Z-4_02 2550.882353 2400.0 ## 142 19_Tag40182_Z-4_03 2446.074074 2402.0 ## 143 19_Tag40182_Z-4_04 4275.285714 3602.0 ## 144 19_Tag40182_Z-4_05 4666.931034 3628.0 ## 145 19_Tag40182_Z-4_06 5595.395349 3604.0 ## 146 19_Tag40182_Z-4_07 4688.250000 3914.5 ## 147 19_Tag40182_Z-4_08 4797.571429 4011.0 ## 148 19_Tag40182_Z-4_09 3911.058824 3602.0 ## 149 19_Tag40182_Z-4_10 4851.529412 3763.0 ## 150 19_Tag40182_Z-4_11 5446.333333 4110.5 ## 151 19_Tag40182_Z-4_12 4526.636364 3671.0 ## 152 19_Tag40182_Z-4_13 7577.750000 7529.5 ## 153 19_Tag40182_Z-4_14 12042.600000 7651.0 ## 154 20_Tag17600_Z-170_01 2860.368421 1451.0 ## 155 20_Tag17600_Z-170_02 4255.916667 1935.5 ## 156 20_Tag17600_Z-170_03 2403.260870 1712.0 ## 157 20_Tag17600_Z-170_04 3562.000000 1203.0 ## 158 20_Tag17600_Z-170_05 2943.666667 2034.5 ## 159 20_Tag17600_Z-170_06 3717.466667 1279.0 ## 160 20_Tag17600_Z-170_07 2188.480000 1239.0 ## 161 20_Tag17600_Z-170_08 3349.687500 1332.5 ## 162 20_Tag17600_Z-170_09 4134.230769 2405.0 ## 163 20_Tag17600_Z-170_10 4420.909091 3076.0 ## 164 20_Tag17600_Z-170_11 4307.142857 3284.0 ## 165 20_Tag17600_Z-170_12 4904.545455 4029.0 ## 166 20_Tag17604_Z-95_01 1800.346154 1202.5 ## 167 20_Tag17604_Z-95_03 3328.352941 2347.0 ## 168 20_Tag17604_Z-95_04 3708.733333 1668.0 ## 169 20_Tag17604_Z-95_05 5773.000000 1248.0 ## 170 20_Tag17604_Z-95_06 8958.200000 7644.0 ## 171 20_Tag17604_Z-95_07 12119.545455 1201.0 ## 172 20_Tag17604_Z-95_08 15574.777778 3668.0 ## 173 20_Tag17604_Z-95_09 43546.000000 34250.0 ## 174 20_Tag17604_Z-95_10 9722.000000 2404.0 ## 175 20_Tag17604_Z-95_11 5484.000000 2513.0 ## 176 20_Tag17604_Z-95_12 2992.700000 2265.0 ## 177 20_Tag17604_Z-95_13 12209.000000 1202.0 ## 178 20_Tag17604_Z-95_14 4358.933333 2602.0 ## 179 20_Tag17604_Z-95_15 5589.300000 1850.5 ## 180 20_Tag17604_Z-95_16 5403.666667 1831.5 ## 181 20_Tag17604_Z-95_17 3894.650000 1202.5 ## 182 20_Tag17644_Z-106_01 2847.611111 1202.5 ## 183 20_Tag17644_Z-106_02 5180.229167 1200.5 ## 184 20_Tag17644_Z-106_03 5105.500000 1203.0 ## 185 20_Tag17644_Z-106_04 6102.000000 1201.0 ## 186 20_Tag17644_Z-106_05 4719.329545 1201.0 ## 187 20_Tag17644_Z-106_06 4203.600000 1586.0 ## 188 20_Tag17677_Z-170 (2nd Parent)_01 18697.800000 4836.0 ## 189 20_Tag17677_Z-170 (2nd Parent)_02 4427.776786 1201.0 ## 190 20_Tag17677_Z-170 (2nd Parent)_03 8044.380952 1202.0 ## 191 20_Tag40024_Z-178 (2nd Parent)_01 1446.333333 1207.5 ## 192 20_Tag40024_Z-178 (2nd Parent)_02 1426.600000 1201.0 ## 193 20_Tag40024_Z-178 (2nd Parent)_03 4919.636364 1253.0 ## 194 20_Tag40024_Z-178 (2nd Parent)_04 2432.800000 1281.0 ## 195 20_Tag40024_Z-178 (2nd Parent)_05 3229.882353 1257.0 ## 196 20_Tag40024_Z-178 (2nd Parent)_06 4134.714286 1200.0 ## 197 20_Tag40024_Z-178 (2nd Parent)_08 3322.711864 1202.0 ## 198 20_Tag40024_Z-178 (2nd Parent)_09 5319.416667 1204.5 ## 199 20_Tag40024_Z-178 (2nd Parent)_10 8273.428571 1335.0 ## 200 20_Tag40024_Z-178 (2nd Parent)_11 5768.454545 1201.0 ## 201 20_Tag40024_Z-178 (2nd Parent)_12 7764.111111 1204.5 ## 202 20_Tag40024_Z-178 (2nd Parent)_13 6386.571429 3152.0 ## 203 20_Tag40024_Z-178 (2nd Parent)_14 13321.000000 6989.0 ## 204 20_Tag40039_Z-15 (2nd Parent)_01 1583.675000 1204.0 ## 205 20_Tag40039_Z-15 (2nd Parent)_02 1353.893617 1205.0 ## 206 20_Tag40039_Z-15 (2nd Parent)_03 2173.500000 1247.0 ## 207 20_Tag40039_Z-15 (2nd Parent)_04 1863.647059 1203.0 ## 208 20_Tag40039_Z-15 (2nd Parent)_05 1761.114286 1205.0 ## 209 20_Tag40039_Z-15 (2nd Parent)_06 2187.000000 2398.5 ## 210 20_Tag40039_Z-15 (2nd Parent)_07 2914.571429 2406.0 ## 211 20_Tag40039_Z-15 (2nd Parent)_08 2896.400000 2585.5 ## 212 20_Tag40039_Z-15 (2nd Parent)_09 3885.189189 2582.0 ## 213 20_Tag40039_Z-15 (2nd Parent)_10 3275.295455 2682.0 ## 214 20_Tag40039_Z-15 (2nd Parent)_11 2774.923077 1205.0 ## 215 20_Tag40039_Z-15 (2nd Parent)_12 2722.280000 1598.0 ## 216 20_Tag40039_Z-15 (2nd Parent)_13 4179.728814 1205.0 ## 217 20_Tag40073_Z-131 (2nd Parent)_01 1549.000000 1205.0 ## 218 20_Tag40073_Z-131 (2nd Parent)_02 1870.307692 1397.0 ## 219 20_Tag40073_Z-131 (2nd Parent)_03 2320.203125 1360.0 ## 220 20_Tag40073_Z-131 (2nd Parent)_04 2320.142857 1270.0 ## 221 20_Tag40073_Z-131 (2nd Parent)_05 4014.266667 3249.0 ## 222 20_Tag40073_Z-131 (2nd Parent)_06 4246.357143 3095.5 ## 223 20_Tag40073_Z-131 (2nd Parent)_07 4080.214286 3493.0 ## 224 20_Tag40073_Z-131 (2nd Parent)_08 3760.571429 2739.0 ## 225 20_Tag40073_Z-131 (2nd Parent)_09 4896.583333 3799.0 ## 226 20_Tag40073_Z-131 (2nd Parent)_10 5732.535714 3860.5 ## 227 20_Tag40073_Z-131 (2nd Parent)_11 6122.600000 3597.5 ## 228 20_Tag40073_Z-131 (2nd Parent)_12 3568.058824 2990.0 ## 229 20_Tag40073_Z-131 (2nd Parent)_13 5928.111111 4525.0 ## 230 20_Tag40073_Z-131 (2nd Parent)_14 4437.000000 3628.5 ## 231 20_Tag40073_Z-131 (2nd Parent)_15 3178.150000 2928.0 ## 232 20_Tag40073_Z-131 (2nd Parent)_16 3191.157895 2833.0 ## 233 20_Tag40073_Z-131 (2nd Parent)_17 4931.782609 2841.5 ## 234 20_Tag40078_Z-178_01 1967.281250 1251.5 ## 235 20_Tag40078_Z-178_02 1733.965517 1203.0 ## 236 20_Tag40078_Z-178_03 1973.823529 1226.0 ## 237 20_Tag40078_Z-178_04 2223.103448 1446.0 ## 238 20_Tag40094_Z-131_01 2098.292683 1203.0 ## 239 20_Tag40094_Z-131_02 3929.810345 1776.5 ## 240 20_Tag40094_Z-131_03 3776.000000 1315.0 ## 241 20_Tag40094_Z-131_04 4934.845238 1201.0 ## 242 20_Tag40094_Z-131_05 6620.333333 6260.5 ## 243 20_Tag40094_Z-131_06 14867.000000 7024.0 ## 244 20_Tag40094_Z-131_07 5619.684211 2214.5 ## 245 20_Tag40094_Z-131_08 3537.500000 1201.5 ## 246 20_Tag40094_Z-131_09 4503.000000 2181.0 ## 247 20_Tag40094_Z-131_10 5998.727273 1203.0 ## 248 20_Tag40094_Z-131_11 2864.814815 1203.0 ## 249 20_Tag40094_Z-131_12 4906.058824 1206.0 ## 250 20_Tag40094_Z-131_13 3781.609756 1206.0 ## 251 20_Tag40118_Z-175_01 3284.235294 1444.0 ## 252 20_Tag40118_Z-175_02 3347.882353 1373.0 ## 253 20_Tag40118_Z-175_03 2647.058824 2154.0 ## 254 20_Tag40118_Z-175_04 2453.000000 1526.5 ## 255 20_Tag40118_Z-175_05 3578.153846 1819.0 ## 256 20_Tag40118_Z-175_06 4685.100000 1472.5 ## 257 20_Tag40118_Z-175_07 8926.500000 3240.0 ## 258 20_Tag40118_Z-175_08 4537.090909 3099.0 ## 259 20_Tag40118_Z-175_09 5353.900000 4584.5 ## 260 20_Tag40118_Z-175_10 2169.125000 1886.0 ## 261 20_Tag40118_Z-175_11 3335.600000 2502.0 ## 262 20_Tag40118_Z-175_12 3950.857143 2994.0 ## 263 20_Tag40118_Z-175_13 6943.875000 5236.0 ## 264 20_Tag40118_Z-175_14 3613.352941 2577.0 ## 265 20_Tag40118_Z-175_15 3274.588235 2594.0 ## 266 20_Tag40118_Z-175_16 3907.764706 2737.0 ## 267 20_Tag40118_Z-175_17 4117.270270 2841.0 ## 268 20_Tag40118_Z-175_18 3732.133333 2726.0 ## 269 20_Tag40118_Z-175_19 2628.380952 1933.0 ## 270 20_Tag40118_Z-175_20 2463.913043 1928.0 ## 271 20_Tag40118_Z-175_21 3166.751592 1370.0 ## 272 20_Tag40118_Z-175_22 2834.000000 2420.0 ## 273 20_Tag40118_Z-175_23 2227.144231 1240.0 ## 274 20_Tag40133_Z-1 (2nd Parent)_01 1294.148936 1200.0 ## 275 20_Tag40133_Z-1 (2nd Parent)_02 1796.536585 1208.5 ## 276 20_Tag40133_Z-1 (2nd Parent)_03 1615.463415 1323.0 ## 277 20_Tag40133_Z-1 (2nd Parent)_04 2821.000000 2452.5 ## 278 20_Tag40133_Z-1 (2nd Parent)_05 2726.738636 2400.0 ## 279 20_Tag40133_Z-1 (2nd Parent)_06 2890.500000 2403.5 ## 280 20_Tag40133_Z-1 (2nd Parent)_07 3549.871795 2408.0 ## 281 20_Tag40133_Z-1 (2nd Parent)_08 3401.250000 2629.0 ## 282 20_Tag40133_Z-1 (2nd Parent)_09 2826.373494 2401.0 ## 283 20_Tag40133_Z-1 (2nd Parent)_10 2914.521739 2411.0 ## 284 20_Tag40133_Z-1 (2nd Parent)_11 2712.900000 2402.5 ## 285 20_Tag40133_Z-1 (2nd Parent)_12 3270.722222 2453.0 ## 286 20_Tag40133_Z-1 (2nd Parent)_13 2906.771930 2401.0 ## 287 20_Tag40193_Z-13 (2nd Parent)_01 4228.333333 3603.5 ## 288 20_Tag40193_Z-13 (2nd Parent)_02 4272.416667 3665.0 ## 289 20_Tag40193_Z-13 (2nd Parent)_03 9009.114286 3988.0 ## 290 20_Tag40859_Z-179_01 4299.750000 1433.5 ## 291 20_Tag41108_Z-95 (2nd Parent)_01 1659.804598 1204.0 ## 292 20_Tag41108_Z-95 (2nd Parent)_02 2425.967742 1797.0 ## 293 20_Tag41108_Z-95 (2nd Parent)_03 1598.394737 1353.0 ## 294 20_Tag41108_Z-95 (2nd Parent)_04 1946.812500 1209.5 ## 295 20_Tag41108_Z-95 (2nd Parent)_05 2871.190476 1692.0 ## 296 20_Tag41108_Z-95 (2nd Parent)_06 2403.000000 1845.0 ## 297 20_Tag41108_Z-95 (2nd Parent)_07 3972.200000 3514.0 ## 298 20_Tag41108_Z-95 (2nd Parent)_08 3095.421053 2406.0 ## 299 20_Tag41108_Z-95 (2nd Parent)_09 3521.611111 3141.5 ## 300 20_Tag41108_Z-95 (2nd Parent)_10 3089.979167 2412.0 ## 301 20_Tag41108_Z-95 (2nd Parent)_11 3324.400000 2607.5 ## 302 20_Tag41108_Z-95 (2nd Parent)_12 4521.692308 3242.0 ## 303 20_Tag41108_Z-95 (2nd Parent)_13 8483.896552 3065.0 ## 304 20_Tag41108_Z-95 (2nd Parent)_14 8180.620690 3984.0 ## 305 20_Tag41108_Z-95 (2nd Parent)_15 5906.200000 2564.5 ## min_timegap_secs max_timegap_secs max_timegap_days ## 1 1194 87842 1.02 ## 2 1200 10478 0.12 ## 3 1196 30663 0.35 ## 4 1194 82303 0.95 ## 5 1195 18016 0.21 ## 6 1199 8904 0.10 ## 7 1200 20248 0.23 ## 8 1195 79438 0.92 ## 9 2894 56196 0.65 ## 10 2397 31853 0.37 ## 11 2398 14803 0.17 ## 12 1199 6296 0.07 ## 13 2393 5411 0.06 ## 14 2393 30424 0.35 ## 15 2397 6840 0.08 ## 16 2395 14346 0.17 ## 17 1194 65797 0.76 ## 18 1193 62651 0.73 ## 19 1190 3565 0.04 ## 20 1193 22457 0.26 ## 21 2395 9069 0.10 ## 22 2390 5148 0.06 ## 23 2393 7779 0.09 ## 24 2395 5266 0.06 ## 25 2395 23922 0.28 ## 26 3595 7605 0.09 ## 27 3599 7739 0.09 ## 28 3592 9326 0.11 ## 29 3596 7767 0.09 ## 30 1197 13949 0.16 ## 31 1197 9175 0.11 ## 32 1197 21956 0.25 ## 33 2393 56912 0.66 ## 34 2398 13942 0.16 ## 35 2393 59759 0.69 ## 36 3593 85464 0.99 ## 37 2400 7980 0.09 ## 38 2395 26298 0.30 ## 39 3597 7398 0.09 ## 40 3595 5366 0.06 ## 41 3599 9523 0.11 ## 42 3594 16483 0.19 ## 43 2394 21593 0.25 ## 44 2394 9511 0.11 ## 45 2396 12628 0.15 ## 46 2395 18735 0.22 ## 47 2395 4184 0.05 ## 48 3595 13224 0.15 ## 49 3594 41815 0.48 ## 50 1191 3805 0.04 ## 51 1194 7593 0.09 ## 52 2473 14965 0.17 ## 53 2407 13036 0.15 ## 54 2398 36048 0.42 ## 55 2394 77485 0.90 ## 56 2395 9761 0.11 ## 57 2424 18115 0.21 ## 58 3596 67044 0.78 ## 59 4362 46261 0.54 ## 60 3594 36814 0.43 ## 61 2395 6049 0.07 ## 62 2394 112755 1.31 ## 63 3596 9973 0.12 ## 64 3597 25196 0.29 ## 65 3595 4383 0.05 ## 66 3596 10125 0.12 ## 67 3594 8728 0.10 ## 68 3597 11352 0.13 ## 69 3598 7592 0.09 ## 70 3620 13722 0.16 ## 71 3595 14060 0.16 ## 72 3596 22571 0.26 ## 73 3598 11304 0.13 ## 74 4798 19939 0.23 ## 75 1193 4155 0.05 ## 76 1193 4349 0.05 ## 77 1193 4087 0.05 ## 78 2394 6339 0.07 ## 79 2393 5211 0.06 ## 80 2397 5955 0.07 ## 81 2394 4900 0.06 ## 82 2396 4895 0.06 ## 83 2393 10957 0.13 ## 84 2392 10227 0.12 ## 85 2393 4803 0.06 ## 86 2394 4988 0.06 ## 87 2394 7729 0.09 ## 88 2393 11983 0.14 ## 89 2398 5935 0.07 ## 90 2391 19152 0.22 ## 91 1194 7066 0.08 ## 92 1195 10813 0.13 ## 93 1199 38827 0.45 ## 94 1193 254116 2.94 ## 95 3597 43321 0.50 ## 96 1298 71850 0.83 ## 97 1199 1201 0.01 ## 98 1193 9920 0.11 ## 99 1193 21739 0.25 ## 100 1193 10909 0.13 ## 101 1197 32856 0.38 ## 102 1196 18122 0.21 ## 103 1194 23220 0.27 ## 104 1194 20039 0.23 ## 105 1193 15215 0.18 ## 106 1195 25392 0.29 ## 107 1197 23431 0.27 ## 108 1200 22212 0.26 ## 109 1196 1203 0.01 ## 110 1201 20233 0.23 ## 111 2395 105548 1.22 ## 112 2527 20578 0.24 ## 113 2397 10119 0.12 ## 114 2402 16608 0.19 ## 115 2397 28484 0.33 ## 116 1195 79645 0.92 ## 117 1194 98046 1.13 ## 118 2400 32094 0.37 ## 119 3594 60399 0.70 ## 120 1193 2399 0.03 ## 121 1192 1208 0.01 ## 122 2395 4800 0.06 ## 123 2394 4798 0.06 ## 124 2394 2406 0.03 ## 125 2394 2406 0.03 ## 126 2393 4801 0.06 ## 127 2394 4794 0.06 ## 128 2394 4806 0.06 ## 129 3594 3606 0.04 ## 130 3596 3606 0.04 ## 131 1193 16141 0.19 ## 132 1197 8320 0.10 ## 133 1194 12636 0.15 ## 134 1190 16720 0.19 ## 135 1195 11702 0.14 ## 136 1196 7861 0.09 ## 137 1194 14754 0.17 ## 138 1190 13989 0.16 ## 139 1191 30191 0.35 ## 140 2394 2406 0.03 ## 141 2395 4805 0.06 ## 142 2395 3231 0.04 ## 143 3593 10417 0.12 ## 144 3594 21370 0.25 ## 145 3593 29188 0.34 ## 146 3599 7794 0.09 ## 147 3593 8512 0.10 ## 148 3594 5862 0.07 ## 149 3601 10864 0.13 ## 150 3599 9842 0.11 ## 151 3601 7583 0.09 ## 152 3826 13324 0.15 ## 153 3599 29484 0.34 ## 154 1193 12898 0.15 ## 155 1195 20638 0.24 ## 156 1194 9878 0.11 ## 157 1194 30361 0.35 ## 158 1198 10394 0.12 ## 159 1195 17638 0.20 ## 160 1194 7008 0.08 ## 161 1194 15725 0.18 ## 162 1193 13829 0.16 ## 163 2400 10417 0.12 ## 164 2395 10509 0.12 ## 165 2399 12334 0.14 ## 166 1194 6048 0.07 ## 167 1193 10908 0.13 ## 168 1198 15200 0.18 ## 169 1197 49038 0.57 ## 170 1199 22573 0.26 ## 171 1197 46503 0.54 ## 172 1195 68526 0.79 ## 173 2524 89374 1.03 ## 174 2399 39623 0.46 ## 175 1199 27215 0.31 ## 176 1198 7941 0.09 ## 177 1196 56009 0.65 ## 178 1197 21335 0.25 ## 179 1193 33992 0.39 ## 180 1196 32957 0.38 ## 181 1193 37006 0.43 ## 182 1198 10277 0.12 ## 183 1195 41429 0.48 ## 184 1198 25529 0.30 ## 185 1198 36684 0.42 ## 186 1194 56382 0.65 ## 187 1199 17128 0.20 ## 188 1203 78426 0.91 ## 189 1193 41269 0.48 ## 190 1193 86879 1.01 ## 191 1194 4452 0.05 ## 192 1193 4764 0.06 ## 193 1199 35581 0.41 ## 194 1193 10651 0.12 ## 195 1194 13284 0.15 ## 196 1193 23370 0.27 ## 197 1193 27494 0.32 ## 198 1194 17387 0.20 ## 199 1193 27407 0.32 ## 200 1198 28963 0.34 ## 201 1193 54504 0.63 ## 202 1195 24038 0.28 ## 203 1199 36344 0.42 ## 204 1192 4656 0.05 ## 205 1194 3260 0.04 ## 206 1195 10297 0.12 ## 207 1194 12515 0.14 ## 208 1195 5621 0.07 ## 209 1198 5222 0.06 ## 210 2392 8788 0.10 ## 211 2395 4836 0.06 ## 212 2394 26374 0.31 ## 213 2394 9629 0.11 ## 214 1192 19298 0.22 ## 215 1199 10282 0.12 ## 216 1194 47305 0.55 ## 217 1195 3987 0.05 ## 218 1199 5077 0.06 ## 219 1192 22631 0.26 ## 220 1193 8049 0.09 ## 221 1201 13653 0.16 ## 222 2393 18533 0.21 ## 223 2397 10592 0.12 ## 224 2400 8110 0.09 ## 225 2398 10416 0.12 ## 226 2396 30407 0.35 ## 227 2400 28809 0.33 ## 228 2394 7369 0.09 ## 229 2402 19297 0.22 ## 230 2402 10958 0.13 ## 231 2394 6758 0.08 ## 232 2397 6730 0.08 ## 233 2394 21533 0.25 ## 234 1195 6367 0.07 ## 235 1194 6052 0.07 ## 236 1193 5623 0.07 ## 237 1196 12306 0.14 ## 238 1193 16365 0.19 ## 239 1195 26174 0.30 ## 240 1198 17025 0.20 ## 241 1193 81078 0.94 ## 242 1202 15554 0.18 ## 243 1199 45084 0.52 ## 244 1193 19638 0.23 ## 245 1194 17039 0.20 ## 246 1194 18962 0.22 ## 247 1194 19855 0.23 ## 248 1195 19938 0.23 ## 249 1193 42092 0.49 ## 250 1194 33496 0.39 ## 251 1194 18242 0.21 ## 252 1193 11891 0.14 ## 253 1197 4862 0.06 ## 254 1193 8143 0.09 ## 255 1194 15736 0.18 ## 256 1198 31345 0.36 ## 257 1193 25498 0.30 ## 258 1194 9950 0.12 ## 259 1194 17821 0.21 ## 260 1197 4563 0.05 ## 261 2393 6745 0.08 ## 262 2394 7451 0.09 ## 263 2398 12932 0.15 ## 264 2394 9371 0.11 ## 265 2398 5349 0.06 ## 266 2399 10998 0.13 ## 267 2394 22303 0.26 ## 268 2406 11733 0.14 ## 269 1195 8603 0.10 ## 270 1193 6207 0.07 ## 271 1193 37412 0.43 ## 272 1194 6132 0.07 ## 273 1191 10499 0.12 ## 274 1194 2823 0.03 ## 275 1193 23979 0.28 ## 276 1195 2711 0.03 ## 277 2395 5069 0.06 ## 278 2393 9235 0.11 ## 279 2394 8836 0.10 ## 280 2393 26398 0.31 ## 281 2396 10132 0.12 ## 282 2394 12276 0.14 ## 283 2394 5590 0.06 ## 284 2394 5675 0.07 ## 285 2390 10634 0.12 ## 286 2394 25644 0.30 ## 287 3595 7203 0.08 ## 288 3595 7237 0.08 ## 289 3596 115169 1.33 ## 290 1195 10918 0.13 ## 291 1194 25145 0.29 ## 292 1198 10174 0.12 ## 293 1194 3904 0.05 ## 294 1194 7784 0.09 ## 295 1198 9840 0.11 ## 296 1198 6821 0.08 ## 297 2395 9900 0.11 ## 298 2394 5883 0.07 ## 299 2398 5697 0.07 ## 300 2394 9518 0.11 ## 301 2393 8756 0.10 ## 302 2398 12709 0.15 ## 303 2394 34433 0.40 ## 304 2395 31484 0.36 ## 305 2395 29146 0.34 head(SummaryTimeDiff) ## tripID mean_timegap_secs median_timegap_secs min_timegap_secs ## 1 19_Tag17600_Z-9_01 11970.777778 1205.0 1194 ## 2 19_Tag17600_Z-9_02 4352.500000 3998.5 1200 ## 3 19_Tag17600_Z-9_04 5313.181818 1484.0 1196 ## 4 19_Tag17600_Z-9_05 6794.486111 1209.0 1194 ## 5 19_Tag17600_Z-9_06 4058.000000 1729.0 1195 ## 6 19_Tag17604_Z-7_01 2965.107143 1733.0 1199 ## max_timegap_secs max_timegap_days ## 1 87842 1.02 ## 2 10478 0.12 ## 3 30663 0.35 ## 4 82303 0.95 ## 5 18016 0.21 ## 6 8904 0.10 29.20.1 Sampling interval review Consider whether the sampling interval of your tracking data is appropriate for formally running the track2KBA functions. Remember, the time differences between each of your location points should be equal (or close enough to equal) across all location points and individuals tracked. If the time difference between location points is not equal, the outputs you generate from track2KBA will not be valid because the underlying kernel density analysis implemented within the track2KBA functions will be invalid (because you need points evenly spaced in time for this analysis to be valid). Therefore, review the summary of your recorded sampling interval data: #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Review sampling interval ---- #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Average sampling interval of all data ## median of median time gaps in minutes median(SummaryTimeDiff$median_timegap_secs)/60 ## [1] 40.03333333 ## Sort data by maximum time gap first - then view. ## Consider if you have any outlier trips with massively different time gaps. SummaryTimeDiff %&gt;% arrange(-max_timegap_secs) %&gt;% head(10) ## tripID mean_timegap_secs median_timegap_secs ## 1 19_Tag40086_Z-11 (2nd Parent)_03 9979.694545 2400 ## 2 20_Tag40193_Z-13 (2nd Parent)_03 9009.114286 3988 ## 3 19_Tag40069_Z-6_02 5782.236364 2689 ## 4 19_Tag40133_Z-15_03 9949.354839 2401 ## 5 19_Tag40138_Z-17_03 7335.763006 2400 ## 6 20_Tag17604_Z-95_09 43546.000000 34250 ## 7 19_Tag17600_Z-9_01 11970.777778 1205 ## 8 20_Tag17677_Z-170 (2nd Parent)_03 8044.380952 1202 ## 9 19_Tag17704_Z-11_08 12840.085106 7194 ## 10 19_Tag17600_Z-9_05 6794.486111 1209 ## min_timegap_secs max_timegap_secs max_timegap_days ## 1 1193 254116 2.94 ## 2 3596 115169 1.33 ## 3 2394 112755 1.31 ## 4 2395 105548 1.22 ## 5 1194 98046 1.13 ## 6 2524 89374 1.03 ## 7 1194 87842 1.02 ## 8 1193 86879 1.01 ## 9 3593 85464 0.99 ## 10 1194 82303 0.95 ## simple histogram hist(SummaryTimeDiff$max_timegap_days) If you have trips where the maximum time gap in seconds (max_timegap_secs) is extremely different to the median of median time gaps in minutes, then it’s likely you need to consider why this is the case for those trips. - Did you specify tripSplit parameters incorrectly? - Does the data require further cleaning in some other way? - What else to consider NOTE: you should be aware of what the original pre-programmed sampling interval was. How do your results compare to this interval? 29.21 track2KBA: Interpolating data for analysis If you have gaps between time stamps in your tracking data, you need to fill these gaps for the purpose of the track2KBA protocol. It’s likely you will need to do this for many other tracking data analyses. Broadly speaking, there are two key ways to fill the gaps in your tracking data, a process known as interpolation. These two ways include: Simpler linear interpolation More advanced interpolation options that try account for where the animal could have moved (e.g. CRAWL) Typically, for flying seabirds, where gaps in tracking data while birds at sea are less likely because birds do not typically dive underwater for durations as long as non-flying seabirds, linear interpolation should serve as a suitable starting point. More advanced interpolation methods may be required for diving seabirds, or other diving marine predators. See the appendix which offers an introduction to other available interpolation methods 29.21.1 Interpolating data: using only at-sea locations REMINDER: Removing trip start and end points near the colony for the interpolation (as completed above), especially if using more advanced methods like CRAWL, can support filtering only points at sea when you estimate birds should be moving, as opposed to trying to deal with sections of trips when the bird is actually stationary on land. Other methods do support interpolation of data when animals are on land. These are not yet detailed in the toolkit. 29.21.2 Interpolating data: choice of sampling interval Reminder: The average sampling interval of all data (i.e. the median of median time gaps in minutes) was 40.0333333333 minutes. Set your interpolation interval accordingly. You can use these results and knowledge of your programmed sampling interval. Here we set the interpolation interval in minutes. interp.interval = 30 29.21.3 Interpolating data: linear interpolation implementation Prior to implementing linear interpolation using available tools, we save a relevant version of the metadata because the interpolation functions often remove some of the additional metadata which are useful for later steps in the track2kba protocol. ## review data object for analysis head(data.frame(trips_df),2) ## x y dttm dataset_id ## 1200 42.811528 16.885531 2019-05-24 00:49:09 populated-upon-upload-STDB ## 2159 42.812029 16.886907 2019-05-24 01:09:03 populated-upon-upload-STDB ## scientific_name common_name site_name colony_name lat_colony ## 1200 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## 2159 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z 42.774893 ## lon_colony device ID track_id ## 1200 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 2159 16.875649 GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage ## 1200 populated-upon-upload-STDB adult unknown chick-rearing ## 2159 populated-upon-upload-STDB adult unknown chick-rearing ## breed_status date_gmt time_gmt argos_quality equinox ## 1200 populated-upon-upload-STDB 2019-05-24 00:49:09 NA NA ## 2159 populated-upon-upload-STDB 2019-05-24 01:09:03 NA NA ## Filter optional Latitude Longitude DateTime tripID ## 1200 TRUE TRUE 42.811528 16.885531 2019-05-24 00:49:09 19_Tag17600_Z-9_01 ## 2159 TRUE TRUE 42.812029 16.886907 2019-05-24 01:09:03 19_Tag17600_Z-9_01 ## X Y Returns StartsOut ColDist dataGroup.Longitude ## 1200 16.885531 42.811528 Yes Yes 4149.301440 16.885531 ## 2159 16.886907 42.812029 Yes Yes 4226.997952 16.886907 ## dataGroup.Latitude optional.1 ## 1200 42.811528 TRUE ## 2159 42.812029 TRUE ## trips_meta &lt;- trips_df %&gt;% dplyr::select(scientific_name, common_name, site_name, colony_name, lat_colony, lon_colony, bird_id = ID, trip_id = tripID, age, sex, breed_stage, breed_status) %&gt;% group_by(trip_id) %&gt;% slice(1) ## Compare and ensure same number of trips across data length(unique(trips_df$tripID)) ## [1] 305 length(unique(trips_meta$trip_id)) ## [1] 305 Now perform the interpolation on each unique trip in your data. ## start blank df trips_interp_df &lt;- data.frame() for(i in 1:length(unique(trips_df$tripID))){ temp &lt;- trips_df %&gt;% dplyr::filter(tripID == unique(trips_df$tripID)[i]) ## Linear interpolation ----- ## Apply linear interpolation step to speed filtered only data ## create ltraj object trip_lt &lt;- as.ltraj(xy = bind_cols(x = temp$Longitude, y = temp$Latitude), date = temp$DateTime, id = temp$tripID) ## Linearly interpolate/re-sample tracks according to chose interval (specified in seconds) trip_interp &lt;- redisltraj(trip_lt, interp.interval * 60, type=&quot;time&quot;) head(trip_interp) ## convert back into format for track2KBA - dataframe for now trip_interp &lt;- ld(trip_interp) %&gt;% dplyr::mutate(Longitude = x, Latitude = y) ## bind back onto dataframe trips_interp_df &lt;- rbind(trips_interp_df, trip_interp) ## remove temporary items before next loop iteration rm(temp,trip_lt) ## Print loop progress print(paste(&quot;Trip &quot;, i, &quot; of &quot;, length(unique(trips_df$tripID)), &quot; processed&quot;)) } ## [1] &quot;Trip 1 of 305 processed&quot; ## [1] &quot;Trip 2 of 305 processed&quot; ## [1] &quot;Trip 3 of 305 processed&quot; ## [1] &quot;Trip 4 of 305 processed&quot; ## [1] &quot;Trip 5 of 305 processed&quot; ## [1] &quot;Trip 6 of 305 processed&quot; ## [1] &quot;Trip 7 of 305 processed&quot; ## [1] &quot;Trip 8 of 305 processed&quot; ## [1] &quot;Trip 9 of 305 processed&quot; ## [1] &quot;Trip 10 of 305 processed&quot; ## [1] &quot;Trip 11 of 305 processed&quot; ## [1] &quot;Trip 12 of 305 processed&quot; ## [1] &quot;Trip 13 of 305 processed&quot; ## [1] &quot;Trip 14 of 305 processed&quot; ## [1] &quot;Trip 15 of 305 processed&quot; ## [1] &quot;Trip 16 of 305 processed&quot; ## [1] &quot;Trip 17 of 305 processed&quot; ## [1] &quot;Trip 18 of 305 processed&quot; ## [1] &quot;Trip 19 of 305 processed&quot; ## [1] &quot;Trip 20 of 305 processed&quot; ## [1] &quot;Trip 21 of 305 processed&quot; ## [1] &quot;Trip 22 of 305 processed&quot; ## [1] &quot;Trip 23 of 305 processed&quot; ## [1] &quot;Trip 24 of 305 processed&quot; ## [1] &quot;Trip 25 of 305 processed&quot; ## [1] &quot;Trip 26 of 305 processed&quot; ## [1] &quot;Trip 27 of 305 processed&quot; ## [1] &quot;Trip 28 of 305 processed&quot; ## [1] &quot;Trip 29 of 305 processed&quot; ## [1] &quot;Trip 30 of 305 processed&quot; ## [1] &quot;Trip 31 of 305 processed&quot; ## [1] &quot;Trip 32 of 305 processed&quot; ## [1] &quot;Trip 33 of 305 processed&quot; ## [1] &quot;Trip 34 of 305 processed&quot; ## [1] &quot;Trip 35 of 305 processed&quot; ## [1] &quot;Trip 36 of 305 processed&quot; ## [1] &quot;Trip 37 of 305 processed&quot; ## [1] &quot;Trip 38 of 305 processed&quot; ## [1] &quot;Trip 39 of 305 processed&quot; ## [1] &quot;Trip 40 of 305 processed&quot; ## [1] &quot;Trip 41 of 305 processed&quot; ## [1] &quot;Trip 42 of 305 processed&quot; ## [1] &quot;Trip 43 of 305 processed&quot; ## [1] &quot;Trip 44 of 305 processed&quot; ## [1] &quot;Trip 45 of 305 processed&quot; ## [1] &quot;Trip 46 of 305 processed&quot; ## [1] &quot;Trip 47 of 305 processed&quot; ## [1] &quot;Trip 48 of 305 processed&quot; ## [1] &quot;Trip 49 of 305 processed&quot; ## [1] &quot;Trip 50 of 305 processed&quot; ## [1] &quot;Trip 51 of 305 processed&quot; ## [1] &quot;Trip 52 of 305 processed&quot; ## [1] &quot;Trip 53 of 305 processed&quot; ## [1] &quot;Trip 54 of 305 processed&quot; ## [1] &quot;Trip 55 of 305 processed&quot; ## [1] &quot;Trip 56 of 305 processed&quot; ## [1] &quot;Trip 57 of 305 processed&quot; ## [1] &quot;Trip 58 of 305 processed&quot; ## [1] &quot;Trip 59 of 305 processed&quot; ## [1] &quot;Trip 60 of 305 processed&quot; ## [1] &quot;Trip 61 of 305 processed&quot; ## [1] &quot;Trip 62 of 305 processed&quot; ## [1] &quot;Trip 63 of 305 processed&quot; ## [1] &quot;Trip 64 of 305 processed&quot; ## [1] &quot;Trip 65 of 305 processed&quot; ## [1] &quot;Trip 66 of 305 processed&quot; ## [1] &quot;Trip 67 of 305 processed&quot; ## [1] &quot;Trip 68 of 305 processed&quot; ## [1] &quot;Trip 69 of 305 processed&quot; ## [1] &quot;Trip 70 of 305 processed&quot; ## [1] &quot;Trip 71 of 305 processed&quot; ## [1] &quot;Trip 72 of 305 processed&quot; ## [1] &quot;Trip 73 of 305 processed&quot; ## [1] &quot;Trip 74 of 305 processed&quot; ## [1] &quot;Trip 75 of 305 processed&quot; ## [1] &quot;Trip 76 of 305 processed&quot; ## [1] &quot;Trip 77 of 305 processed&quot; ## [1] &quot;Trip 78 of 305 processed&quot; ## [1] &quot;Trip 79 of 305 processed&quot; ## [1] &quot;Trip 80 of 305 processed&quot; ## [1] &quot;Trip 81 of 305 processed&quot; ## [1] &quot;Trip 82 of 305 processed&quot; ## [1] &quot;Trip 83 of 305 processed&quot; ## [1] &quot;Trip 84 of 305 processed&quot; ## [1] &quot;Trip 85 of 305 processed&quot; ## [1] &quot;Trip 86 of 305 processed&quot; ## [1] &quot;Trip 87 of 305 processed&quot; ## [1] &quot;Trip 88 of 305 processed&quot; ## [1] &quot;Trip 89 of 305 processed&quot; ## [1] &quot;Trip 90 of 305 processed&quot; ## [1] &quot;Trip 91 of 305 processed&quot; ## [1] &quot;Trip 92 of 305 processed&quot; ## [1] &quot;Trip 93 of 305 processed&quot; ## [1] &quot;Trip 94 of 305 processed&quot; ## [1] &quot;Trip 95 of 305 processed&quot; ## [1] &quot;Trip 96 of 305 processed&quot; ## [1] &quot;Trip 97 of 305 processed&quot; ## [1] &quot;Trip 98 of 305 processed&quot; ## [1] &quot;Trip 99 of 305 processed&quot; ## [1] &quot;Trip 100 of 305 processed&quot; ## [1] &quot;Trip 101 of 305 processed&quot; ## [1] &quot;Trip 102 of 305 processed&quot; ## [1] &quot;Trip 103 of 305 processed&quot; ## [1] &quot;Trip 104 of 305 processed&quot; ## [1] &quot;Trip 105 of 305 processed&quot; ## [1] &quot;Trip 106 of 305 processed&quot; ## [1] &quot;Trip 107 of 305 processed&quot; ## [1] &quot;Trip 108 of 305 processed&quot; ## [1] &quot;Trip 109 of 305 processed&quot; ## [1] &quot;Trip 110 of 305 processed&quot; ## [1] &quot;Trip 111 of 305 processed&quot; ## [1] &quot;Trip 112 of 305 processed&quot; ## [1] &quot;Trip 113 of 305 processed&quot; ## [1] &quot;Trip 114 of 305 processed&quot; ## [1] &quot;Trip 115 of 305 processed&quot; ## [1] &quot;Trip 116 of 305 processed&quot; ## [1] &quot;Trip 117 of 305 processed&quot; ## [1] &quot;Trip 118 of 305 processed&quot; ## [1] &quot;Trip 119 of 305 processed&quot; ## [1] &quot;Trip 120 of 305 processed&quot; ## [1] &quot;Trip 121 of 305 processed&quot; ## [1] &quot;Trip 122 of 305 processed&quot; ## [1] &quot;Trip 123 of 305 processed&quot; ## [1] &quot;Trip 124 of 305 processed&quot; ## [1] &quot;Trip 125 of 305 processed&quot; ## [1] &quot;Trip 126 of 305 processed&quot; ## [1] &quot;Trip 127 of 305 processed&quot; ## [1] &quot;Trip 128 of 305 processed&quot; ## [1] &quot;Trip 129 of 305 processed&quot; ## [1] &quot;Trip 130 of 305 processed&quot; ## [1] &quot;Trip 131 of 305 processed&quot; ## [1] &quot;Trip 132 of 305 processed&quot; ## [1] &quot;Trip 133 of 305 processed&quot; ## [1] &quot;Trip 134 of 305 processed&quot; ## [1] &quot;Trip 135 of 305 processed&quot; ## [1] &quot;Trip 136 of 305 processed&quot; ## [1] &quot;Trip 137 of 305 processed&quot; ## [1] &quot;Trip 138 of 305 processed&quot; ## [1] &quot;Trip 139 of 305 processed&quot; ## [1] &quot;Trip 140 of 305 processed&quot; ## [1] &quot;Trip 141 of 305 processed&quot; ## [1] &quot;Trip 142 of 305 processed&quot; ## [1] &quot;Trip 143 of 305 processed&quot; ## [1] &quot;Trip 144 of 305 processed&quot; ## [1] &quot;Trip 145 of 305 processed&quot; ## [1] &quot;Trip 146 of 305 processed&quot; ## [1] &quot;Trip 147 of 305 processed&quot; ## [1] &quot;Trip 148 of 305 processed&quot; ## [1] &quot;Trip 149 of 305 processed&quot; ## [1] &quot;Trip 150 of 305 processed&quot; ## [1] &quot;Trip 151 of 305 processed&quot; ## [1] &quot;Trip 152 of 305 processed&quot; ## [1] &quot;Trip 153 of 305 processed&quot; ## [1] &quot;Trip 154 of 305 processed&quot; ## [1] &quot;Trip 155 of 305 processed&quot; ## [1] &quot;Trip 156 of 305 processed&quot; ## [1] &quot;Trip 157 of 305 processed&quot; ## [1] &quot;Trip 158 of 305 processed&quot; ## [1] &quot;Trip 159 of 305 processed&quot; ## [1] &quot;Trip 160 of 305 processed&quot; ## [1] &quot;Trip 161 of 305 processed&quot; ## [1] &quot;Trip 162 of 305 processed&quot; ## [1] &quot;Trip 163 of 305 processed&quot; ## [1] &quot;Trip 164 of 305 processed&quot; ## [1] &quot;Trip 165 of 305 processed&quot; ## [1] &quot;Trip 166 of 305 processed&quot; ## [1] &quot;Trip 167 of 305 processed&quot; ## [1] &quot;Trip 168 of 305 processed&quot; ## [1] &quot;Trip 169 of 305 processed&quot; ## [1] &quot;Trip 170 of 305 processed&quot; ## [1] &quot;Trip 171 of 305 processed&quot; ## [1] &quot;Trip 172 of 305 processed&quot; ## [1] &quot;Trip 173 of 305 processed&quot; ## [1] &quot;Trip 174 of 305 processed&quot; ## [1] &quot;Trip 175 of 305 processed&quot; ## [1] &quot;Trip 176 of 305 processed&quot; ## [1] &quot;Trip 177 of 305 processed&quot; ## [1] &quot;Trip 178 of 305 processed&quot; ## [1] &quot;Trip 179 of 305 processed&quot; ## [1] &quot;Trip 180 of 305 processed&quot; ## [1] &quot;Trip 181 of 305 processed&quot; ## [1] &quot;Trip 182 of 305 processed&quot; ## [1] &quot;Trip 183 of 305 processed&quot; ## [1] &quot;Trip 184 of 305 processed&quot; ## [1] &quot;Trip 185 of 305 processed&quot; ## [1] &quot;Trip 186 of 305 processed&quot; ## [1] &quot;Trip 187 of 305 processed&quot; ## [1] &quot;Trip 188 of 305 processed&quot; ## [1] &quot;Trip 189 of 305 processed&quot; ## [1] &quot;Trip 190 of 305 processed&quot; ## [1] &quot;Trip 191 of 305 processed&quot; ## [1] &quot;Trip 192 of 305 processed&quot; ## [1] &quot;Trip 193 of 305 processed&quot; ## [1] &quot;Trip 194 of 305 processed&quot; ## [1] &quot;Trip 195 of 305 processed&quot; ## [1] &quot;Trip 196 of 305 processed&quot; ## [1] &quot;Trip 197 of 305 processed&quot; ## [1] &quot;Trip 198 of 305 processed&quot; ## [1] &quot;Trip 199 of 305 processed&quot; ## [1] &quot;Trip 200 of 305 processed&quot; ## [1] &quot;Trip 201 of 305 processed&quot; ## [1] &quot;Trip 202 of 305 processed&quot; ## [1] &quot;Trip 203 of 305 processed&quot; ## [1] &quot;Trip 204 of 305 processed&quot; ## [1] &quot;Trip 205 of 305 processed&quot; ## [1] &quot;Trip 206 of 305 processed&quot; ## [1] &quot;Trip 207 of 305 processed&quot; ## [1] &quot;Trip 208 of 305 processed&quot; ## [1] &quot;Trip 209 of 305 processed&quot; ## [1] &quot;Trip 210 of 305 processed&quot; ## [1] &quot;Trip 211 of 305 processed&quot; ## [1] &quot;Trip 212 of 305 processed&quot; ## [1] &quot;Trip 213 of 305 processed&quot; ## [1] &quot;Trip 214 of 305 processed&quot; ## [1] &quot;Trip 215 of 305 processed&quot; ## [1] &quot;Trip 216 of 305 processed&quot; ## [1] &quot;Trip 217 of 305 processed&quot; ## [1] &quot;Trip 218 of 305 processed&quot; ## [1] &quot;Trip 219 of 305 processed&quot; ## [1] &quot;Trip 220 of 305 processed&quot; ## [1] &quot;Trip 221 of 305 processed&quot; ## [1] &quot;Trip 222 of 305 processed&quot; ## [1] &quot;Trip 223 of 305 processed&quot; ## [1] &quot;Trip 224 of 305 processed&quot; ## [1] &quot;Trip 225 of 305 processed&quot; ## [1] &quot;Trip 226 of 305 processed&quot; ## [1] &quot;Trip 227 of 305 processed&quot; ## [1] &quot;Trip 228 of 305 processed&quot; ## [1] &quot;Trip 229 of 305 processed&quot; ## [1] &quot;Trip 230 of 305 processed&quot; ## [1] &quot;Trip 231 of 305 processed&quot; ## [1] &quot;Trip 232 of 305 processed&quot; ## [1] &quot;Trip 233 of 305 processed&quot; ## [1] &quot;Trip 234 of 305 processed&quot; ## [1] &quot;Trip 235 of 305 processed&quot; ## [1] &quot;Trip 236 of 305 processed&quot; ## [1] &quot;Trip 237 of 305 processed&quot; ## [1] &quot;Trip 238 of 305 processed&quot; ## [1] &quot;Trip 239 of 305 processed&quot; ## [1] &quot;Trip 240 of 305 processed&quot; ## [1] &quot;Trip 241 of 305 processed&quot; ## [1] &quot;Trip 242 of 305 processed&quot; ## [1] &quot;Trip 243 of 305 processed&quot; ## [1] &quot;Trip 244 of 305 processed&quot; ## [1] &quot;Trip 245 of 305 processed&quot; ## [1] &quot;Trip 246 of 305 processed&quot; ## [1] &quot;Trip 247 of 305 processed&quot; ## [1] &quot;Trip 248 of 305 processed&quot; ## [1] &quot;Trip 249 of 305 processed&quot; ## [1] &quot;Trip 250 of 305 processed&quot; ## [1] &quot;Trip 251 of 305 processed&quot; ## [1] &quot;Trip 252 of 305 processed&quot; ## [1] &quot;Trip 253 of 305 processed&quot; ## [1] &quot;Trip 254 of 305 processed&quot; ## [1] &quot;Trip 255 of 305 processed&quot; ## [1] &quot;Trip 256 of 305 processed&quot; ## [1] &quot;Trip 257 of 305 processed&quot; ## [1] &quot;Trip 258 of 305 processed&quot; ## [1] &quot;Trip 259 of 305 processed&quot; ## [1] &quot;Trip 260 of 305 processed&quot; ## [1] &quot;Trip 261 of 305 processed&quot; ## [1] &quot;Trip 262 of 305 processed&quot; ## [1] &quot;Trip 263 of 305 processed&quot; ## [1] &quot;Trip 264 of 305 processed&quot; ## [1] &quot;Trip 265 of 305 processed&quot; ## [1] &quot;Trip 266 of 305 processed&quot; ## [1] &quot;Trip 267 of 305 processed&quot; ## [1] &quot;Trip 268 of 305 processed&quot; ## [1] &quot;Trip 269 of 305 processed&quot; ## [1] &quot;Trip 270 of 305 processed&quot; ## [1] &quot;Trip 271 of 305 processed&quot; ## [1] &quot;Trip 272 of 305 processed&quot; ## [1] &quot;Trip 273 of 305 processed&quot; ## [1] &quot;Trip 274 of 305 processed&quot; ## [1] &quot;Trip 275 of 305 processed&quot; ## [1] &quot;Trip 276 of 305 processed&quot; ## [1] &quot;Trip 277 of 305 processed&quot; ## [1] &quot;Trip 278 of 305 processed&quot; ## [1] &quot;Trip 279 of 305 processed&quot; ## [1] &quot;Trip 280 of 305 processed&quot; ## [1] &quot;Trip 281 of 305 processed&quot; ## [1] &quot;Trip 282 of 305 processed&quot; ## [1] &quot;Trip 283 of 305 processed&quot; ## [1] &quot;Trip 284 of 305 processed&quot; ## [1] &quot;Trip 285 of 305 processed&quot; ## [1] &quot;Trip 286 of 305 processed&quot; ## [1] &quot;Trip 287 of 305 processed&quot; ## [1] &quot;Trip 288 of 305 processed&quot; ## [1] &quot;Trip 289 of 305 processed&quot; ## [1] &quot;Trip 290 of 305 processed&quot; ## [1] &quot;Trip 291 of 305 processed&quot; ## [1] &quot;Trip 292 of 305 processed&quot; ## [1] &quot;Trip 293 of 305 processed&quot; ## [1] &quot;Trip 294 of 305 processed&quot; ## [1] &quot;Trip 295 of 305 processed&quot; ## [1] &quot;Trip 296 of 305 processed&quot; ## [1] &quot;Trip 297 of 305 processed&quot; ## [1] &quot;Trip 298 of 305 processed&quot; ## [1] &quot;Trip 299 of 305 processed&quot; ## [1] &quot;Trip 300 of 305 processed&quot; ## [1] &quot;Trip 301 of 305 processed&quot; ## [1] &quot;Trip 302 of 305 processed&quot; ## [1] &quot;Trip 303 of 305 processed&quot; ## [1] &quot;Trip 304 of 305 processed&quot; ## [1] &quot;Trip 305 of 305 processed&quot; ## review it worked by checking total number of unique trips and comparing to original length(unique(trips_df$tripID)) ## [1] 305 length(unique(trips_interp_df$id)) ## [1] 305 ## compare total number of points nrow(trips_df) ## [1] 9511 nrow(trips_interp_df) ## [1] 21693 Bind metadata back after interpolation. Because we lost the useful metadata after the interpolation step, bind this data back onto the outputted data following interpolation ## First create columns with same names trips_interp_df &lt;- trips_interp_df %&gt;% rename(trip_id = id) ## Now bind the metadata back trips_interp_df &lt;- left_join(trips_interp_df, trips_meta, by = &quot;trip_id&quot;) ## Review data head(trips_interp_df,2) ## x y date dx dy ## 1 16.88553100 42.8115280 2019-05-24 00:49:09 0.002069365 0.0001677 ## 2 16.88760037 42.8116957 2019-05-24 01:19:09 0.002553635 -0.0004107 ## dist dt R2n abs.angle rel.angle ## 1 0.002076149030 1800 0.000000000e+00 0.08086264312 NA ## 2 0.002586450503 1800 4.310394793e-06 -0.15946401320 -0.2403266563 ## trip_id burst pkey ## 1 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01.2019-05-24 00:49:09 ## 2 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01.2019-05-24 01:19:09 ## Longitude Latitude scientific_name common_name site_name ## 1 16.88553100 42.8115280 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 16.88760037 42.8116957 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony bird_id age sex breed_stage ## 1 Z 42.774893 16.875649 19_Tag17600_Z-9 adult unknown chick-rearing ## 2 Z 42.774893 16.875649 19_Tag17600_Z-9 adult unknown chick-rearing ## breed_status ## 1 populated-upon-upload-STDB ## 2 populated-upon-upload-STDB 29.22 Save data Save relevant data for next steps of track2kba implementation ## create new folder within current working directory where you will save data ## first create the name of the species and the file path you need ## also use gsub to replace spaces within character strings (words) with a &quot;-&quot; species_name &lt;- gsub(&quot; &quot;, &quot;-&quot;, trips_interp_df$scientific_name[1]) ## print the name for checking print(species_name) ## [1] &quot;Puffinus-yelkouan&quot; ## then create the new folder within current working directory path_to_folder &lt;- paste(&quot;./data-testing/tracking-data/&quot;, species_name,&quot;-track2kba-files&quot;, sep=&quot;&quot;) ## print the file path name for checking print(path_to_folder) ## [1] &quot;./data-testing/tracking-data/Puffinus-yelkouan-track2kba-files&quot; ## Check if folder exists, and if it does not, then make a new folder if (!file.exists(path_to_folder)) { # If it does not exist, create a new folder dir.create(path_to_folder) print(paste(&quot;Created folder:&quot;, path_to_folder)) } else { # do nothing, but let us know the folder exists already print(paste(&quot;Folder already exists:&quot;, path_to_folder)) } ## [1] &quot;Folder already exists: ./data-testing/tracking-data/Puffinus-yelkouan-track2kba-files&quot; ## save updated file for next steps write.csv(trips_interp_df, ## cleaned tracking data file = paste0(path_to_folder,&quot;/&quot;,species_name, &quot;-input-tracks.csv&quot;), row.names = F) write.csv(sumTrips, ## summary of overall trips data file = paste0(path_to_folder,&quot;/&quot;,species_name, &quot;-input-summary.csv&quot;), row.names = F) "],["track2kba---central-place-foragers-analyse-cleanded-data.html", "30 Track2KBA - Central Place Foragers: Analyse cleanded data 30.1 What this chapter covers: 30.2 Where you can get example data for the chapter: 30.3 Description of data prefiltering for main track2kba analysis: 30.4 Load packages 30.5 Define object names for chapter 30.6 Read in file (or file created from previous chapter) 30.7 track2KBA: format data for use 30.8 track2kba:: projectTracks() 30.9 track2kba:: findScale() 30.10 track2kba: estSpaceUse() 30.11 track2kba:: mapKDE() 30.12 track2kba: review choice of smoothing parameter 30.13 track2kba::repAssess() 30.14 track2kba::findSite() 30.15 track2kba::mapSite() 30.16 track2kba::findSite(), further understanding 30.17 track2kba::findSite(), outputs explained 30.18 track2kba: Save key outputs 30.19 track2kba::findSite(), IBA / KBA assessment considerations 30.20 IBA assessment data preparation 30.21 SAVING OUTPUTS", " 30 Track2KBA - Central Place Foragers: Analyse cleanded data Analyses outlined in this chapter were performed in R version 4.3.2 (2023-10-31 ucrt) This chapter was last updated on 2024-02-23 30.1 What this chapter covers: Analysis of key data via the track2kba protocol Deriving a final site which could be used for conservation planning purposes (such as that of KBAs) 30.2 Where you can get example data for the chapter: This tutorial uses example data from a project led by the BirdLife International partner in Croatia: BIOM The citation for this data is: Zec et al. 2023 Example data is available upon request The prepared example data: See previous chapter 30.3 Description of data prefiltering for main track2kba analysis: Central place foraging data used for this tutorial have been prepared previously as follows: General review of spatial data Removing - if necessary - sections of tracks when animals were not tracked but devices were recording information. Arranging data chronologically and removing duplicate entries Speed filter for clearly erroneous location points Removing location points around the vicinty of the colony (as specified by the inner buffer parameter in earlier steps using track2kba functions) Removing data with too few location points Generating basic summary statistics of the tracking data Reviewing the sampling frequency of data (i.e. what frequncy you set your devices to record at versus what they actually recorded at) Linearly interpolating data to generate tracking information that approximates an even sampling interval Consider: When to clean data with respect to the steps above may depend on the type of animal you tracked and life-cycle stage the animal was tracked over. Non central place foraging data: If your data relates to a period when an animal was not exhibiting central place foraging, consider cleaning the data in line with steps above. However, you would not need to split tracks into trips and summarise data as above. The key thing is to have data approximating an equal sampling interval (i.e. data points evenly sampled in time) 30.4 Load packages Load required R packages for use with codes in this chapter: If the package(s) fails to load, you will need to install the relevant package(s). ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Load libraries -------------------------------------------------------------- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## sf package for spatial data analyses (i.e. vector files such as points, lines, polygons) library(sf) ## Tidyverse for data manipulation library(tidyverse) ## ggplot2 for plotting opionts library(ggplot2) ## rnaturalearth package for basemaps in R library(rnaturalearth) ## leaflet package for interactive maps in R #install.packages(&quot;leaflet&quot;) library(leaflet) ## library(purrr) library(furrr) #install.packages(&quot;track2KBA&quot;) library(track2KBA) ## for date time library(lubridate) ## for stats library(stats) ## speed filter library(trip) ## linear interpolation library(adehabitatLT) 30.5 Define object names for chapter Typically, if your data follows the same format as the examples in the chapter (and previous chapters), then below should be the only thing(s) you need to change. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Specify projections / store needed CRS definitions as variables ---- ## SEE: https://epsg.io/ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## world - unprojected coordinates # wgs84 &lt;- st_crs(&quot;EPSG:4326&quot;) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Source a relevant basemap (download / or load your own) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Source a world map from the rnaturalearth R package ## see details of function to change the type of map you get ## If you can&#39;t download this map - you may need to load a separate shapefile ## depicting a suitable basemap # worldmap &lt;- rnaturalearth::ne_download(scale = &quot;large&quot;, # type = &quot;countries&quot;, # category = &quot;cultural&quot;, # destdir = tempdir(), # load = TRUE, # returnclass = &quot;sf&quot;) 30.6 Read in file (or file created from previous chapter) ## read in the pre-filtered, cleaned tracking data trips_interp_df &lt;- read.csv(&quot;./data-testing/tracking-data/Puffinus-yelkouan-track2kba-files/Puffinus-yelkouan-input-tracks.csv&quot;) ## read in the summary data for the tracks sumTrips &lt;- read.csv(&quot;./data-testing/tracking-data/Puffinus-yelkouan-track2kba-files/Puffinus-yelkouan-input-summary.csv&quot;) 30.7 track2KBA: format data for use 30.7.1 track2KBA::formatFields() This function will help format your data to align with that required of track2KBA. In other words: for the track2KBA functions to work, your data needs to have certain columns named in the appropriate way. This function will help with that. We apply the formatting to the most recently filtered data. ## review current data head(data.frame(trips_interp_df),2) ## x y date dx dy ## 1 16.88553100 42.8115280 2019-05-24 00:49:09 0.002069365 0.0001677 ## 2 16.88760037 42.8116957 2019-05-24 01:19:09 0.002553635 -0.0004107 ## dist dt R2n abs.angle rel.angle ## 1 0.002076149030 1800 0.000000000e+00 0.08086264312 NA ## 2 0.002586450503 1800 4.310394793e-06 -0.15946401320 -0.2403266563 ## trip_id burst pkey ## 1 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01.2019-05-24 00:49:09 ## 2 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01.2019-05-24 01:19:09 ## Longitude Latitude scientific_name common_name site_name ## 1 16.88553100 42.8115280 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 16.88760037 42.8116957 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony bird_id age sex breed_stage ## 1 Z 42.774893 16.875649 19_Tag17600_Z-9 adult unknown chick-rearing ## 2 Z 42.774893 16.875649 19_Tag17600_Z-9 adult unknown chick-rearing ## breed_status ## 1 populated-upon-upload-STDB ## 2 populated-upon-upload-STDB ## Format the data BACK INTO key data fields to the standard used in track2KBA dataGroup_interp &lt;- formatFields( ## your input data.frame or tibble dataGroup = trips_interp_df, ## ID of the animal you tracked fieldID = &quot;bird_id&quot;, fieldDateTime = &quot;date&quot;, ## longitude of device fieldLon = &quot;Longitude&quot;, ## latitude of device fieldLat = &quot;Latitude&quot; ) ## Check output. Output is a data.frame head(dataGroup_interp,2) ## x y date dx dy ## 1 16.88553100 42.8115280 2019-05-24 00:49:09 0.002069365 0.0001677 ## 2 16.88760037 42.8116957 2019-05-24 01:19:09 0.002553635 -0.0004107 ## dist dt R2n abs.angle rel.angle ## 1 0.002076149030 1800 0.000000000e+00 0.08086264312 NA ## 2 0.002586450503 1800 4.310394793e-06 -0.15946401320 -0.2403266563 ## trip_id burst pkey ## 1 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01.2019-05-24 00:49:09 ## 2 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01 19_Tag17600_Z-9_01.2019-05-24 01:19:09 ## Longitude Latitude scientific_name common_name site_name ## 1 16.88553100 42.8115280 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## 2 16.88760037 42.8116957 Puffinus yelkouan Yelkouan Shearwater Lastovo SPA ## colony_name lat_colony lon_colony ID age sex breed_stage ## 1 Z 42.774893 16.875649 19_Tag17600_Z-9 adult unknown chick-rearing ## 2 Z 42.774893 16.875649 19_Tag17600_Z-9 adult unknown chick-rearing ## breed_status DateTime ## 1 populated-upon-upload-STDB 2019-05-24 00:49:09 ## 2 populated-upon-upload-STDB 2019-05-24 01:19:09 30.8 track2kba:: projectTracks() ## run the function tracks_interp &lt;- projectTracks(dataGroup = dataGroup_interp, projType = &#39;azim&#39;, custom=TRUE ) 30.9 track2kba:: findScale() findScale() provides options for setting the all-important smoothing parameter in the KDE. findScale() calculates candidate smoothing parameter values using different methods. Choosing the ‘optimal’ smoothing parameter is critical. See GitHub page. [Consider what further advice we can give to users regarding choice of smoothing parameter?] ## implement findScale function hVals &lt;- findScale( tracks = tracks_interp, scaleARS = TRUE, sumTrips = sumTrips) ## Review output hVals ## med_max_dist step_length mag href scaleARS ## 1 44.05 1.37 3.79 14.33 17 ## must choose between one of three smoothing parameters for further analyses ## smoothing parameter is distance in km. Read more in supporting documents. ## Review each outputted smoothing parameter option hVals$mag # affected by range of animal movement. Only works for central place foragers. ## [1] 3.79 hVals$href # sort of represents quality of data ## [1] 14.33 hVals$scaleARS # affected by quality of data and subsequent ability to determine scale at which animal interacts with environment. Learn more about First Passage Time analysis ## [1] 17 30.10 track2kba: estSpaceUse() Produce KDEs for each individual animal. NOTE: The grid cell size (i.e., grid resolution) should be less than the selected h value, otherwise the entire space use area of the animal may be encompassed in few cells. Guidance needed on choice of smoothing parameter [Guidance: Choice of smoothing parameter] Guidance on choice of UD [Guidance on choice of UD] KDE &lt;- estSpaceUse( tracks = tracks_interp, scale = hVals$mag, levelUD = 50, polyOut = TRUE ) 30.11 track2kba:: mapKDE() use the simple mapping function to get an overview of UDs for individuals ## Specify colony location if you have this. #colony &lt;- data.frame() ## mapKDE(KDE = KDE$UDPolygons, colony = NULL) # input your colony location if you have this, to view in plot 30.12 track2kba: review choice of smoothing parameter After applying estSpaceUse and viewing plot with mapKDE, at this step we should verify that the smoothing parameter value we selected is producing reasonable space use estimates, given what we know about our study animals. Are the core areas much larger than expected? Much smaller? If so, consider using a different value for the scale parameter in the estSpaceUse function. ## specify an individual ## 14 p = 7 ## convert to sf object trips_sf_IndBird &lt;- st_as_sf(tracks_interp) %&gt;% dplyr::filter(ID == unique(tracks_interp$ID)[p]) ## get the UD for a single individual ud_sf_IndBird &lt;- KDE$UDPolygons %&gt;% dplyr::filter(id == trips_sf_IndBird$ID[1]) %&gt;% st_transform(.,crs = st_crs(tracks_interp)) ## Plot OVERALL data again for first single individual plot(st_geometry(trips_sf_IndBird), cex = 0.5, pch = 1) ## and add the UD to the plot plot(st_geometry(ud_sf_IndBird),add=T, border = &quot;red&quot;) warning(&quot;Assess whether your selected smoothing parameter has resulted in sensible Utilisation Distributions.&quot;) 30.13 track2kba::repAssess() Estimate how representative this sample of animals is of the population. NOTE: iterations should be set to 100 at a minimum when running the script for analytical purposes. You can leave iterations as 1 when running the script for testing / exploratory purposes given this is a computer memory intensive task (i.e. it can take a long time). ## repr &lt;- repAssess( tracks = tracks_interp, KDE = KDE$KDE.Surface, levelUD = 50, iteration = 1, ## iterations should be set to 100 at a minimum when running the script officially bootTable = FALSE) 30.14 track2kba::findSite() Using findSite() we can identify areas where animals are overlapping in space and delineate boundaries of sites which may be suited to area-based conservation measures. When you have data that has a high representativeness score (i.e. &gt; 70%), this essentialy indicates that animals are regularly using the location identified from the findSite() function (according to the data). Therefore, the outputted site from the findSite() function is the site that could be used to consider data against the Key Biodiversity Area criteria, or could also be used to showcase important sites at local, national and regional scales. NOTE: The findSite() function is a computationally intensive task. It may take some time (several minutes) to run. Go make a cup of tea while you wait :) ## indicate the population size of your source populaiton. e.g. the population size ## of the colony from which you tracked birds. For KBA identification, this estimate ## should be in Mature Individuals. ## I.e. for seabird colonies: breeding pairs * 2 = mature individuals SourcePopulationSize = 1200 ## sf_use_s2(FALSE) ## findSite function Site_PolyTrue &lt;- findSite( KDE = KDE$KDE.Surface, represent = repr$out, levelUD = 50, popSize = SourcePopulationSize, polyOut = T ) ## review key outputs Site_PolyTrue ## Simple feature collection with 32 features and 3 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 12.05180343 ymin: 41.60260051 xmax: 19.77106214 ymax: 45.69826995 ## Geodetic CRS: WGS 84 ## First 10 features: ## N_animals N_IND potentialSite geometry ## 1 0.00000000 0 FALSE MULTIPOLYGON (((16.856635 4... ## 2 34.90059119 1 FALSE MULTIPOLYGON (((13.00827288... ## 3 69.80118238 2 FALSE MULTIPOLYGON (((12.69810649... ## 4 104.70177357 3 FALSE MULTIPOLYGON (((12.77142009... ## 5 139.60236477 4 TRUE MULTIPOLYGON (((13.00721945... ## 6 174.50295596 5 TRUE MULTIPOLYGON (((12.96094533... ## 7 209.40354715 6 TRUE MULTIPOLYGON (((12.95967702... ## 8 244.30413834 7 TRUE MULTIPOLYGON (((16.6171124 ... ## 9 279.20472953 8 TRUE MULTIPOLYGON (((16.70347028... ## 10 314.10532072 9 TRUE MULTIPOLYGON (((16.70347028... dim(Site_PolyTrue) ## [1] 32 4 Site_PolyTrue$potentialSite ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [13] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE 30.15 track2kba::mapSite() A simple plotting option for mapping the outputs of findSite(). ## plot option Sitemap_PolyTrue &lt;- mapSite(Site_PolyTrue, colony = NULL) ## review output object Sitemap_PolyTrue 30.16 track2kba::findSite(), further understanding If in findSite we instead specify polyOut=FALSE, our output will be a spatial grid of animal densities, with each cell representing the estimated number, or percentage of animals using that area. So this output is independent of the representativness-based importance threshold. i.e. the output indicates only the areas used by more or less individuals that you tracked, it does not give you a polygon that you would necessarily assess against IBA / KBA criteria. The output also does not use the representatives measure to estimate the OVERALL number of individuals that are likely using certain areas when you specify the popSize of your source population. # ## findSite with polyOut=FALSE # Site_PolyFalse &lt;- findSite( # KDE = KDE$KDE.Surface, # represent = repr$out, # levelUD = 50, # popSize = SourcePopulationSize, # polyOut = FALSE # ) # # ## review outputs # dim(Site_PolyFalse) # max(Site_PolyFalse@data$N_IND) # max(Site_PolyFalse@data$N_animals) # head(unique(Site_PolyFalse@data$ID_IND)) # # ## simple plot option # Sitemap_PolyFalse &lt;- mapSite(Site_PolyFalse, colony = colony) # # ## review output object # Sitemap_PolyFalse 30.17 track2kba::findSite(), outputs explained By default, findSite sets the threshold of site importance for the source population based on the degree of tracking sample representativeness following Lascelles et al. (2016): i.e., samples that are &gt;90%, 80-89%, 70-79%, and &lt;70% representative set the threshold for delineating a site as important for the local source population at 10%, 12.5%, 25%, and 50%, respectively) For example, for samples with representativeness of &gt;90%, the area that is considered potentially suitable for assessment against relevant criteria. eg. KBAs, is only that area used by 10% or MORE of the individuals from the source population. Any area used by 10% or LESS of the source population is not thought to sufficiently represent where the source population may be found, and hence is excluded from further assessment. The threshold rules were agreed upon by expert consensus. Note, when representativeness = 90% a bigger overall area in red is defined as potentially suitable for assessment against relevant criteria. when representativeness = 75% a SMALLER overall area in red is defined as potentially suitable for assessment against relevant criteria. This is because with a lower representativeness score, track2KBA provides a more conservative estimate of which areas can definitively be considered core areas regularly used by the sampled population. NOTE also: the total number of individuals estimated using the area is reduced when representativeness is lower. ie. basically, a lower total number of individuals are estimated to be using smaller areas when we are more unsure about how well the data likely represents the source population. 30.18 track2kba: Save key outputs [Consider saving key outputs here instead and aligning output names with the seaward extension outputs. Then we could have a single chapter where we deal with the outputs of both for assessing sites against relevant criteria] 30.19 track2kba::findSite(), IBA / KBA assessment considerations [Consider further text / options here] 30.20 IBA assessment data preparation NOTE, when polyOut = TRUE for function findSite(), the output includes a simple features object with polygons (represented by each row of data) that represent the number of overlapping UDs for individuals (N_IND), and the associated estimate of abundance (N_animals) within each of those polygons scaled according to the popSize and representativeness score. In track2KBA we don’t offer much advice about how to use the final outputs from findSite() for assessing data against various criteria, such as the IBA or KBA criteria. The text on GitHub (as of 18 Oct 2022), notes: ‘Then, we can combine all the polygons within the ’potentialSite’ area, and use, for example, the maximum number of individuals present in that area to assess whether it may merit identification as a Key Biodiversity Area according to the KBA standard.’, BUT: This does text does not describe how to deal with all the individual polygons that were representative, and may be quite separate from each other in space! ## To assess each polygon we first need to summarise the data further. ## First, we must determine how many and where each unique polygon is. Site.polygons &lt;- Site_PolyTrue %&gt;% ## filter to only include potentialSite&#39;s dplyr::filter(potentialSite==TRUE) %&gt;% ## union to create multipart polygon st_union(.) %&gt;% ## cast to create single part polygon object st_cast(., &quot;POLYGON&quot;) %&gt;% st_as_sf() %&gt;% ## add unique id for each polygon mutate(poly.id = 1:nrow(.)) ## Plot to review p &lt;- ggplot() + geom_sf(data = Site.polygons, aes(fill = as.factor(poly.id))) + #scale_fill_viridis_c(trans = &quot;sqrt&quot;, alpha = 1) + scale_color_viridis(discrete = TRUE) + guides(fill=guide_legend(title=&#39;Polygon&#39;)) + ## add the polygon labels geom_sf_text(data = Site.polygons, aes(label = poly.id), colour = &quot;black&quot;, size = 5) + ## remove x y labels theme(axis.title.x = element_blank()) + theme(axis.title.y = element_blank()) + # Title ggtitle(paste(&quot;Polygons for assessment against IBA criteria&quot;,sep=&quot;&quot;))+ theme(plot.title = element_text(hjust = 0.5)) p ## Second, considering that for each representative polygon, the maximum number ## of animals could technically spread across anywhere in the site, we need ## to get the maximum number of animals for each site. ## Merge the new unique polygons with the Site info and get overlapping data sf::sf_use_s2(FALSE) # run this if issues with st_intersection: https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data ## Using an intersection, find all the data from Site object (the findSite output) ## that intersects with Site.polygons object (the unique polygons) Site.polygons.data &lt;- st_intersection(Site.polygons, Site_PolyTrue) ## Summarise the data for each unique polygon. Site.polygons.data.summary &lt;- Site.polygons.data %&gt;% group_by(poly.id) %&gt;% summarise(N_animals_max = round(max(N_animals),0), N_IND_max = round(max(N_IND ),0)) %&gt;% st_drop_geometry() %&gt;% data.frame() ## bind this data back onto the spatial object Site.polygons &lt;- left_join(Site.polygons, Site.polygons.data.summary, by = &quot;poly.id&quot;) [Further guidance will need to be provided about the weird artefact sites you can get from the track2kba analysis] 30.21 SAVING OUTPUTS [May be better to save key outputs here for further assessment against relevant criteria] "],["track2kba-non-central-place-foraging-animal-movement.html", "31 Track2KBA: Non central place foraging animal movement", " 31 Track2KBA: Non central place foraging animal movement Chapter under final construction Increasingly, we are seeing the track2kba protocol outlined in (Beal, Oppel, et al. (2021)) being used to identify important sites for non central place foraging movement data; as also demonstrated in the manuscript through the White Stork (Ciconia ciconia) example. We aim to provide additional tutorials to showcase how the track2kba protocol can be applied to non central place foraging movement data. "],["sites-assessing-criteria.html", "32 Sites: Assessing criteria", " 32 Sites: Assessing criteria Chapter under final construction This chapter will take outputs from previous chapters and support users to test data against relevant Key Biodiversity Area and Important Bird and Biodiversity Area criteria. "],["sites-considerations-for-assessing-sites-against-criteria.html", "33 Sites: Considerations for assessing sites against criteria", " 33 Sites: Considerations for assessing sites against criteria Chapter under final construction This chapter will provide perspective in the context of marine megafauna data on topics such as “Aggregations”, “Predictably”, “Regularly”, and size of final sites. The KBA guidelines provide a key starting point for users to understand these topics further. "],["sites-merging-layers.html", "34 Sites: Merging layers", " 34 Sites: Merging layers Chapter under final construction Analysing data from a single species, at a single location, representative of its distribution during a single life-cycle stage, can be relatively straightforward in terms of identifying an important site. The more species layers of data you add to an important site identification exercise, the more complicated it can be to define the final important area that may be proposed to a relevant authority. This chapter will provide guidance and tools that can facilitate the process of merging data from multiple different sources. "],["sites-refining-boundaries.html", "35 Sites: Refining boundaries 35.1 Lessons from Key Biodiversity Areas 35.2 Lessons from Important Bird and Biodiversity Areas", " 35 Sites: Refining boundaries Chapter under final construction The analysis of spatial data can lead to outputs on maps that make ecological sense, but are not always entirely practical in terms of identifying an important site suited to management purposes. This chapter will guide users through some of the steps that might be considered for refining final outputs derived from analyses in previous chapters, so that these outputs may be more suited to particular management measures where necessary. Users may consider the following guidance: 35.1 Lessons from Key Biodiversity Areas As per the KBA Standards, a site is defined as: KBA Site: A geographical area on land and/or in water with defined ecological, physical, administrative or management boundaries that is actually or potentially manageable as a single unit (e.g. a protected area or other managed conservation unit). For this reason, large-scale biogeographic regions such as ecoregions, Endemic Bird Areas and Biodiversity Hotspots, and land-/seascapes containing multiple management units, are not considered to be sites. In the context of KBAs, “site” and “area” are used interchangeably. 35.2 Lessons from Important Bird and Biodiversity Areas From (Donald et al. (2019)): As far as possible, IBA boundaries are identified such that: the area inside the boundary is different in character, habitat or ornithological importance from surrounding areas; the IBA exists as a discrete manageable unit, such as a protected area, with or without buffer zones, and the site is an area that provides the requirements of the trigger species (i.e. those for which the site qualifies) while present, alone or in combination with networks of other sites. In many cases, delineation is straightforward, often dictated by obvious habitat boundaries or guided by existing protected area boundaries, land ownership or management boundaries. There is no set maximum or minimum size for an IBA, although the condition that the site forms a single manageable unit places a constraint on the maximum sensible area. "],["supporting-data-at-sea-survey-data.html", "36 Supporting data: At-sea survey data 36.1 At-sea survey data and tracking data 36.2 At-sea survey methodology 36.3 At-sea survey data for KBAs or IBAs 36.4 Citations", " 36 Supporting data: At-sea survey data Dedicated surveys to sample the abundance and distribution of seabirds are a basic requirement to understand bird densities within coastal and offshore marine environments. Distribution data can be obtained from observations collected during surveys within a predetermined spatio-temporal frame of reference or by sampling locations of individual animals using animal‐borne tracking devices. The former provide an area-based sampling perspective, also referred to as a Eulerian perspective in the oceanographic literature, whereas the latter provides an individual based sampling perspective, also referred to as a Langragian perspective (Phillips et al. (2019)). Area-based or Eulerian survey designs sample across a predetermined survey area using predetermined sampling locations or transects, which may or may not be replicated through time. The primary objective of this sampling approach is to obtain animal distribution and abundance data in a predefined area and time period. For seabirds, at-sea such surveys are generally conducted using ships or aircraft (Buckland et al. (2012); Camphuysen et al. (2004); Tasker et al. (1984)), although land-based surveys may be used to cover near-shore environments (Arranz et al. (2014); Smith et al. (2015)). 36.1 At-sea survey data and tracking data Due to the differing strengths and weaknesses of the two methods (at survey data vs. direct animal tracking), distributions derived from both may be combined to provide a more complete picture of seabird distribution (Louzao et al. (2009)), but this is not straightforward and formal analytical frameworks for combining area-based and individual-based data remain an active research topic in ecological statistics (Chandler et al. (2022); Glennie et al. (2021)). Synoptic comparisons of both approaches are rare, but the results of studies (Carroll et al. (2019); Phillips et al. (2019)) suggest that tracking data can yield comparable results to area-based survey data when the tracked individuals are a representative sample of the birds using the area of interest. In particular, single-colony tracking appears to yield comparable results to area-based approaches for relatively isolated colonies, whereas multi-colony tracking or tracking of individuals captured at-sea in the area of interest is recommended to get an unbiased picture of seabird distributions in areas used by individuals from dispersed colonies. Assessments of the comparability of sampling approaches therefore remain critical to the interpretation of differences in seabird distribution, when data have been collected using different methods. 36.2 At-sea survey methodology This section provides a brief review of existing census techniques for area-based or Eulerian surveys of seabirds at sea. Two primary observation tools are discussed: aerial and ship-based line transect surveys, which both have the potential to provide similar data outputs, i.e. spatially referenced counts of birds. The European Seabirds At Sea protocol outlines a standardised and broadly agreed upon approach for collecting offshore monitoring data on seabirds and marine mammals through both aerial or ship-based surveys at sea. Additional observation methods exist, such as land-based human observers (Arranz et al. (2014); Smith et al. (2015)) or terrestrial or marine radars (Lilliendahl et al. (2003); Orben et al. (2019)) but are not discussed in detail due to their inability to monitor large offshore areas, and or limitations with regard to species identification. The at-sea survey census techniques generally rely on a common principle: line transect surveys, but different survey methodologies have strength and weaknesses both concerning the nature and quality of the collected data, and in terms of their logistics. Data quality is primarily affected by: the level of detectability of individual birds a method affords, and the level of taxonomic identification of detected birds. Logistical characteristics include differing costs, survey speeds, and allowable environmental conditions under which surveys can be undertaken. Aerial surveys are quick, enabling coverage of larger areas per unit time and therefore providing a more synoptic view of seabird distributions than slower shipboard surveys. Bird data obtained during aerial surveys may be combined with remotely sensed environmental parameters in a correlative approach, but in-situ collection of environmental parameters is usually very limited, whereas shipboard surveys can allow the simultaneous collection of in-situ oceanographic data. Both aerial and shipboard surveys generally rely on visual survey methods (human observers, camera systems; Buckland et al. 2012), which restricts them to daylight hours, and are generally limited to relatively benign wind and wave conditions (generally sea states below 3-5). This may fundamentally limit the understanding of realized seabird distributions under the full set of prevailing environmental conditions. Survey platforms further differ in their effect on seabird behaviour. Surface vessels may elicit avoidance or attraction effects on birds (Spear et al. (2004)), whereas the degree of avoidance to aircraft is largely governed by their flight height, so that surveys may have little to no impact on bird behaviour when executed at a sufficient aircraft altitude (Buckland et al. (2012)). 36.3 At-sea survey data for KBAs or IBAs While at-sea survey data only provides a snapshot of distribution and numbers at any given time (unless collected over many years), it can play a vital role in identifying the locations of potentially important marine sites, especially if threshold numbers of animals are exceeded. Raw data or those converted into density estimates can be used to consider if important criteria thresholds are met. Applying a scale which includes the relevant important criteria threshold will clearly show the locations of observations that have recorded adequate numbers of animals. This approach may be most useful for threatened species with low population thresholds, given these species are more likely to trigger relevant important criteria because of lower thresholds needing to be met. 36.4 Citations "],["supporting-data-statistical-models.html", "37 Supporting data: statistical models 37.1 Introduction to statistical models for estimating animal distribution 37.2 How do statistical models for estimating animal distribution work (broadly speaking)? 37.3 Examples of what you can use distribution models for 37.4 Further detail to statistical models for estimating animal distribution 37.5 Examples of different statistical modelling approaches for predicting distribution 37.6 Using statistical models to estimate distribution in unsampled locations 37.7 Examples of using predicted species distribution outputs for conservation purposes 37.8 Further resources", " 37 Supporting data: statistical models 37.1 Introduction to statistical models for estimating animal distribution The distribution of marine megafauna at sea has been difficult to study due to the lack of human observers in the marine environment. Besides the use of tracking devices to follow individuals, researchers have used a range of sophisticated modelling techniques to predict where marine megafauna occur at sea. These species distribution models are widespread to predict the occurrence of plants and animals on land, and have been adapted to the marine environment for at least three decades. Providing detailed guidance or specific overviews about how to implement species distribution models for marine megafauna is beyond the scope of this toolkit. We provide a high level review about these options as potential alternatives to the identification of important sites based on tracking data. 37.2 How do statistical models for estimating animal distribution work (broadly speaking)? Species distribution models generally work by relating some observations about the presence of a species to environmental variables, and then using maps of these variables and the estimated relationships to project where a species may occur. For seabirds at sea (and other marine megafauna), the observations are generally provided by either direct observations from a vessel (research surveys, opportunistic sightings, museum records etc.), or from tracking data. These observations are then combined with either sampled or random locations where the target species was not observed or recorded, and then related to static (depth, latitude, longitude, distance from coast, seamounts etc.) or dynamic (sea temperature, salinity, chlorophyll concentration, wind, wave height etc.) environmental variables. A large range of different model types are available to construct species distribution models, which vary in their complexities, data requirements, assumptions, and the way how the relationships between observations and environmental variables are related. 37.3 Examples of what you can use distribution models for Species distribution models generally return spatially explicit predictions of the habitat suitability or probability of occurrence of the target species, which can be shown on a map to visualise the projected distribution of a species. These maps can then be used to inform the identification and protection of important sites at sea in the same way as the outputs created using the track2kba protocol detailed in this toolkit. We do not, however, recommend that users propose KBAs or IBAs solely based on prediction from species distribution models. Rather, predicted distributions can be useful for: Strategically allocating survey effort to areas where there is a high probability of occurrence, Delimiting site boundaries for sites that have been confirmed as important by other data sources, and Extrapolating the number of individuals potentially using a site based on environment-abundance relationships. 37.4 Further detail to statistical models for estimating animal distribution Predictive models are based on the principles that equations and rule-sets can be constructed to represent how a species’ distribution is related to environmental conditions (Aarts, Fieberg, and Matthiopoulos (2012); Robinson et al. (2017)). Species distribution models (also often referred to as ‘habitat suitability models’ or ‘resource selection functions’) for seabirds have been used for &gt;20 years and were historically based on observations obtained from vessels. More recently, species distribution models are based on the locations that tracked individuals of a species used at sea, which resulted in a much broader distribution of ‘presence observations’ over a wider range of the marine realm than had been possible using vessel-based observation data (Matthiopoulos et al. (2022)). In addition, models are now frequently used to not only predict where a species occurs, but where specific behaviours occur, e.g. where seabirds are foraging rather than just occur in transit (Boyd et al. (2015)). Species distribution models rely on contrasting environmental conditions between locations where a species or a particular behaviour is observed, and where it is not observed to infer relationships between environment and occurrence. However, for highly mobile species like seabirds, defining and interpreting what ‘not observed’ actually means can be very difficult and affect the quality and interpretability of species distribution models. In contrast to sessile plants, it is virtually impossible to objectively determine whether a seabird species is truly ‘absent’ (= never occurs) at a given point in the sea – the fact that no birds of that species were seen during a research cruise at that location, or that none of the tracked individuals visited that location, does not exclude that other individuals of the same species may occur there at other times. Many seabird distribution models therefore rely on ‘presence-only’ data, which are the least robust form of data that cannot differentiate between the limit of a species’ distribution and the limit of the sampling effort. One of the key decisions when modelling the distribution of seabirds at sea is therefore to select the right contrast and appropriate data to model the contrast (Matthiopoulos et al. (2022)). If survey effort is sufficient to use non-detection data as contrast to locations where a species was observed, then so-called detection – non-detection models can be fitted which generally permit stronger inference about the probability of a species to occur at a certain location. For tracking data, this can be the case if only certain behaviours are modelled (where the occurrence of ‘foraging’ can be contrasted with all other behaviours), but more frequently the observations will be contrasted with a set of random points where no information exists whether the species did or did not occur there. These random points can be created based on virtual tracks that mimic the movements of seabirds (Žydelis et al. (2011)). Presence-only data can be combined with other data sources to inform the underlying distribution and the observation process (Matthiopoulos et al. (2022)), but they need to be interpreted with caution given that there are natural limits of inference (Hastie and Fithian (2013)). The spatial and environmental extent and variability at random locations against which observations are contrasted will have a great influence on the model and the inferred relationships between the presence of a species or behaviour and the environment. The scale at which inference is sought (e.g. do we want to know where species X occurs in the world, or which bay they prefer for foraging from colony Y) is critical in guiding the environmental data and the selection of background or non-detection points to ensure that the model can yield information at the desired scale of inference. 37.5 Examples of different statistical modelling approaches for predicting distribution Popular and widely used approaches to predict seabird distributions or behaviours at sea are: Generalised Linear Models (GLM; hue@huettmannSeabirdColonyLocations2001), Generalised Additive Models (GAM; Critchley et al. (2020); Warwick-Evans et al. (2022); Žydelis et al. (2011)), mixed-effects implementations of GLM and GAM that allow for the serial dependence of observations through the incorporation of random effects (GLMM or GAMM; Chimienti et al. (2017); Gilman et al. (2014); Waggitt et al. (2016); Weber et al. (2021)), Maximum Entropy (MaxEnt; Hodges, Erikstad, and Reiertsen (2022); Krüger et al. (2017); Lemos et al. (2023)), Boosted Regression Trees (BRTs; Evans, Lea, and Hindell (2021); Humphries (2015); Torres et al. (2015)), Random Forests (RFs; Boyd et al. (2015); Diop et al. (2018); Huettmann et al. (2011); Mikami et al. (2022)), point process models (I. W. Renner et al. (2015); Wakefield et al. (2017)), and ensembles of multiple models with average predictions based on the performance of each model (Fox et al. (2017); Häkkinen et al. (2021); Lavers et al. (2014); Lieske, Fifield, and Gjerdrum (2014); Oppel et al. (2012); Pereira et al. (2018); M. Renner et al. (2013); Scales et al. (2016)). Ultimately, however, the choice of the algorithm and how the contrast is selected will have a greater effect on the resulting model predictions than the spatial and temporal resolution of the data used to train the model (Quillfeldt et al. (2017)). If tracking data are considered as a presence-only dataset for the purpose of a distribution model, it is important to consider a species’ ecology and the spatial and temporal resolution of the tracking data to avoid the inclusion of sections of the track where the individual is not actively ‘using’ the associated environment, but is just passing through. A range of bespoke analytical techniques are available to identify different behaviours from tracking data (e.g. state-space models, hidden markov models, expectation-maximisation binary clustering etc.), and each of these methods comes with its associated assumptions and limitations which we will not elaborate here. Useful overviews of what methods can be used to identify behaviour are: benni@bennisonSearchForagingBehaviors2018; Browning et al. (2018); Garriga et al. (2016); McClintock and Michelot (2018); Patterson et al. (2019). Identification of “hotspots” can also be achieved mathematically with metrics such as Getis-Ord and Maximum Curvature (requ@cleasbyIdentifyingImportantAtsea2020; Requena et al. (2020)). 37.6 Using statistical models to estimate distribution in unsampled locations Species distribution models are generally evaluated with independent test data – observations that were not used to develop the model, but are then used to evaluate how accurate the predictions of the model are. Depending on how far away in space and environmental conditions the test data are from the data that were used to build the model, the resulting predictions generally become less accurate the farther away the test data are from the training data. Seabird species distribution models have so far not transferred very well across different regions (Diop et al. (2018); Torres et al. (2015)), indicating that explaining the distribution of a species in one region will not necessarily allow for an accurate prediction where that species may occur in another region even if similar environmental data are available. We therefore do not recommend to use predicted distributions that are based on models which were constructed without any input data from the target species population. Although, when guided by expert knowledge, these data might be considered for strategically allocating survey effort to areas where there is a high probability of occurrence of the species. 37.7 Examples of using predicted species distribution outputs for conservation purposes Predicted species distributions can be used in conjunction with other outputs of this toolkit, or across multiple species or seasons to prioritise marine areas based on systematic spatial planning approaches. Popular algorithms such as (Zonation)[https://cbig.github.io/zonator/] and (prioritizr)[https://prioritizr.net/index.html] allow users to overlay predicted distribution maps for several species (or the same species in several seasons) and then determine the areas at sea that are most valuable to protecting all species (or a species in all seasons) based on algorithms that trade off the size of the area that needs to be protected with the minimum amount of habitat that needs to be protected for each species or season (Dias et al. (2017); Oppel et al. (2012)). 37.8 Further resources Help us populate this list Some further resources to consider include: BRT guide: Elith, Leathwick, and Hastie (2008) Data mining and statistical models: Hochachka et al. (2007) MaxEnt: Merow, Smith, and Silander (2013) Community science data: Johnston et al. (2021) "],["sites-proposing-a-kba.html", "38 Sites: Proposing a KBA 38.1 Who can propose a KBA? 38.2 Queries about proposing a KBA?", " 38 Sites: Proposing a KBA Previous steps in this toolkit support users to generate the data required for proposing a Key Biodiversity Area (or Important Bird and Biodiversity Area in the case of some BirdLife Partners). Once users have generated this data they should review the Key Biodiversity Area website and the document Guidance on Proposing, Reviewing, Nominating and Confirming sites to understand how they can formally propose a site as a Key Biodiversity Area. 38.1 Who can propose a KBA? In principle, anyone can propose a KBA. However, proposing a KBA through an established NCG, or National Coordination Group, is the recommended best practice where this is feasible. 38.2 Queries about proposing a KBA? Those supporting KBA work want to help. If you have any queries, reach out to us. "],["sites-monitoring.html", "39 Sites: Monitoring 39.1 Why monitor sites? 39.2 What does the KBA monitoring protocol entail? 39.3 How to establish an effectively implemented monitoring protocol?", " 39 Sites: Monitoring A formal KBA monitoring protocol is under currently under development. 39.1 Why monitor sites? Informs the pressures taking place at key sites for biodiversity, the status of the qualifying species, and any actions being implemented to alleviate the impacts of pressures. Helps identify priority sites for action, prioritise conservation actions within them, determine the effectiveness of interventions The outputs can be used to hold governments to account, to inform policy, influence donors and decision-makers. They also form the basis of a range of indicators for reporting to the Convention on Biological Diversity (CBD), the United Nations Sustainable Development Goals (UN SDGs) and other policy fora and global/regional/thematic assessments (e.g. Global Biodiversity Outlook (GBO), Group on Earth Observations (GEO), Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services (IPBES) etc), and inform global and regional-scale advocacy and communications. 39.2 What does the KBA monitoring protocol entail? The goal of the KBA monitoring protocol is to gather information on three main things: STATE: The abundance of trigger species, extent of trigger ecosystem types, or degree of ecological integrity within the site relative to a benchmark. PRESSURE: The impacts of threats that are affecting or have the potential to affect trigger species, ecosystem types or ecological integrity, including information about the timing, scope and severity of impacts. RESPONSE: Response indicators identify and track conservation actions: for example, changes in conservation designation to a site, implementation of conservation projects, and establishment of Local Conservation Groups. 39.3 How to establish an effectively implemented monitoring protocol? We’re working on populating a growing list of resources. We’d love your input. "],["sites-conservation-of-sites.html", "40 Sites: Conservation of sites 40.1 What threats exist? 40.2 What threats impact seabirds? 40.3 What known solutions to threats exist? 40.4 What scale should threat mitigation be considered over? 40.5 Best available science", " 40 Sites: Conservation of sites Once you have done the work of identifying a site which may require action to conserve biodiversity at the site (Technical), then you have to determine what the likely actions are that can conserve the biodiversity (Conservation). 40.1 What threats exist? Typically, one must first understand what a potential threat to the site might be. The Toolkit advocates for recognising threats in a globally standardised way. The IUCN Red List Threat Classification Scheme, https://www.iucnredlist.org/resources/threat-classification-scheme, offers a way of recognising threats in a globally standardised way. 40.2 What threats impact seabirds? For seabirds, two key papers provide the starting point for users to consider what human activities may likely impact a species: Croxall et al. (2012); Dias et al. (2019) Users should use these papers as a guide to understand the threats recognised to impact species at a global level, and then consider what threats might be impacting species at a potential local, national or regional scale. 40.3 What known solutions to threats exist? When identifying whether a threat may impact species at the site, users should also look beyond their specific species and explore whether a potential human activity has been documented to impact related species. Once potential threats to species at the site have been identified, then users should understand what the potential solutions to the threats are. The Cambridge University Conservation Evidence group summarises the documented evidence for the effectiveness of conservation actions. Here, users can find evidence of actions known to reduce the impacts of threats to species. This evidence will be key to building the case for management measures that are necessary to conserve biodiversity at a site. 40.4 What scale should threat mitigation be considered over? Different threats occur at different scales. Therefore, conservation actions for species will need to occur at different scales depending on the scale of the threat and the species dispersal ability. Two key papers document this consideration of scale with respect to conservation solutions for seabirds and broader biodiversity: Seabirds: Oppel et al. (2018) Broader biodiversity: Boyd et al. (2008) 40.5 Best available science For many species at sites where human impacts are likely to occur, it’s likely species will be impacted by multiple threats. Disentangling which threat impacts a species most, and, therefore, which course of action will be most appropriate to conserve the species, may be challenging. Where there is uncertainty about the impact of a potential threat to species, this Toolkit advocates for consideration of the “precautionary principle” and recognises the text of certain agreements which call for decisions to be made on the “best available science”. Ultimately, determining a course of action to reduce a threat to species within a site will require understanding a number of factors. The Cambridge University Conservation Evidence group showcases known solutions, but the “best available science” should also be used to inform solutions to conserve biodiversity when necessary. "],["sites-policy-and-advocacy.html", "41 Sites: Policy and advocacy 41.1 Achieving the goal: “marine megafauna in favourable conservation status” 41.2 Achieving conservation of sites 41.3 Important sites in the marine environment 41.4 Key Biodiversity Area (KBA) definition and scope 41.5 KBA recognition internationally 41.6 KBA conservation through international mechanisms 41.7 KBA conservation through marine protected areas", " 41 Sites: Policy and advocacy 41.1 Achieving the goal: “marine megafauna in favourable conservation status” While the toolkit currently favours opportunities for seabird conservation, many of the policy and advocacy strategies will apply to all marine megafauna. The overarching goal of the Toolkit is to see marine megafauna populations in a favourable conservation status, as outlined in the Theory of Change. When identifying the steps required to achieve this goal, Toolkit users are reminded that a suite of actions will likely be required. Achieving the long-term goal, may be achieved through formal delineation of a protected area. However, other management measures that are not protected areas may also be effective. Deciding on the most appropriate management measure will require understanding impacts of potential threats to species in space and time, and both the scale at which a threat may occur, or a species may disperse (Boyd et al. (2008), p. 200; Oppel et al. (2018)). Where there is uncertainty about the impact of a potential threat to species, this Toolkit advocates for consideration of the “precautionary principle” and recognises the text of certain agreements which call for decisions to be made on the “best available science”. 41.2 Achieving conservation of sites Critical to the success of getting conservation actions implemented is getting decision-makers to act. Decision-makers typically act for one of two reasons, or a combination of both: They are typically pulled into acting when there is an established legal or other policy related mechanism in place. Or they are pushed into acting through advocacy efforts. As indicated above, management measures that enable a site to be protected so species can achieve a favourable conservation status, do not explicitly need to be formal protected areas. The concept of a site is the critical concept here. In the toolkit, we recognise a spectrum of sites. However, we advocate for, and support the identification of, Key Biodiversity Areas (KBAs). This is because by formally identifying a site as a KBA, the site will have added ability to bring about a change by a decision-maker that supports species maintaining or achieving a favourable conservation status. Key message for conservationists: by formally identifying a site as a KBA, there are formal mechanisms that can help get the site protected through an appropriate management measure. Beyond KBAs, the “best available science” describing key biodiversity at a unique site should also be used to support implementation of management measures at sites. This may be particularly relevant for key biodiversity at unique sites at local, national and regional scales. Key message for conservationists: while the concept of a site for a KBA has a definition, the concept of what constitutes a specific site for supporting marine megafauna conservation is still the subject of debate. Toolkit users are encouraged to explore the tools in the Toolkit that can help identify a site, but should also consider the scale of the particular site and how it could be used to inform delivery of a conservation outcome for species. (e.g. the track2KBA tool can be applied to GLS animal tracking data. However, the resultant site may be even larger than a countries EEZ. Nevertheless, this type of site could still inform where bycatch mitigation measures should be enforced in tuna RFMOs which operate at the ocean basin scale.) 41.3 Important sites in the marine environment Multiple different frameworks exist aimed to identify and describe sites within the marine environment that are of ecological significance, differing in their focus, scope, and processes of identification. Example frameworks include: Key Biodiversity Areas (KBAs) Important Bird and Biodiversity Areas (IBAs) Ecological and Biologically Signification Areas (EBSAs) Important Shark and Ray Areas (ISRAs) Important Marine Mammal Areas (IMMAs) Important Marine Turtle Areas Marine Key Ecological Features (MKEFs) While these frameworks do not specifically dictate a protected status for the specific site, they guide policy makers in identifying which sites are of most importance for preserving biodiversity according to a set of pre-defined criteria. The Toolkit focuses on KBAs as a key policy mechanism given, they are an overarching framework which facilitates recognition of sites contributing significantly to the global persistence of biodiversity across all taxonomic groups. Furthermore, KBAs are formally recognised in a suite of international agreements that promote, support and enable the conservation of biodiversity. See Plumptre et al. (2024) for an overview about KBAs and a comparison of the conservation objectives and relevance to different systems of the main approaches to identification of areas of particular importance for biodiversity. 41.4 Key Biodiversity Area (KBA) definition and scope A KBA is a site contributing significantly to the global persistence of biodiversity. The site can be significant for a single species, assemblages of species, ecosystems, sites of outstanding ecological integrity, or sites with high irreplaceability. The Key Biodiversity Area (KBA) Partnership is the official body responsible for advancing and promoting the identification, mapping, and monitoring of KBAs, and providing the means to maintain the infrastructure that ensures KBAs have lasting recognition. The Partnership was launched in 2016 and consists of 13 international conservation organisations, including BirdLife International, the International Union for the Conservation of Nature (IUCN), American Bird Conservancy, Amphibian Survival Alliance, Conservation International, Critical Ecosystems Partnership Fund, Global Environment Facility (GEF), NatureServe, Rainforest Trust, Re:wild, the Royal Society for the Protection of Birds (RSPB), Wildlife Conservation Society, and World Wildlife Fund (WWF). Key message for conservationists: KBAs are supported by a network of some of the world’s largest conservation organizations. This ensures that when a KBA is identified, there is the infrastructure in place to effectively maintain a record and visibility of the KBA in perpetuity (i.e. the identified site can continue to inform decision making processes beyond the lifespan of a typical project, and likely even beyond an individual’s employment period). By working towards KBA identification and supporting monitoring efforts, contributed data can make a difference to global biodiversity conservation beyond what could likely be achieved by a single project. KBAs are identified based on 11 quantitative criteria. Use of global quantitative criteria enables comparisons to be made between sites anywhere in the world. For a site to qualify as a KBA, it must hold a significant proportion of the biodiversity element, where the threshold required is also dependent on the IUCN Red List Conservation Status of a species or ecosystem. NOTE: KBA criteria allow different parameters to be used to determine the proportion of a population within the KBA. FOR THE TOOLKIT: the toolkit primarily focuses on the use of mature individuals as the key population metric. Other frameworks such as IBAs or ISRAs can operate at regional levels. As of January 2024, development of standardised regional KBA criteria is being undertaken. Canada is a country which has described the use of regional KBA criteria. 41.5 KBA recognition internationally KBAs in international multilateral environmental agreements: KBAs serve as valuable indicators of targets within the CBD Kunming-Montreal Global Biodiversity Framework and the Sustainable Development Goals. For the CBS, targets can be met by individual countries through achieving their National Biodiversity Strategy and Action Plans (NBSAPs), and KBAs can guide development of these NBSAPs. KBAs in international business agreements: KBAs are recognised by the private sector and financing institutions as ‘Critical Habitat’, used in performance standard 6 of the International Finance Corporation (IFC) and adopted by 84 Equator Principles Financial Institutions. To meet this standard, companies should not have demonstrable negative impacts on the biodiversity features that trigger KBA status. KBAs in international funding mechanisms: KBAs are used by international funding agencies to guide their funding decisions. For Example, the Global Environment Facility 7th Replenishment (GEF-7) and GEF-8 funds new protected areas only if they meet KBA global criteria. KBAs as tools to support business decision-making: The integration of KBA data, IUCN Red List data, and Protected Planet data through tools like the Integrated Biodiversity Assessment Tool (IBAT), https://www.ibat-alliance.org/, enables the generation of comprehensive reports that companies can use to assess how their activities may impact nature in, or around, KBAs. The funding generated from these reports supports the maintenance of the KBA, IUCN Red List, and Protected Planet databases, ensuring that these datasets remain prominent and visible to the world. Further details about how KBAs can be used to inform decision making processes are available on the KBA website: [https://www.keybiodiversityareas.org/] 41.6 KBA conservation through international mechanisms Reminder: Designation of a site as a KBA does not require the site to be protected within a formal protected area. To achieve the long-term goal outlined in the Theory of Change (Seabirds in favourable conservation status), conservation actions other than protected areas can be appropriate. Critical to the success of getting conservation actions implemented is getting decision-makers to act. Here we outline international mechanisms that almost all countries around the world have agreed to achieve and, therefore, decision-makers should be acting toward. 41.6.0.1 Convention on Biological Diversity (CBD) The CBD is an international treaty (an agreement that governments have signed up to) that aims to conserve biodiversity, sustainably use its components, and ensure the fair and equitable sharing of benefits arising from genetic resources. Several targets outlined in the CBD benefit from the use of KBAs to deliver these targets, or make specific reference to KBAs in order to support delivering these targets. These targets can be met by individual countries through achieving their National Biodiversity Strategy and Action Plans (NBSAPs), and KBAs can guide development of these NBSAPs. Target 1 of the Global Biodiversity Framework (GBF) calls for spatial planning or other effective management for areas of biodiversity. Target 3 promotes the establishment and management of Marine Protected Areas (MPAs) as a tool for conserving marine biodiversity. Progress towards achieving Target 1 and Target 3 of the GBF will use the Percentage of spatial plans utilizing information on key biodiversity areas, and Coverage of KBAs by Protected areas and OECMs as component indicators, respectively. Key message for conservationists: Check if your country is signed up to the CBD (it likely will be). If you identify KBAs, you will have added strength in using these sites to motivate for your country to achieve the targets it has agreed to. The states that have signed and/or ratified the Convention on Biological Diversity can be found here, and the obligation of signatory parties to meet the targets of the Global Biodiversity Framework can be seen as one of many reasons to conserve KBAs. Although the GBF lacks the power to establish protected areas, signatory parties can be guided by this mechanism in order to pursuing its targets through national processes. 41.6.0.1.1 National processes to support CBD National Legislation and Policy: Ensure that the proposing country has appropriate national legislation and policies in place to support the establishment and management of protected areas and the conservation of biodiversity. Over 200 countries have signed the GBF and are therefore obliged to adopt legal mechanisms to achieve its targets. Stakeholder Engagement: When drafting a proposal, use the templates provided by the relevant national authority or contact national CBD focal points for their guidance. During the process it is important to engage with relevant stakeholders, such as local communities, expert scientists, regional/local NGOs, and government agencies (such as environment, fisheries, or transport ministries). Their involvement is crucial to ensure that the proposed protection measures reflect local needs, traditional knowledge, and concerns. Organising online or in-person consultations, workshops, and meetings can be useful to gather input and build support. CBD National Focal Point: Share the national KBA or MPA proposal with the respective CBD National Focal Point, who serve as the contact point for CBD-related activities and can provide guidance, support, and feedback on proposals. National Focal Points for the Global Biodiversity Framework can be found here, and those specific to Marine and Coastal Biodiversity can be found here. CBD Regional Bodies: Engaging with the relevant CBD regional bodies that focus on protecting biodiversity can provide additional support, guidance, and technical assistance in the establishment of protected areas and the conservation of KBAs. A list of bodies across all continents can be found here. Review and Approval: The national proposal will undergo a review process by the CBD National Focal Point and potentially other relevant national authorities and stakeholders. This review may involve expert assessments, peer reviews, and consultations. Revise and refine the proposal based on feedback and recommendations. Adoption and Designation: The National CBD National Focal Point can guide where to submit a proposal. Once a proposal is reviewed and approved by the correct national authorities, it can be formally adopted and designated as a protected area under the CBD. This may involve enacting national legislation, signing international agreements, or making formal declarations to provide legal recognition and support for the establishment and management of the protected area. Implementation and Management: Develop and implement a management plan for the protected area, including regulations, zoning schemes, enforcement mechanisms, and monitoring programs. Collaborate with relevant stakeholders, local communities, and government agencies to ensure effective implementation and sustainable management of the protected area. Reporting and Collaboration: The CBD monitoring framework offers a method to regularly report on the progress, achievements, and challenges related to achieving Targets 1 and 3 of the GBF. It is important for countries to develop and incorporate national monitoring systems into their National Biodiversity Strategies and Action Plans (NBSAPs) that report conservation progress against the biological headline, component and complementary indicators set out by the CBD monitoring framework. Collaboration with other countries and organizations is encouraged under the CBD framework to share experiences, best practices, and resources for enhanced biodiversity conservation efforts. It should be noted that the specific process of proposing and establishing the protection of a marine KBA will vary between countries. Therefore, along with the CBD National Focal Point, it is recommended to consult with the relevant authorities and experts to ensure compliance with national processes. 41.6.1 United Nation’s Sustainable Development Goals The Sustainable Development Goals (SDGs), adopted by the United Nations in 2015, recognise a plan of action for people, planet and prosperity aimed to be achieved by 2030. The SDGs include a specific target to conserve and sustainably use the oceans, seas, and marine resources: Goal 14 Life Below Water. Key message for conservationists: KBA coverage by protected areas is an indicator of the targets within SDG Goal 14. In other words, KBAs are recognised within the SDGs. Therefore, your country can use identified KBAs to help demonstrate how it is achieving the SDGs. More broadly: When prioritising actions that could be implemented to achieve targets under SDG Goal 14, prioritising these actions within or around KBAs may offer the most significant return on effort. The SDGs also recognise the legal frameworks outlined in the United Nations Convention on the Law of the Sea (UNCLOS) as mechanism to achieve targets. 41.6.1.0.1 Targets within SDG 14 call to: prevent and significantly reduce marine pollution of all kinds, particularly from land-based activities, including marine debris and nutrient pollution. sustainably manage and protect marine and coastal ecosystems to avoid significant adverse impacts, including through the establishment of effectively managed marine protected areas. minimize and address the impacts of ocean acidification, including through enhanced scientific cooperation at all levels. effectively regulate harvesting and end overfishing, illegal, unreported, and unregulated (IUU) fishing, and destructive fishing practices, and implement science-based management plans to restore fish stocks in the shortest time feasible, at least to levels that can produce maximum sustainable yield as determined by their biological characteristics. conserve at least 10 percent of coastal and marine areas, consistent with national and international law and based on the best available scientific information prohibit certain forms of fisheries subsidies that contribute to overcapacity and overfishing, eliminate subsidies that contribute to IUU fishing, and refrain from introducing new such subsidies, recognizing that appropriate and effective special and differential treatment for developing and least developed countries should be an integral part of the World Trade Organization fisheries subsidies negotiation. increase the economic benefits to small island developing states and least developed countries from the sustainable use of marine resources, including through sustainable management of fisheries, aquaculture, and tourism. Sub-level targets of SDG Goal 14, call to: increase scientific knowledge, develop research capacities, and transfer marine technology, taking into account the Intergovernmental Oceanographic Commission Criteria and Guidelines on the Transfer of Marine Technology, in order to improve ocean health and to enhance the contribution of marine biodiversity to the development of developing countries, in particular, small island developing states and least developed countries. provide access for small-scale artisanal fishers to marine resources and markets. enhance the conservation and sustainable use of oceans and their resources by implementing international law as reflected in UNCLOS, which provides the legal framework for the conservation and sustainable use of oceans and their resources. 41.6.2 United Nations Convention on the Law of the Sea (UNCLOS) The United Nations Convention on the Law of the Sea (UNCLOS) primarily focuses on the legal framework for ocean governance rather than the establishment of protected areas. However, UNCLOS provides a foundation for the conservation and sustainable use of marine resources, including the protection of marine biodiversity. The countries that have signed onto and/or ratified UNCLOS can be found here. National Jurisdiction: Each coastal state has the authority to establish MPAs within its exclusive economic zone (EEZ) and continental shelf, in accordance with UNCLOS. The coastal state should have a clear understanding of its jurisdictional boundaries and the areas it can designate as MPAs. Conduct Scientific Assessment: Conduct a scientific assessment of the marine KBA to gather data on its ecological importance, biodiversity values, and conservation needs. This assessment should include ecological surveys, biodiversity monitoring, and analysis of threats and vulnerabilities. The scientific evidence will support the proposal and inform the decision-making process. Proposal Development: once a KBA has undergone a scientific assessment and stakeholder consultations, those proposing it must advocate for its implementation by including how its proposed protection would align with the objectives and principles of UNCLOS (as outlined in the Articles in the point below). The proposal should outline the ecological significance of the area, biodiversity values, threats, and proposed management measures. Identify Relevant Provisions: The UNCLOS contains relevant provisions that can be used to support the protection of marine biodiversity, at least 18 of which deal specifically with marine-biodiversity or environmental management topics (Appendix A). Linking which of these UNCLOS Articles are relevant to the threats that the KBA faces, will strengthen the reason for its protection and the overall proposal. National Implementation: This will depend on national legislation and policies, as seen with implementation through other international/regional mechanisms. Work with the relevant national authorities to implement the proposed protection measures within the national jurisdiction. Reporting and Collaboration: States are required to regularly report on the progress, achievements, and challenges related to the protection of the KBA through national and international reporting mechanisms. They should collaborate with other countries and organizations under the UNCLOS framework to share experiences, exchange information, and foster collaborative efforts to protect marine biodiversity. It is important to note that UNCLOS does not provide a specific process for proposing and establishing protected areas. The establishment of protected areas is primarily governed by national legislation and policies, often guided by regional or international frameworks, and will therefore vary across regions. The UN Treaty on the High Seas, negotiated in New York in 2023 is a new process under which marine protected areas may be designated in the future, once this treaty enters into force. See further details below. UNCLOS Articles that are relevant to the protection of the marine environment. Article 192: General Obligation to Protect and Preserve the Marine Environment Article 194: Measures to Prevent, Reduce, and Control Pollution of the Marine Environment Article 195: Duty to Protect and Preserve the Marine Environment Article 196: Cooperation in the Field of Marine Pollution Article 197: Pollution from Vessels Article 198: Responsibility and Liability for Pollution Damage Article 199: Liability for Pollution Damage Article 200: Compensation for Pollution Damage Article 201: Cooperation in Response to Pollution Emergencies Article 206: Environmental Impact Assessment Article 211: Preservation of the Living Resources of the High Seas Article 215: Protection and Preservation of the Marine Environment in Areas Under National Jurisdiction Article 216: Protection of the Marine Environment in the Area Article 238: Conservation and Management of Living Resources on the High Seas Article 239: Highly Migratory Species Article 240: Marine Mammals Article 245: Cooperation in Research and Development Article 246: Marine Scientific Research on the High Seas 41.7 KBA conservation through marine protected areas When pursuing a marine protected area as a conservation mechanism for a KBA, the summaries outlined below will help inform how one could go about this. 41.7.1 Regional Seas Agreements Regional Seas programs, such as the Mediterranean Action Plan, the Caribbean Environment Programme, and the East Asian Seas Action Plan, promote cooperation among countries in specific regions to protect and manage marine and coastal environments. These programmes often include provisions for establishing MPAs and conserving key biodiversity areas. There are several Regional Seas programs established around the world which have the authority to establish MPAs in their respective regions. Some examples of existing Regional Seas programs that have a mandate to create protected areas include: Baltic Sea Regional Seas Programme: Covers the Baltic Sea region and is governed by the Helsinki Commission (HELCOM). The program addresses pollution, biodiversity conservation, fisheries, and maritime spatial planning in the Baltic Sea area. Contracting Parties of the Baltic Sea Regional Seas Programme can be found here. Black Sea Regional Seas Programme: Focuses on the Black Sea region and is governed by the Black Sea Commission (BSC). The program addresses pollution, biodiversity conservation, sustainable fisheries, and integrated coastal zone management in the Black Sea area. Contracting Parties include Republic of Bulgaria (Bulgaria), Georgia, Romania, the Russian Federation, the Republic of Turkey, and Ukraine. Caribbean Regional Seas Programme: Covers the Caribbean Sea and is governed by the Caribbean Environment Programme (CEP). The program addresses pollution, coral reef conservation, coastal erosion, climate change impacts, and sustainable tourism in the Caribbean region. Mediterranean Regional Seas Programme: Governed by the United Nations Environment Programme - Mediterranean Action Plan (UNEP/MAP), the program focuses on the Mediterranean Sea region and aims to implement the provisions of the legally-binding Barcelona Convention. It addresses pollution, marine biodiversity, coastal zone management, and sustainable development in the Mediterranean. The 22 Contracting Parties of the Barcelona Convention can be found here. Northeast Atlantic Regional Seas Programme: Governed by the Oslo-Paris Convention (OSPAR), this program covers the Northeast Atlantic Ocean. It addresses pollution, marine biodiversity conservation, fisheries management, and offshore oil and gas activities in the region. The Abidjan Convention: A regional Treaty established in protect and manage the marine and coastal environment of the West and Central African region. The Abidjan Convention focuses on addressing pollution, conserving biodiversity, and promoting sustainable development. [ Northwest Pacific Regional Seas Programme: Governed by the Northwest Pacific Action Plan (NOWPAP), the program focuses on the marine environment of the Northwest Pacific region. It addresses pollution, biodiversity conservation, sustainable development, and marine litter management. South Asian Seas Programme: Covers the marine and coastal areas of the South Asian region and is governed by the South Asia Co-operative Environment Programme (SACEP). The program addresses pollution, biodiversity conservation, climate change impacts, and integrated coastal zone management in the region. Southeast Pacific Regional Seas Programme: Governed by the Permanent Commission for the South Pacific (CPPS), this program focuses on the marine environment of the Southeast Pacific region. It addresses pollution, marine biodiversity conservation, sustainable fisheries, and climate change impacts. **The Nairobi Convention:** A Regional Seas Programme of the UNEP, covering the coastal countries of the Western Indian Ocean. [The Nairobi Convention](https://www.nairobiconvention.org/) aims to promote the protection and sustainable management of the marine and coastal environment in the region, focussing on pollution, conserving biodiversity, and promoting sustainable development through cooperative efforts and the implementation of specific action plans and protocols. Its Contracting Parties can be found [here](https://www.nairobiconvention.org/nairobi-convention/who-we-are/contracting-parties/), with its National Focal Points listed [here](https://www.nairobiconvention.org/nairobi-convention/who-we-are/country-representation/). Antarctic Regional Seas Programme: Governed by the Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR): Manages marine living resources in the Southern Ocean, including fisheries. Members and their respective contact details can be found here. 41.7.2 The High Seas Treaty Currently in its ratification phase (as of FEbruary 2024), the Agreement Under the United Nations Convention on the Law of the Sea on the Conservation and Sustainable Use of Marine Biological Diversity of Areas Beyond National Jurisdiction (also called the High Seas Treaty or the “BBNJ Treaty”) is hoped to come into force following ratification by 60 parties, by the next United Nations Ocean Conference in June 2025 in Nice, France. If a KBA is identified in international waters, the High Seas Treaty is the appropriate framework to use to propose a protected area. The Treaty provides a legal pathway for the designation and implementation of MPAs that are fully or partially located on the high seas. Under the draft text of the treaty, they are defined as areas for “conservation and sustainable use” of biodiversity. For the high seas, this mechanism previously only existed in Antarctica, the Northeast Atlantic and the Mediterranean and relatively few high seas MPAs have been designated to date. The process for MPA designation under the High Seas Treaty, once it enters into force will be as follows: Proposals are submitted by a Contracting Party to the Treaty, which outlines the area that needs to be protected, the threats it faces and a draft management plan with proposed management measures. The High Seas Treaty sets out the process for defining an MPA in international waters: That proposal will undergo a consultation process where stakeholders and NGOs will have an opportunity to review and comment on the proposal. The proponent will consider the input received during the consultation process and may revise the proposal. The Scientific and Technical Body of the High Seas Treaty would review and assess the MPA proposal and provide a recommendation to the Conference of Parties (COP). The COP would decide whether to establish the MPA. Decisions on MPAs at the Conference of Parties can be taken by voting with a ¾ majority to be adopted. This process creates the ability to designate areas towards the target of 30% of ocean areas protected by 2030, target that was pledged in the CBD Kunming-Montreal Global Biodiversity Framework. The text also provides guidelines for implementation, monitoring, and review of MPAs established. The current agreed text (as of March 2023) of the High Seas Treaty agreement under the United Nations Convention on the Law of the Sea on the conservation and sustainable use of marine biological diversity of areas beyond national jurisdiction can be found here. 41.7.3 Advocating for the protection of a KBA through MPA status When advocating for the official protection of a marine KBA under national legislation or by Regional Seas Programmes, there are several effective advocacy strategies to consider. The following steps have been tailored to support the advocacy efforts for an important marine site for seabirds. 41.7.3.1 Build a Strong Case To support the advocacy efforts for the official protection of a KBA, conducting scientific surveys and research is crucial. These efforts aim to gather comprehensive data on seabird populations, their distribution, and the ecological significance of the KBA. Key species of seabirds that rely on the KBA for breeding, feeding, or migration should be identified, and their conservation status and vulnerability assessed. Collaboration with researchers with specialist knowledge on these species and relevant ecosystems is essential to analyse and interpret the collected data, emphasizing the importance of the KBA for seabird conservation. The scientific evidence should then be used to develop a proposal, as well as fact sheets and publications that effectively its significance for seabirds and the broader marine ecosystem. 41.7.3.2 Raise Awareness and Mobilize Support To generate support for the official protection of a marine KBA, various advocacy strategies can be employed. Collaboration with bird enthusiasts, environmental organizations, and local NGOs can be useful in promoting and highlight the value of the KBA and fostering public support. Leveraging the power of social media platforms, websites, and local media channels enables the widespread dissemination of information about the KBA, including success stories, interesting seabird facts, and the need for its protection. Encouraging community involvement through citizen science programs provides opportunities for locals to contribute valuable data and observations on seabird populations and habitats, fostering a sense of ownership and engagement in the protection of the KBA. It should be noted that engaging local communities in supporting the protection of an KBA is likely to be easier if it’s located in areas of national jurisdiction or near coastlines, and that other strategies may be needed for areas in the high seas. 41.7.3.3 Engage Decision-Makers Engaging decision-makers is essential in advocating for the official protection of a marine KBAs. The first step is to identify key decision-makers at the national level, such as ministries of environment, fisheries, or tourism, and focus advocacy efforts on them, including engaging with their key advisors. This can be done by engaging in government frameworks to develop MPA networks, and through formal submissions on marine protection processes. It is crucial to demonstrate the socio-economic benefits associated with protecting the KBA, emphasizing how conservation efforts can contribute to sustainable development. Where possible, engaging with Ministers or high-level officials over the important value that KBAs and the related science can bring to MPA network development is useful. Emphasise the role of seabirds and coastal birds as umbrella species for many other parts of the marine ecosystem. Supporting the advocacy with policy briefs, proposals, and case studies that showcase successful examples of protected KBAs in other regions and the positive outcomes they have achieved can help sway decision-makers. Additionally, seeking endorsements from influential individuals, organizations, or businesses who can lend their support to the cause and effectively influence decision-makers can further strengthen the advocacy efforts. 41.7.3.4 Collaborate with Environmental Mechanisms When advocating for the protection of a marine KBA, it is important to identify and collaborate with relevant global and regional environmental mechanisms that address the specific threats faced by seabirds in the KBA. For example, there are many mechanisms that address marine plastic pollution, such as the African Marine Waste Network, , that aims to combat marine litter, including plastic pollution, in African coastal areas and the and the European Union LIFE project SEABIL which aims to create regional level governance structures that will help reduce the production of waste by marine professionals and upskill the public in reporting pollution events and seabird deaths on beach areas across Western Europe. In the case of overfishing and bycatch, engagement with Regional Fisheries Management Organizations (RFMOs) or the Agreement on the Conservation of Albatrosses and Petrels (ACAP) can be effective, as their objectives include minimizing the effects of fishing on associated and dependent species (for RFMOs and ACAP) and protecting seabirds in specific regions (for ACAP). Additionally, to address climate change impacts, collaboration with the Intergovernmental Panel on Climate Change (IPCC) and regional climate change organizations is crucial. By sharing relevant data and research on the vulnerability of seabirds to climate change, advocacy efforts can emphasize the need for climate action to protect these vulnerable species and their habitats. Referring to the relevant mechanisms to support different aspects of the identified KBA (i.e., by region, threat, species), as well as how it can contribute to a country’s global commitments to environmental conventions (e.g., CMS, CBD, ACAP), can be crucial for securing an area’s protected status. 41.7.3.5 Seek legal and policy support To support the establishment of the marine KBA as a legally protected area, it is crucial to research national legislation and policies pertaining to marine conservation, protected areas, or fisheries management. This research will help identify existing legal frameworks that can be leveraged to provide support for the KBA’s protection. Working alongside legal experts or environmental organizations, an assessment can be conducted to identify any gaps in the current laws or policies and develop recommendations for strengthening them. Additionally, advocating for the inclusion of the KBA in marine spatial planning processes, marine protected area strategies, or conservation plans that focus on seabirds or marine biodiversity can significantly enhance the KBA’s chances of being legally protected. 41.7.4 KBA conservation through alternative pathways It is important to note that not all KBAs will become marine protected areas and that many may gain various levels of protection through other effective area-based conservation measures (OECMs), areas-based management tools or species-based protection. An OECM is “a geographically defined area other than a Protected Area, which is governed and managed in ways that achieve positive and sustained long-term outcomes for the in-situ conservation of biodiversity with associated ecosystem functions and services and where applicable, cultural, spiritual, socio–economic, and other locally relevant values” (as set out in CBD Decision 14/8, CBD, 2018). For KBA protection to be included in the Global Biodiversity Framework Target 3, which aims to protect 30% of marine and coastal areas by 2030 (policy ambitions known as “30x30”), it must be covered by either a marine protected area or an OECM. Inclusion of OECMs in CBD targets allows an alternative pathway to achieve biodiversity conservation through a wider range of spatial management practitioners, even in cases where conservation isn’t the primary objective but nonetheless an outcome of such management. Area-based management tools (ABMTs) are a “tool, including a marine protected area, for a geographically defined area through which one or several sectors or activities are managed with the aim of achieving particular conservation and sustainable use objectives” (BBNJ Draft Agreement, 2023; Part III). In the marine context, ABMTs may include but are not limited to temporary or permanent fishing closures, customary fisheries management areas and marine spatial planning. ABMTs have previously been promoted in UN commitments such as the sustainable development goals and the Global Biodiversity Framework. Recognising which ABMTs can meet OECM criteria remains a work in progress as many government authorities and the private sector still set up standardized processes for the identification, designation, and ongoing management of OECMs (Himes-Cornell et al., 2022). Whether the area-based management tool meets all the OECM criteria is very context specific and can vary on a case-by-case basis. The following section outlines both area-based and species-specific conservation methods that offer an alternative pathway towards protecting KBAs. 41.7.4.1 Sustainable fisheries management Regional Fishery Management Organisations (RFMOs) are international bodies responsible for the conservation and management of fishery resources in specific regions. Some RFMOs, such as the Northwest Atlantic Fisheries Organization (NAFO), have adopted measures to protect important marine habitats. Most RFMOs focus strongly on management of fishing activity on specific stocks that they manage as defined in the agreements, their activities can include setting allowable catches, reporting catch and effort, implementing measures to prevent overfishing, and regulating fishing practices within their areas of competence. ABMTs can meet the criteria to qualify as an OECM if there is evidence that they provide co-benefits to biodiversity, with those that do using ecosystem-wide approaches to achieve both socio-cultural and biodiversity goals. If the identified KBA is threatened by unsustainable fishing practices, such as fish stock over-exploitation or incidental mortality (also known as bycatch), RFMOs can be approached to contribute to the protection of KBAs. Management of fisheries by an RFMO, contributing to sustainable management of a KBA also has the potential to meet OECM criteria, if one of its primary objectives is to enable sustainable management of fisheries (Himes-Cornell et al., 2022). RFMOs provide scientific advice on fish stocks and fisheries management, which in turn can inform zoning management plans and spatial management measures in an area could be further protected by area-based management actions or time-based management of fishing activity (e.g., seasonal restrictions). The regions and RFMOs with most influence on Albatross populations were examined by (Beal, Dias, et al. (2021)) and showed that multiple countries had strong connections with different RFMOs, creating a complex web of interactions between fishery management organisations and their member countries, in terms of seabird conservation. This highlighted the shared responsibility of international agencies on marine biodiversity, and the difficulty of working on multiple fronts to achieve conservation outcomes. Some prominent Regional Fisheries Management Organizations (RFMOs) include: International Commission for the Conservation of Atlantic Tunas (ICCAT): Manages tuna and tuna-like species in the Atlantic Ocean and adjacent seas. Contracting Parties of the ICCAT can be found here. Northwest Atlantic Fisheries Organization (NAFO): Manages fisheries in the Northwest Atlantic Ocean. Contracting Parties of NAFO can be found here. North Atlantic Salmon Conservation Organization (NASCO): Focuses on the conservation and management of Atlantic salmon. Contracting Parties of NASCO can be found here. International Pacific Halibut Commission (IPHC): Manages the Pacific halibut fishery in the waters of Canada and the United States. North Atlantic Marine Mammal Commission (NAMMCO): Promotes the conservation and management of marine mammals in the North Atlantic. Members of the NAMMCO are the Faroe Islands, Greenland (autonomous territory of Denmark), Iceland and Norway. South Pacific Regional Fisheries Management Organization (SPRFMO): Manages fisheries in the high seas of the South Pacific Ocean. Commission Members and Cooperating countries of the SPRFMO can be found here. Western and Central Pacific Fisheries Commission (WCPFC): Manages fisheries for tunas and other highly migratory species in the western and central Pacific Ocean. Members of the WCPFC can be found here. Indian Ocean Tuna Commission (IOTC): Manages tuna and tuna-like species in the Indian Ocean. Members of the IOTC can be found here. Commission for the Conservation of Southern Bluefin Tuna (CCSBT): Manages the Southern Bluefin Tuna fishery in the southern hemisphere. It’s area of activity is based on the sites where Southern Bluefin Tuna is fished and covers the Southern Ocean, Indian, Pacific and Atlantic Oceans. This RFMO overlaps its activities with several other RFMOs. Members of the Extended Commission comprise: Australia, the European Union, the Fishing Entity of Taiwan, Indonesia, Japan, Republic of Korea, New Zealand, and South Africa. Inter-American Tropical Tuna Commission (IATTC): Manages tuna and tuna-like species in the eastern Pacific Ocean. Members of the IATTC can be found here. North-East Atlantic Fisheries Commission (NEAFC): Manages fisheries in the North-East Atlantic Ocean. Contracting Parties of the NEAFC are Denmark (in respect of the Faroe Islands &amp; Greenland), the EU, Iceland, Norway, the Russian Federation and the United Kingdom, with cooperating Non-Contracting Parties including the Bahamas, Canada and Panama. Most fisheries ABMTs have the potential to allow various fishing activities while achieving the desired outcomes of an OECM, as long as the fisheries can operate in accordance with its criteria. 41.7.4.2 Ecosystem-based management through marine spatial planning (MSP) Marine spatial planning (MSP) is a comprehensive and integrated process that aims to strategically manage and allocate the use of marine space and resources. It involves the systematic analysis of marine ecosystems, human activities, and stakeholder interests to make informed decisions about how to best utilize and protect marine areas. MSP considers ecological, economic, social, and cultural considerations to achieve sustainable and balanced outcomes. MSP can play a crucial role in protecting marine KBAs through: Zoning and Spatial Management: MSP allows for the allocation of specific zones within a marine area based on ecological importance and different uses. By designating zones that prioritize the conservation of KBAs, such as no-take zones or restricted-use areas, MSP helps minimize the impact of potentially harmful activities on these critical habitats. Ecosystem-Based Approach: MSP encourages an ecosystem-based approach to management, considering the interconnectedness of different habitats, species, and ecological processes. By considering the broader ecosystem context, MSP can help protect and maintain the ecological integrity of KBAs. Stakeholder Engagement and Collaboration: MSP promotes stakeholder engagement and collaboration, bringing together various sectors, including government agencies, industries, NGOs, indigenous groups, and local communities. Stakeholder consultations may include establishing guidelines for activities such as fishing, shipping, energy exploration, tourism, and conservation. This participatory approach allows for the inclusion of different perspectives and knowledge, helping to ensure the effective protection of KBAs while addressing the needs and interests of all stakeholders. Adaptive Management and Monitoring: MSP emphasizes adaptive management and monitoring, enabling the assessment of the effectiveness of conservation measures in protecting KBAs. By regularly evaluating the status of KBAs and adjusting management strategies as needed, MSP ensures the ongoing conservation of these important areas. The entities responsible for carrying out MSP in EEZs and ABNJ vary depending on the jurisdiction. In EEZs it may be the responsibility of a national government agency or a dedicated MSP authority. Here are a few examples of specific MSP authorities that can assist mapping out the activities of a marine area within and around a KBA: United Kingdom Marine Management Organisation (MMO) Norwegian Coastal Administration Swedish Agency for Marine and Water Management Dutch Ministry of Infrastructure and Water Management Australian Marine Spatial Planning Portal Baltic Sea Region Spatial Planning The United States of America National Oceanic and Atmospheric Administration (NOAA) European MSP Platform – A collaborative initiative that supports MSP in European waters In areas beyond national jurisdiction, regional or international organizations, such as regional fisheries management organizations or the regional seas organisations may play a role in coordinating and implementing MSP processes. For example, the Nairobi convention which operates across several nations in the Western Indian Ocean and East Africa region has conducted an extensive MSP process combining work across the EEZs of several nations under their SAPPHIRE and WIOSAP programmes. It’s important to note that with the ongoing ratification of the BBNJ Treaty, marine spatial planning methodologies is still a developing field. 41.7.4.3 Major Conventions: Convention on Migratory Species As an environmental treaty of the United Nations, Convention on Migratory Species (CMS) provides a global platform for the conservation and sustainable use of migratory animals and their habitats. CMS brings together the States through which migratory animals pass, the Range States, and lays the legal foundation for internationally coordinated conservation measures throughout a migratory range. CMS Parties strive towards strictly protecting these animals, conserving, or restoring the places where they live, mitigating obstacles to migration and controlling other factors that might endanger them. Parties and Range States of CMS can be found here. While there is no formal process to protect KBAs under the CMS, applying for the protection of specific species that frequently inhabit the identified KBA not only safeguards these migratory species and their habitats but also extends protection to the KBAs themselves. This synergistic approach ensures that both the species and their critical habitats receive the necessary levels of conservation and management. The CMS has however recommended the inclusion and effective conservation of KBAs for migratory species as headline indicators for Target 3 of the Global Biodiversity Framework. This approach would integrate elements of effectiveness, which entails creating favourable conditions, and connectivity, as demonstrated by the status of migratory species. It would rely on standardized monitoring of Key Biodiversity Areas (KBAs) using data collected through on-site observations and remote sensing methods, leveraging existing monitoring practices and datasets which have been highlighted for birds. The coordination of these efforts would be facilitated through the KBA Partnership. If there are certain migratory species within the boundaries of the KBA that should be protected under the Convention on Migratory Species (CMS), there are the general steps one can follow to do so: Understand the CMS and its mandate: ensure that the proposal aligns with the CMS goals and specifically addresses the conservation needs of migratory seabirds. Consult with experts and stakeholders: Engage with experts, scientists, and stakeholders who have expertise in migratory seabirds, marine conservation, and the CMS. Seek their input, advice, and support regarding the proposed KBA and its potential protection under the CMS framework. Prepare a proposal: A state that is party to the CMS must sponsor any proposal for protection. However, civil society groups, researchers or experts can assist the process of developing a comprehensive proposal outlining the ecological importance of the KBA for migratory seabirds, including information on species, populations, breeding and feeding habitats, and migratory pathways. Identify any threats the area faces and propose conservation measures that can be implemented under the CMS framework to address these threats. Existing proposals, as well as Appendix I and II templates can be found here. Engage with the CMS: Contact the CMS Secretariat and express the intention to propose the establishment and protection of the KBA under the CMS. Request guidance on the submission process, relevant agreements, and any specific requirements they may have for such proposals. Submit the proposal: Prepare the formal proposal according to the CMS guidelines and submit it to the Secretariat within the specified timeframe. Include all relevant information, supporting documents, and scientific evidence to strengthen its case. Participate in CMS meetings: If the proposal is accepted, the proposer may be invited to present and discuss it at CMS meetings or relevant working groups. Advocate for support: Reach out to member countries of the CMS and other relevant stakeholders to garner support for the proposal. This may involve diplomatic efforts, raising awareness about the KBA’s significance for migratory seabirds, and mobilizing support from conservation organizations, birding communities, and the scientific community. Follow the decision-making process: The CMS operates through a decision-making process involving the Conference of the Parties (COP) and other subsidiary bodies. The proposal will undergo review and assessment by relevant expert groups and committees. Ultimately, the proposal will be considered for adoption or endorsement during the COP meetings. Monitor and adapt: If the proposal is successful and the KBA is recognized and protected under the CMS, it is crucial to continue monitoring the area and adapting conservation measures as needed. Collaborate with relevant stakeholders and contribute to ongoing research and monitoring efforts related to migratory seabirds and their habitats. 41.7.5 KBA conservation guidance: further information 41.7.5.1 The International Union for Conservation of Nature (IUCN) The IUCN is an international organization that provides guidelines, expertise, and recommendations related to conservation and sustainable management practices. The establishment of MPAs is typically the responsibility of governments or relevant authorities at the national or local level. These authorities are responsible for designating and legally establishing MPAs within their jurisdiction. However, the IUCN plays a crucial role in providing guidance and technical support to governments, stakeholders, and communities in the establishment and management of MPAs. The IUCN’s expertise, including its protected area management categories and guidelines, can assist in developing effective MPA networks, ensuring conservation objectives are met, and promoting best practices in MPA management. Once the conservation needs of the KBA have been identified and its boundaries delineated, the IUCN offers comprehensive guidelines on establishing and effectively managing MPAs. The following steps are recommended: Stakeholder engagement: Identify and engage relevant stakeholders, including local communities, indigenous groups, scientists, and resource users, to gather their perspectives and ensure their involvement throughout the process. Zoning and regulations: Develop a zoning plan that designates specific areas for different levels of protection or use and establish regulations and management measures accordingly. Assess the potential environmental, social, and economic impacts, and develop mitigation measures to address any negative effects. Legal and institutional framework: Legal designation: Identify the appropriate legal mechanisms for designating the MPA, considering national laws and international obligations. Governance structure: Define the governance structure and management arrangements, involving relevant government agencies, local communities, and other stakeholders. Develop a comprehensive management plan: Formulate a management plan that outlines specific objectives, strategies, and actions for conservation, monitoring, enforcement, and community engagement. Allow for flexibility and adaptive responses to changing conditions and new information. Capacity building: Identify capacity needs and develop training programs to enhance the skills and knowledge of MPA managers and staff. Enforcement and compliance: Establish mechanisms for monitoring compliance with regulations, detecting and addressing illegal activities, and imposing appropriate penalties for non-compliance. Establishing marine protected areas, particularly in areas that have been identified as KBAs is key to achieving Target 3 of the Global Biodiversity Framework, which aims for the protection of 30% of marine and coastal areas by 2030 (30x30). The IUCN offers additional guides on how to best achieve 30x30, as well as how to implement effective area-based management tools, conserve connectivity and strengthen ecological networks can be found here. 41.7.5.2 The Global Ocean Biodiversity Initiative The Global Ocean Biodiversity Initiative (GOBI) is not a formal regulatory body but rather a collaborative partnership that supports the conservation and sustainable use of marine biodiversity. While GOBI does not have a specific process for proposing and establishing MPAs, it provides expertise, knowledge and data to support the Convention on Biological Diversity’s efforts to identify ecologically or biologically significant marine areas (EBSAs) by assisting a range of intergovernmental, regional and national organisations to use and develop data, tools and methodologies. GOBI also undertakes research that will generate new science to enhance the value of EBSAs and their utility for promoting environmental protection and management for specific areas of the world’s oceans. The GOBI Advisory Board comprises representatives from the Convention on Biological Diversity, the Convention on the Conservation of Migratory Species of Wild Animals, the Food and Agriculture Organisation, the Global Environment Facility, the International Maritime Organisation, the Intergovernmental Oceanographic Commission of UNESCO, the International Seabed Authority, the UN Development Programme, the UN Environment Programme and, as an observer, the Division for Ocean Affairs and the Law of the Sea of the United Nations Office of Legal Affairs. Therefore, those who want to propose the protection of KBAs may reach out to GOBI to request support and guidance regarding the following: Proposal developments: Advise on the scientific assessment of the marine KBA to gather data on its ecological importance, biodiversity values, and conservation needs. This assessment should include ecological surveys, biodiversity monitoring, and analysis of threats and vulnerabilities. The scientific evidence will support a proposal and inform conservation efforts. Stakeholder Engagement: Engaging with relevant stakeholders, including local communities, scientists, NGOs, and government agencies. As the partnership consists of many diverse NGOs, they can put proposers in contact with relevant local partners within their own partnerships that may act as consultants or stakeholders to a KBA. GOBI Secretariat and Partnerships: Share a MPA proposal with the GOBI Secretariat and relevant partners. The GOBI Secretariat serves as a central hub for coordinating GOBI activities and can provide guidance, support, and feedback on proposals. Collaboration with partners can enhance the implementation of conservation measures and access to resources. GOBI Workshops and Capacity Building: Participate in GOBI workshops, training programs, and capacity-building initiatives. These activities provide opportunities to learn from experts, share experiences, and build technical and scientific capacities related to marine biodiversity conservation. Stay updated on GOBI events and initiatives that can support certain proposals. Funding Opportunities: Explore funding opportunities provided by GOBI and its partners. GOBI often supports projects and initiatives that contribute to marine biodiversity conservation and the establishment of protected areas. Consider applying for relevant grants, awards, or fellowships to secure resources for the implementation of a proposal. 41.7.6 Are KBA conservation actions working? Monitor and document To understand whether the conservation mechanism for a marine megafauna population within the marine KBA is working, it is essential to establish a comprehensive monitoring programme. This programme should regularly assess the status and trends of species populations, including their reproductive success, foraging behaviour, and any changes in their habitat. Collaboration with research institutions, universities, and citizen science initiatives is crucial to collect valuable data on seabird abundance, distribution, and potential threats. Standardized monitoring protocols and methodologies should be implemented to ensure data consistency and comparability over time, enabling accurate analysis of long-term trends. For birds, the BirdLife Datazone offers a framework for monitoring IBAs that can be applied. This framework is being adopted for KBA monitoring. It is important to document any observed changes or threats within the KBA, such as habitat degradation, pollution incidents, emergence of new threats or disturbances. The monitoring findings and reports should be shared with decision-makers, environmental mechanisms, and relevant stakeholders to emphasize the ongoing importance of conserving the KBA and the need for continued conservation efforts where necessary. "],["sites-proposing-an-iba.html", "42 Sites: Proposing an IBA 42.1 Who can propose an IBA? 42.2 Queries about proposing an IBA?", " 42 Sites: Proposing an IBA Previous steps in this toolkit support users to generate the data required for proposing a Key Biodiversity Area (or Important Bird and Biodiversity Area in the case of some BirdLife Partners). Before users have generated this data they should consult with the relevent regional IBA coordinator to understand how they can formally propose a site as an IBA. 42.1 Who can propose an IBA? IBAs must typically be proposed by a BirdLife International partner organisation. In instances where a BirdLife International partner may not have capacity to take a formal lead on a particular site, there must be an opportunity for the partner to be consulted at the minimum. 42.2 Queries about proposing an IBA? Those supporting IBA work want to help. If you have any queries, reach out to us. "],["appendix-tracking-data-advanced-interpolation.html", "43 Appendix: Tracking data: advanced interpolation 43.1 Goal of chapter: 43.2 Interpolation 43.3 Load packages 43.4 Input parameters for chapter tutorial 43.5 Load input example data and prepare for track2KBA R package protocol 43.6 Interpolation methods differences 43.7 Speed filter &amp; linear interpolation 43.8 Plot: speed filtered and linear interpolation data 43.9 Advanced interpolation 43.10 Compare different interplation methods 43.11 Review comparison 43.12 Interpolation: all data", " 43 Appendix: Tracking data: advanced interpolation This chapter uses previously filtered data. It is still a work in progress :) NOTE: if your animal visits land at several other locations beyond the colony, you may need to consider appropriate action for more advanced interpolation methods. 43.1 Goal of chapter: Support further cleaning of tracking data by applying speed filters and interpolation methods. 43.2 Interpolation If you have gaps in your tracking data, you need to fill these gaps for the purpose of the track2KBA protocol. It’s likely you will need to do this for many other tracking data analyses. Broadly speaking, there are two key ways to fill the gaps in your tracking data, a process known as interpolation. These two ways include: - Simpler linear interpolation - More advanced interpolation options that try account for where the animal could have moved (e.g. CRAWL) Typically, for flying seabirds, where gaps in tracking data are less likely because birds do not typically dive underwater for durations as long as diving seabirds, linear interpolation should serve as a suitable starting point. More advanced interpolation methods may be required for diving seabirds, or other diving marine predators. 43.3 Load packages Load required R packages: If the package(s) fails to load, you will need to install the relevant package(s). ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Load libraries -------------------------------------------------------------- ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ &quot;Had to install R version: R version 4.2.2 (2022-10-31 ucrt) for aniMotum&quot; ## [1] &quot;Had to install R version: R version 4.2.2 (2022-10-31 ucrt) for aniMotum&quot; ## Options to install aniMotum package for animal track interpolation ## aniMotum: https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14060 #install.packages(&#39;aniMotum&#39;, repos = c(&#39;https://ianjonsen.r-universe.dev&#39;, &#39;https://cloud.r-project.org&#39;)) # may need to install aniMotum after downloading using: devtools::install_local(package.zip) #install.packages(&#39;TMB&#39;, type = &#39;source&#39;) library(&quot;aniMotum&quot;) ## sf package for spatial data analyses (i.e. vector files such as points, lines, polygons) library(sf) ## Tidyverse for data manipulation library(tidyverse) ## ggplot2 for plotting opionts library(ggplot2) ## rnaturalearth package for basemaps in R library(rnaturalearth) ## leaflet package for interactive maps in R #install.packages(&quot;leaflet&quot;) library(leaflet) ## library(purrr) library(furrr) #install.packages(&quot;track2KBA&quot;) library(track2KBA) ## for date time library(lubridate) ## for stats library(stats) ## speed filter library(trip) ## linear interpolation library(adehabitatLT) 43.4 Input parameters for chapter tutorial Here we define input parameters needed for sections of the code later in this tutorial. Depending on how your data is set up, you should not need to define any further input parameters. ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Specify projections / store needed CRS definitions as variables ---- ## SEE: https://epsg.io/ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## world - unprojected coordinates wgs84 &lt;- st_crs(&quot;EPSG:4326&quot;) ## Croatia - projected coordinates htrs96 &lt;- st_crs(&quot;EPSG:3765&quot;) ## Source a world map from the rnaturalearth R package ## see details of function to change the type of map you get worldmap &lt;- rnaturalearth::ne_download(scale = &quot;large&quot;, type = &quot;countries&quot;, category = &quot;cultural&quot;, destdir = tempdir(), load = TRUE, returnclass = &quot;sf&quot;) ## Reading layer `ne_10m_admin_0_countries&#39; from data source ## `C:\\Users\\jonathan.handley\\AppData\\Local\\Temp\\Rtmp6L566o\\ne_10m_admin_0_countries.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 258 features and 168 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -180 ymin: -90 xmax: 180 ymax: 83.63410065 ## Geodetic CRS: WGS 84 43.5 Load input example data and prepare for track2KBA R package protocol Loading the input example data ## Load the example data for Yelkouan Shearwaters load(&quot;data-testing/tracking-data/Tracking_YESH_raw_step3.Rdata&quot;) ## view the first two rows of data ## First view the data in tibble format #head(tracks,2) ## Then view the data in data frame format head(data.frame(tracks),2) ## dataset_id scientific_name common_name site_name colony_name ## 8 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 9 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## lat_colony lon_colony device ID track_id ## 8 tbc tbc GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## 9 tbc tbc GPS 19_Tag17600_Z-9 19_Tag17600_Z-9 ## original_track_id age sex breed_stage breed_status date_gmt ## 8 19_Tag17600_Z-9 adult unknown chick-rearing breeding 2019-05-24 ## 9 19_Tag17600_Z-9 adult unknown chick-rearing breeding 2019-05-24 ## time_gmt argos_quality equinox dttm bird_id_num Longitude ## 8 03:09:05 NA NA 2019-05-24 03:09:05 15 16.875686 ## 9 03:29:05 NA NA 2019-05-24 03:29:05 15 16.842989 ## Latitude nlocs track_segment track_colour DateTime ## 8 42.863631 8 track.start #66c2a5 2019-05-24 03:09:05 ## 9 42.889146 9 track.start #66c2a5 2019-05-24 03:29:05 ## tripID X Y Returns StartsOut ColDist ## 8 19_Tag17600_Z-9_01 16.875686 42.863631 Yes 5843.849769 ## 9 19_Tag17600_Z-9_01 16.842989 42.889146 Yes 9297.406605 ## dataGroup.Longitude dataGroup.Latitude optional ## 8 16.875686 42.863631 TRUE ## 9 16.842989 42.889146 TRUE 43.6 Interpolation methods differences We will consider some of the different interpolation methods: Linear interpolation CRAWL interpolation 43.6.1 Get example data for testing Based on some previous exploration of the data, here are some individual trips that provide a basis of example data to understand impact of different inteprolation methods. NOTE to JONO: Consider impact of previous buffer choice on selection of final number of trips. [Should we apply relative at-sea buffer at the tripSplit step or later on. Later seems to make sense to me. But this also means we might remove what are considered invidual trips if we increase the buffer size.] ## Checking number of trips in data length(unique(tracks$tripID)) ## [1] 339 Example trips to try: 278: a good track. Although technically colony location might be wrong given buffer applied above. 305: a good track. Seems feasible. 339: a track that goes over land supposedly. 252: dodgey track with too few points most likely. 210: reasonable track, but some big gaps in data likely when birds commuting. 273: obvious location error with single point extremely far away.” Change the input parameter below to select a new unique trip ## Input parameter for selecting unique trips i= 273 ## subset the data from a unique trip bird_track &lt;- data.frame(tracks) %&gt;% dplyr::filter(tripID == unique(tracks$tripID)[i]) ## add a column indicating start and end of tracks bird_track &lt;- bird_track %&gt;% mutate(nlocs = 1:nrow(bird_track)) %&gt;% mutate(track_segment = if_else(nlocs &lt;= 10, &quot;track.start&quot;,&quot;track.journey&quot;)) %&gt;% ## note: if you have a track with less than 20 points, then you will overwrite ## some of the previous data. mutate(track_segment = if_else(nlocs %in% (nrow(bird_track)-9):(nrow(bird_track)),&quot;track.end&quot;,track_segment)) %&gt;% ## add a column indicating colour for start and end of tracks ## colours from: https://colorbrewer2.org/#type=qualitative&amp;scheme=Set2&amp;n=3 mutate(track_colour = if_else(nlocs &lt;= 10, &quot;#66c2a5&quot;,&quot;#8da0cb&quot;)) %&gt;% mutate(track_colour = if_else(nlocs %in% (nrow(bird_track)-9):(nrow(bird_track)),&quot;#fc8d62&quot;,track_colour)) head(data.frame(bird_track),12) ## dataset_id scientific_name common_name site_name colony_name ## 1 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 2 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 3 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 4 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 5 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 6 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 7 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 8 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 9 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 10 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 11 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 12 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## lat_colony lon_colony device ID track_id ## 1 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 2 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 3 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 4 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 5 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 6 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 7 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 8 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 9 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 10 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 11 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 12 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## original_track_id age sex breed_stage breed_status date_gmt ## 1 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 2 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 3 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 4 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 5 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 6 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 7 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 8 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 9 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 10 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 11 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 12 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## time_gmt argos_quality equinox dttm bird_id_num Longitude ## 1 00:41:02 NA NA 2020-05-23 00:41:02 27 16.873765 ## 2 02:00:55 NA NA 2020-05-23 02:00:55 27 16.976549 ## 3 02:40:55 NA NA 2020-05-23 02:40:55 27 16.977327 ## 4 03:21:00 NA NA 2020-05-23 03:21:00 27 17.065564 ## 5 04:01:09 NA NA 2020-05-23 04:01:09 27 17.399801 ## 6 04:56:05 NA NA 2020-05-23 04:56:05 27 17.772279 ## 7 05:40:22 NA NA 2020-05-23 05:40:22 27 17.787105 ## 8 06:25:59 NA NA 2020-05-23 06:25:59 27 17.792098 ## 9 07:41:36 NA NA 2020-05-23 07:41:36 27 17.791651 ## 10 09:27:30 NA NA 2020-05-23 09:27:30 27 17.792932 ## 11 10:57:03 NA NA 2020-05-23 10:57:03 27 17.782182 ## 12 11:43:08 NA NA 2020-05-23 11:43:08 27 17.779680 ## Latitude nlocs track_segment track_colour DateTime ## 1 42.775604 1 track.start #66c2a5 2020-05-23 00:41:02 ## 2 42.837699 2 track.start #66c2a5 2020-05-23 02:00:55 ## 3 42.837664 3 track.start #66c2a5 2020-05-23 02:40:55 ## 4 42.857446 4 track.start #66c2a5 2020-05-23 03:21:00 ## 5 42.844356 5 track.start #66c2a5 2020-05-23 04:01:09 ## 6 42.736141 6 track.start #66c2a5 2020-05-23 04:56:05 ## 7 42.735978 7 track.start #66c2a5 2020-05-23 05:40:22 ## 8 42.737175 8 track.start #66c2a5 2020-05-23 06:25:59 ## 9 42.737054 9 track.start #66c2a5 2020-05-23 07:41:36 ## 10 42.729099 10 track.start #66c2a5 2020-05-23 09:27:30 ## 11 42.736360 11 track.journey #8da0cb 2020-05-23 10:57:03 ## 12 42.735342 12 track.journey #8da0cb 2020-05-23 11:43:08 ## tripID X Y Returns StartsOut ColDist ## 1 20_Tag40118_Z-175_10 16.873765 42.775604 Yes 4236.43456 ## 2 20_Tag40118_Z-175_10 16.976549 42.837699 Yes 10399.61143 ## 3 20_Tag40118_Z-175_10 16.977327 42.837664 Yes 10459.51519 ## 4 20_Tag40118_Z-175_10 17.065564 42.857446 Yes 17999.32080 ## 5 20_Tag40118_Z-175_10 17.399801 42.844356 Yes 44730.44513 ## 6 20_Tag40118_Z-175_10 17.772279 42.736141 Yes 75558.63900 ## 7 20_Tag40118_Z-175_10 17.787105 42.735978 Yes 76766.77599 ## 8 20_Tag40118_Z-175_10 17.792098 42.737175 Yes 77158.00160 ## 9 20_Tag40118_Z-175_10 17.791651 42.737054 Yes 77123.13324 ## 10 20_Tag40118_Z-175_10 17.792932 42.729099 Yes 77331.29092 ## 11 20_Tag40118_Z-175_10 17.782182 42.736360 Yes 76361.42790 ## 12 20_Tag40118_Z-175_10 17.779680 42.735342 Yes 76170.90183 ## dataGroup.Longitude dataGroup.Latitude optional ## 1 16.873765 42.775604 TRUE ## 2 16.976549 42.837699 TRUE ## 3 16.977327 42.837664 TRUE ## 4 17.065564 42.857446 TRUE ## 5 17.399801 42.844356 TRUE ## 6 17.772279 42.736141 TRUE ## 7 17.787105 42.735978 TRUE ## 8 17.792098 42.737175 TRUE ## 9 17.791651 42.737054 TRUE ## 10 17.792932 42.729099 TRUE ## 11 17.782182 42.736360 TRUE ## 12 17.779680 42.735342 TRUE tail(data.frame(bird_track),12) ## dataset_id scientific_name common_name site_name colony_name ## 281 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 282 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 283 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 284 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 285 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 286 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 287 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 288 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 289 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 290 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 291 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 292 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## lat_colony lon_colony device ID track_id ## 281 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 282 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 283 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 284 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 285 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 286 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 287 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 288 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 289 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 290 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 291 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 292 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## original_track_id age sex breed_stage breed_status date_gmt ## 281 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 282 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 283 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 284 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 285 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 286 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 287 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 288 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 289 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 290 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 291 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## 292 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-06-04 ## time_gmt argos_quality equinox dttm bird_id_num Longitude ## 281 09:14:25 NA NA 2020-06-04 09:14:25 27 16.889855 ## 282 10:01:50 NA NA 2020-06-04 10:01:50 27 16.882272 ## 283 10:23:26 NA NA 2020-06-04 10:23:26 27 16.886676 ## 284 10:46:20 NA NA 2020-06-04 10:46:20 27 16.936658 ## 285 11:16:16 NA NA 2020-06-04 11:16:16 27 16.934755 ## 286 12:02:24 NA NA 2020-06-04 12:02:24 27 16.911330 ## 287 12:26:12 NA NA 2020-06-04 12:26:12 27 16.880714 ## 288 12:46:32 NA NA 2020-06-04 12:46:32 27 16.881518 ## 289 13:09:53 NA NA 2020-06-04 13:09:53 27 16.890075 ## 290 14:23:01 NA NA 2020-06-04 14:23:01 27 16.883198 ## 291 16:02:15 NA NA 2020-06-04 16:02:15 27 16.628421 ## 292 20:17:21 NA NA 2020-06-04 20:17:21 27 16.700074 ## Latitude nlocs track_segment track_colour DateTime ## 281 43.247558 281 track.journey #8da0cb 2020-06-04 09:14:25 ## 282 43.246526 282 track.journey #8da0cb 2020-06-04 10:01:50 ## 283 43.184219 283 track.end #fc8d62 2020-06-04 10:23:26 ## 284 43.219847 284 track.end #fc8d62 2020-06-04 10:46:20 ## 285 43.227534 285 track.end #fc8d62 2020-06-04 11:16:16 ## 286 43.253257 286 track.end #fc8d62 2020-06-04 12:02:24 ## 287 43.194572 287 track.end #fc8d62 2020-06-04 12:26:12 ## 288 43.179669 288 track.end #fc8d62 2020-06-04 12:46:32 ## 289 43.175502 289 track.end #fc8d62 2020-06-04 13:09:53 ## 290 43.181891 290 track.end #fc8d62 2020-06-04 14:23:01 ## 291 43.239596 291 track.end #fc8d62 2020-06-04 16:02:15 ## 292 42.866379 292 track.end #fc8d62 2020-06-04 20:17:21 ## tripID X Y Returns StartsOut ColDist ## 281 20_Tag40118_Z-175_10 16.889855 43.247558 Yes 48579.34946 ## 282 20_Tag40118_Z-175_10 16.882272 43.246526 Yes 48432.22494 ## 283 20_Tag40118_Z-175_10 16.886676 43.184219 Yes 41539.87847 ## 284 20_Tag40118_Z-175_10 16.936658 43.219847 Yes 45905.38549 ## 285 20_Tag40118_Z-175_10 16.934755 43.227534 Yes 46728.46321 ## 286 20_Tag40118_Z-175_10 16.911330 43.253257 Yes 49344.41695 ## 287 20_Tag40118_Z-175_10 16.880714 43.194572 Yes 42660.85256 ## 288 20_Tag40118_Z-175_10 16.881518 43.179669 Yes 41010.77314 ## 289 20_Tag40118_Z-175_10 16.890075 43.175502 Yes 40592.20978 ## 290 20_Tag40118_Z-175_10 16.883198 43.181891 Yes 41264.78385 ## 291 20_Tag40118_Z-175_10 16.628421 43.239596 Yes 51055.50065 ## 292 20_Tag40118_Z-175_10 16.700074 42.866379 Yes 14052.11191 ## dataGroup.Longitude dataGroup.Latitude optional ## 281 16.889855 43.247558 TRUE ## 282 16.882272 43.246526 TRUE ## 283 16.886676 43.184219 TRUE ## 284 16.936658 43.219847 TRUE ## 285 16.934755 43.227534 TRUE ## 286 16.911330 43.253257 TRUE ## 287 16.880714 43.194572 TRUE ## 288 16.881518 43.179669 TRUE ## 289 16.890075 43.175502 TRUE ## 290 16.883198 43.181891 TRUE ## 291 16.628421 43.239596 TRUE ## 292 16.700074 42.866379 TRUE ## plot the tracks using leaflet package in R. map &lt;- leaflet() %&gt;% ## start leaflet plot addProviderTiles(providers$Esri.WorldImagery, group = &quot;World Imagery&quot;) %&gt;% ## plot the points. Note: leaflet automatically finds lon / lat colonies ## label by nloc (location) number. Colour accordingly. addCircleMarkers(data = bird_track, label = bird_track$nlocs, radius = 3, fillColor = bird_track$track_colour, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between points addPolylines(lng = bird_track$Longitude, lat = bird_track$Latitude, weight = 1, color = &quot;white&quot;) map ## plot with legend map %&gt;% addLegend(colors = unique(bird_track$track_colour), labels = unique(bird_track$track_segment)) 43.7 Speed filter &amp; linear interpolation First apply the simpler cleaning step to the data: McConnel Speed Filter (i.e. remove points based on unrealistic travel speeds) Linear interpolation (i.e. add missing points on a straight line between known points) ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Speed filter / linear interpolation ---- ## For flying seabirds: CRAWL may not be best bet - linear interpolation may be better.&quot; ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## review example data head(bird_track,2) ## dataset_id scientific_name common_name site_name colony_name ## 1 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 2 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## lat_colony lon_colony device ID track_id ## 1 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 2 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## original_track_id age sex breed_stage breed_status date_gmt ## 1 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 2 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## time_gmt argos_quality equinox dttm bird_id_num Longitude ## 1 00:41:02 NA NA 2020-05-23 00:41:02 27 16.873765 ## 2 02:00:55 NA NA 2020-05-23 02:00:55 27 16.976549 ## Latitude nlocs track_segment track_colour DateTime ## 1 42.775604 1 track.start #66c2a5 2020-05-23 00:41:02 ## 2 42.837699 2 track.start #66c2a5 2020-05-23 02:00:55 ## tripID X Y Returns StartsOut ColDist ## 1 20_Tag40118_Z-175_10 16.873765 42.775604 Yes 4236.43456 ## 2 20_Tag40118_Z-175_10 16.976549 42.837699 Yes 10399.61143 ## dataGroup.Longitude dataGroup.Latitude optional ## 1 16.873765 42.775604 TRUE ## 2 16.976549 42.837699 TRUE ## remove any erroneous locations due to speed use the McConnel Speed Filter ##from the trip package trip_obj &lt;- bird_track %&gt;% #group_by(tripID) %&gt;% dplyr::select(x = X, y = Y, DateTime, everything()) %&gt;% trip() head(trip_obj,2) ## DateTime dataset_id scientific_name common_name ## 1 2020-05-23 00:41:02 tbc Puffinus yelkouan Yelkouan Shearwater ## 2 2020-05-23 02:00:55 tbc Puffinus yelkouan Yelkouan Shearwater ## site_name colony_name lat_colony lon_colony device ID ## 1 Lastovo SPA Z tbc tbc GPS 20_Tag40118_Z-175 ## 2 Lastovo SPA Z tbc tbc GPS 20_Tag40118_Z-175 ## track_id original_track_id age sex breed_stage breed_status ## 1 20_Tag40118_Z-175 20_Tag40118_Z-175 adult unknown chick-rearing breeding ## 2 20_Tag40118_Z-175 20_Tag40118_Z-175 adult unknown chick-rearing breeding ## date_gmt time_gmt argos_quality equinox dttm bird_id_num ## 1 2020-05-23 00:41:02 NA NA 2020-05-23 00:41:02 27 ## 2 2020-05-23 02:00:55 NA NA 2020-05-23 02:00:55 27 ## Longitude Latitude nlocs track_segment track_colour tripID ## 1 16.873765 42.775604 1 track.start #66c2a5 20_Tag40118_Z-175_10 ## 2 16.976549 42.837699 2 track.start #66c2a5 20_Tag40118_Z-175_10 ## Returns StartsOut ColDist dataGroup.Longitude dataGroup.Latitude optional ## 1 Yes 4236.43456 16.873765 42.775604 TRUE ## 2 Yes 10399.61143 16.976549 42.837699 TRUE ## McConnel Speedilter ----- ## apply speedfilter and creat data frame trip_obj$Filter &lt;- speedfilter(trip_obj, max.speed = 100) # speed in km/h trip_obj &lt;- data.frame(trip_obj) head(trip_obj,2) ## x y DateTime dataset_id scientific_name ## 1 16.873765 42.775604 2020-05-23 00:41:02 tbc Puffinus yelkouan ## 2 16.976549 42.837699 2020-05-23 02:00:55 tbc Puffinus yelkouan ## common_name site_name colony_name lat_colony lon_colony device ## 1 Yelkouan Shearwater Lastovo SPA Z tbc tbc GPS ## 2 Yelkouan Shearwater Lastovo SPA Z tbc tbc GPS ## ID track_id original_track_id age sex ## 1 20_Tag40118_Z-175 20_Tag40118_Z-175 20_Tag40118_Z-175 adult unknown ## 2 20_Tag40118_Z-175 20_Tag40118_Z-175 20_Tag40118_Z-175 adult unknown ## breed_stage breed_status date_gmt time_gmt argos_quality equinox ## 1 chick-rearing breeding 2020-05-23 00:41:02 NA NA ## 2 chick-rearing breeding 2020-05-23 02:00:55 NA NA ## dttm bird_id_num Longitude Latitude nlocs track_segment ## 1 2020-05-23 00:41:02 27 16.873765 42.775604 1 track.start ## 2 2020-05-23 02:00:55 27 16.976549 42.837699 2 track.start ## track_colour tripID Returns StartsOut ColDist ## 1 #66c2a5 20_Tag40118_Z-175_10 Yes 4236.43456 ## 2 #66c2a5 20_Tag40118_Z-175_10 Yes 10399.61143 ## dataGroup.Longitude dataGroup.Latitude optional Filter optional.1 ## 1 16.873765 42.775604 TRUE TRUE TRUE ## 2 16.976549 42.837699 TRUE TRUE TRUE ## How many locations were removed with speed filter? nrow(subset(trip_obj, trip_obj$Filter == F)) ## [1] 1 ## plot the original data AND McConnel speed filtered removed values map %&gt;% addCircleMarkers(data = subset(trip_obj, trip_obj$Filter == F), #label = bird_track_gaps$nlocs, radius = 5, fillColor = &quot;black&quot;, fillOpacity = 0.5, stroke = F) %&gt;% addLegend(colors = &quot;black&quot;, labels = &quot;McConnel removed values&quot;) ## Keep only filtered coordinates - after checking dimensions of other outputs again dim(trip_obj) ## [1] 292 38 dim(bird_track) ## [1] 292 36 trip_obj &lt;- subset(trip_obj,trip_obj$Filter==TRUE) dim(trip_obj) ## [1] 291 38 ## Linear interpolation ----- ## Apply linear interpolation step to speed filtered only data ## create ltraj object trip_lt &lt;- as.ltraj(xy = bind_cols(x = trip_obj$x, y = trip_obj$y), date = trip_obj$DateTime, id = trip_obj$tripID) ## Linearly interpolate/re-sample tracks every 30 minutes (specified in seconds) trip_interp &lt;- redisltraj(trip_lt, 1800, type=&quot;time&quot;) head(trip_interp) ## ## *********** List of class ltraj *********** ## ## Type of the traject: Type II (time recorded) ## * Time zone: UTC * ## Regular traject. Time lag between two locs: 1800 seconds ## ## Characteristics of the bursts: ## id burst nb.reloc NAs date.begin ## 1 20_Tag40118_Z-175_10 20_Tag40118_Z-175_10 616 0 2020-05-23 00:41:02 ## date.end ## 1 2020-06-04 20:11:02 ## ## ## infolocs provided. The following variables are available: ## [1] &quot;pkey&quot; ## convert back into format for track2KBA - dataframe for now trip_interp &lt;- ld(trip_interp) %&gt;% dplyr::mutate(Longitude = x, Latitude = y) head(trip_interp,2) ## x y date dx dy ## 1 16.87376500 42.77560400 2020-05-23 00:41:02 0.03860029209 0.0233196328 ## 2 16.91236529 42.79892363 2020-05-23 01:11:02 0.03860029209 0.0233196328 ## dist dt R2n abs.angle rel.angle id ## 1 0.04509753678 1800 0.000000000000 0.5434514602 NA 20_Tag40118_Z-175_10 ## 2 0.04509753678 1800 0.002033787823 0.5434514602 0 20_Tag40118_Z-175_10 ## burst pkey Longitude ## 1 20_Tag40118_Z-175_10 20_Tag40118_Z-175_10.2020-05-23 00:41:02 16.87376500 ## 2 20_Tag40118_Z-175_10 20_Tag40118_Z-175_10.2020-05-23 01:11:02 16.91236529 ## Latitude ## 1 42.77560400 ## 2 42.79892363 [CONSIDER BEST WAY TO ADD RELATED METADATA BACK. Holding script below for now] ## Select key data for track2KBA &quot;update&quot; ## [1] &quot;update&quot; #head(tracks_yelk) #yelk_interp &lt;- yelk_interp %&gt;% dplyr::select(X = x,Y =y, DateTime = date, ID = id) ## update metadata that was lost during interpolation steps &quot;update&quot; ## [1] &quot;update&quot; #yelk_meta &lt;- tracks_yelk %&gt;% # data.frame() %&gt;% # dplyr::select(ID, colony_code) %&gt;% # distinct(ID, colony_code) ## update for track2KBA &quot;update&quot; ## [1] &quot;update&quot; #yelk_interp &lt;- left_join(yelk_interp, yelk_meta, by = &quot;ID&quot;) %&gt;% # st_as_sf(coords = c(&quot;X&quot;, &quot;Y&quot;), crs = wgs84) 43.8 Plot: speed filtered and linear interpolation data ## plot speedfilter &amp; linear interpolation map %&gt;% ## Speed Filtered and Linear interpolated addCircleMarkers(data = trip_interp, #label = bird_track$nlocs, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between Speed Filtered and Linear interpolated points addPolylines(lng = trip_interp$Longitude, lat = trip_interp$Latitude, weight = 1, color = &quot;cyan&quot;) [Review advice on whether linear interpolation is suitable] 43.9 Advanced interpolation [Possibly need to move this to appendix instead. Consider feedback] Advanced interpolation methods such as CRAWL have been simplified with the aniMotum R package. We will apply the steps in the aniMotum R package to apply CRAWL interpolation to the data. ## CRAWL interpolation with aniMotum R package: &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 1: Format the data&quot; ## [1] &quot;STEP 1: Format the data&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; head(bird_track,2) ## dataset_id scientific_name common_name site_name colony_name ## 1 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 2 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## lat_colony lon_colony device ID track_id ## 1 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 2 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## original_track_id age sex breed_stage breed_status date_gmt ## 1 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 2 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## time_gmt argos_quality equinox dttm bird_id_num Longitude ## 1 00:41:02 NA NA 2020-05-23 00:41:02 27 16.873765 ## 2 02:00:55 NA NA 2020-05-23 02:00:55 27 16.976549 ## Latitude nlocs track_segment track_colour DateTime ## 1 42.775604 1 track.start #66c2a5 2020-05-23 00:41:02 ## 2 42.837699 2 track.start #66c2a5 2020-05-23 02:00:55 ## tripID X Y Returns StartsOut ColDist ## 1 20_Tag40118_Z-175_10 16.873765 42.775604 Yes 4236.43456 ## 2 20_Tag40118_Z-175_10 16.976549 42.837699 Yes 10399.61143 ## dataGroup.Longitude dataGroup.Latitude optional ## 1 16.873765 42.775604 TRUE ## 2 16.976549 42.837699 TRUE ## format the data into format required for aniMotum ## NOTE: The format varies for Argos, GPS and GLS data - format accordingly bird_track_am &lt;- bird_track %&gt;% mutate(lc = &quot;G&quot;) %&gt;% dplyr::select(id = &quot;tripID&quot;, date = &quot;dttm&quot;, lc, lon = &quot;Longitude&quot;, lat = &quot;Latitude&quot;) ## review the newly formatted data head(bird_track_am,20) ## id date lc lon lat ## 1 20_Tag40118_Z-175_10 2020-05-23 00:41:02 G 16.873765 42.775604 ## 2 20_Tag40118_Z-175_10 2020-05-23 02:00:55 G 16.976549 42.837699 ## 3 20_Tag40118_Z-175_10 2020-05-23 02:40:55 G 16.977327 42.837664 ## 4 20_Tag40118_Z-175_10 2020-05-23 03:21:00 G 17.065564 42.857446 ## 5 20_Tag40118_Z-175_10 2020-05-23 04:01:09 G 17.399801 42.844356 ## 6 20_Tag40118_Z-175_10 2020-05-23 04:56:05 G 17.772279 42.736141 ## 7 20_Tag40118_Z-175_10 2020-05-23 05:40:22 G 17.787105 42.735978 ## 8 20_Tag40118_Z-175_10 2020-05-23 06:25:59 G 17.792098 42.737175 ## 9 20_Tag40118_Z-175_10 2020-05-23 07:41:36 G 17.791651 42.737054 ## 10 20_Tag40118_Z-175_10 2020-05-23 09:27:30 G 17.792932 42.729099 ## 11 20_Tag40118_Z-175_10 2020-05-23 10:57:03 G 17.782182 42.736360 ## 12 20_Tag40118_Z-175_10 2020-05-23 11:43:08 G 17.779680 42.735342 ## 13 20_Tag40118_Z-175_10 2020-05-23 12:23:14 G 17.779476 42.734154 ## 14 20_Tag40118_Z-175_10 2020-05-23 13:03:13 G 17.772935 42.740455 ## 15 20_Tag40118_Z-175_10 2020-05-23 13:43:13 G 17.768276 42.744929 ## 16 20_Tag40118_Z-175_10 2020-05-23 15:52:24 G 17.807283 42.725885 ## 17 20_Tag40118_Z-175_10 2020-05-23 16:44:49 G 17.798066 42.731225 ## 18 20_Tag40118_Z-175_10 2020-05-23 17:24:49 G 17.569362 42.764891 ## 19 20_Tag40118_Z-175_10 2020-05-23 20:28:07 G 16.896792 42.804893 ## 20 20_Tag40118_Z-175_10 2020-05-24 01:49:27 G 16.888790 42.788237 &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 2: Fit the model&quot; ## [1] &quot;STEP 2: Fit the model&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;When fitting the model, there are some useful parameters to consider&quot; ## [1] &quot;When fitting the model, there are some useful parameters to consider&quot; ## fit the state-space model ## SEE the help file: ?fit_ssm, to understand some of the arguments within the function ## NOTE: the function can do 3 things simultaneously: data formatting step, a pre-filtering step, and the actual model fitting ## INPUT: data.frame, tibble or sf-tibble of observations, depending on the tracking data type fit &lt;- fit_ssm(bird_track_am, ## specify what kind of model you want to fit. See details about different model types in paper. model = &quot;crw&quot;, ## specify the speed at which data points could be considered outlier points (in m/s) vmax = 27, ## time.step in hours - specify time.step of new values to be predicted (interpolation) time.step = 0.5, ## turning angle/s in degrees. remove locations with turning angles set between intervals ## default values are not 0,0 (which will not do anything), but rather 15,25 ang = c(0, 0), ## step lengths in km - check implications for GPS vs. Argos data filtering ## defaults 2500,5000 distlim = c(2500, 5000)) ## fitting crw SSM to 1 tracks... ## pars: 0 0 0 0 pars: 0.93008 0.30696 0.20177 -0.00299 pars: 1.88497 0.03116 0.0922 -0.01351 pars: 3.44545 -1.23135 -0.56662 -0.02755 pars: 4.20599 -2.35909 -2.17381 0.14558 pars: 4.71635 -1.66561 -4.10041 0.24591 pars: 5.2144 -1.41556 -5.48667 0.34885 pars: 5.54323 -1.66357 -5.96781 0.40455 pars: 5.71782 -2.18086 -5.84244 0.42465 pars: 5.77391 -2.71252 -5.44297 0.4225 pars: 5.77391 -2.71252 -5.44297 0.4225 &quot;NOTE: Depending on how you prefilter your data before running fit_ssm, you may want to consider changing some of the function parameters. E.g. you might indicate fit.to.subset = F, if you have filtered your data already and are sure all your locations are true locations.&quot; ## [1] &quot;NOTE: Depending on how you prefilter your data before running fit_ssm, you may\\nwant to consider changing some of the function parameters. E.g. you might indicate\\nfit.to.subset = F, if you have filtered your data already and are sure all your \\nlocations are true locations.&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 3: Review the model fit&quot; ## [1] &quot;STEP 3: Review the model fit&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## review the model summary ## See: https://ianjonsen.github.io/aniMotum/articles/Overview.html &quot;Check that converged and phHess were True. NOTE: I&#39;m not sure what it means if they are false&quot; ## [1] &quot;Check that converged and phHess were True. NOTE: I&#39;m not sure what it means if they are false&quot; fit ## # A tibble: 1 × 5 ## id ssm converged pdHess pmodel ## &lt;chr&gt; &lt;named list&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 20_Tag40118_Z-175_10 &lt;ssm [15]&gt; TRUE TRUE crw &quot;Review overall summaries and SSM details for each individual. Again, not entirely sure what all the important bits are&quot; ## [1] &quot;Review overall summaries and SSM details for each individual. Again, not entirely sure what all the important bits are&quot; #summary(fit) &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 4: Review the different tabular ouputs after fitting the model&quot; ## [1] &quot;STEP 4: Review the different tabular ouputs after fitting the model&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## data.frame of SSM fitted values (location estimates corresponding to the observation times) floc.fitted &lt;- grab(fit, what = &quot;fitted&quot;) ## data.frame of predicted values (corresponding to locations predicted at regular time.step intervals) floc.predicted &lt;- grab(fit, what = &quot;predicted&quot;) ## data.frame of original data with a column indicating which locations to keep or not floc.data &lt;- grab(fit, what = &quot;data&quot;) ## review the new data frames you get and your original data head(data.frame(floc.fitted),2) ## id date lon lat x ## 1 20_Tag40118_Z-175_10 2020-05-23 00:41:02 16.87376504 42.775604 1878.378932 ## 2 20_Tag40118_Z-175_10 2020-05-23 02:00:55 16.97654894 42.837699 1889.820784 ## y x.se y.se u v ## 1 5248.851500 0.002867360468 0.0004212185085 0.009405468279 0.007483220442 ## 2 5258.239344 0.006636952156 0.0004326470664 6.551973003306 5.625237176649 ## u.se v.se s s.se ## 1 0.5970948485 0.594493515 1.856746356e-314 NA ## 2 9.5691434047 9.569135863 1.111640309e+01 NA head(data.frame(floc.predicted),2) ## id date lon lat x ## 1 20_Tag40118_Z-175_10 2020-05-23 00:41:00 16.87376500 42.77560400 1878.378928 ## 2 20_Tag40118_Z-175_10 2020-05-23 01:11:00 16.91178928 42.79809711 1882.611772 ## y x.se y.se u v ## 1 5248.851500 9.999990762e-06 9.999951414e-06 2.630553167e-12 2.092932393e-12 ## 2 5252.251028 4.504251162e+00 4.504240895e+00 8.475094487e+00 6.806617985e+00 ## u.se v.se s s.se ## 1 0.000010000 0.00001000 1.856746329e-314 NA ## 2 9.018512652 9.01850149 1.085794797e+01 NA head(data.frame(floc.data),2) ## id date lc lon lat smaj smin eor ## 1 20_Tag40118_Z-175_10 2020-05-23 00:41:02 G 16.873765 42.775604 NA NA NA ## 2 20_Tag40118_Z-175_10 2020-05-23 02:00:55 G 16.976549 42.837699 NA NA NA ## obs.type keep x y emf.x emf.y ## 1 GPS TRUE 1878.378928 5248.851500 0.1 0.1 ## 2 GPS TRUE 1889.820790 5258.239344 0.1 0.1 head(data.frame(bird_track),2) ## dataset_id scientific_name common_name site_name colony_name ## 1 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## 2 tbc Puffinus yelkouan Yelkouan Shearwater Lastovo SPA Z ## lat_colony lon_colony device ID track_id ## 1 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## 2 tbc tbc GPS 20_Tag40118_Z-175 20_Tag40118_Z-175 ## original_track_id age sex breed_stage breed_status date_gmt ## 1 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## 2 20_Tag40118_Z-175 adult unknown chick-rearing breeding 2020-05-23 ## time_gmt argos_quality equinox dttm bird_id_num Longitude ## 1 00:41:02 NA NA 2020-05-23 00:41:02 27 16.873765 ## 2 02:00:55 NA NA 2020-05-23 02:00:55 27 16.976549 ## Latitude nlocs track_segment track_colour DateTime ## 1 42.775604 1 track.start #66c2a5 2020-05-23 00:41:02 ## 2 42.837699 2 track.start #66c2a5 2020-05-23 02:00:55 ## tripID X Y Returns StartsOut ColDist ## 1 20_Tag40118_Z-175_10 16.873765 42.775604 Yes 4236.43456 ## 2 20_Tag40118_Z-175_10 16.976549 42.837699 Yes 10399.61143 ## dataGroup.Longitude dataGroup.Latitude optional ## 1 16.873765 42.775604 TRUE ## 2 16.976549 42.837699 TRUE &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 5: Plot the different tabular ouputs after fitting the model&quot; ## [1] &quot;STEP 5: Plot the different tabular ouputs after fitting the model&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## plot the FITTED values over original data (i.e. locations used for fitting the model) map %&gt;% addCircleMarkers(data = floc.fitted, #label = bird_track_gaps$nlocs, radius = 3, fillColor = &quot;lightgreen&quot;, fillOpacity = 0.5, stroke = F) %&gt;% addLegend(colors = &quot;lightgreen&quot;, labels = &quot;fitted values&quot;) ## plot the PREDICTED values over original data (i.e. locations predcited from the model) map %&gt;% addCircleMarkers(data = floc.predicted, #label = bird_track_gaps$nlocs, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% addLegend(colors = &quot;cyan&quot;, labels = &quot;predicted values&quot;) ## plot the REMOVED values over original data (i.e. locations that were removed from the prefiltering step) map %&gt;% addCircleMarkers(data = subset(floc.data, floc.data$keep == F), #label = bird_track_gaps$nlocs, radius = 3, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) %&gt;% addLegend(colors = &quot;red&quot;, labels = &quot;removed values&quot;) ## plot the PREDICTED AND REMOVED values over original data (i.e. locations that were removed from the prefiltering step) map %&gt;% addCircleMarkers(data = floc.predicted, #label = bird_track_gaps$nlocs, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% addCircleMarkers(data = subset(floc.data, floc.data$keep == F), #label = bird_track_gaps$nlocs, radius = 5, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 6: Visualising a model fit&quot; ## [1] &quot;STEP 6: Visualising a model fit&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # plot time-series of the fitted values dev.off() ## null device ## 1 plot(fit, what = &quot;fitted&quot;, type = 1, pages = 1) # plot time-series of the predcited values dev.off() ## null device ## 1 plot(fit, what = &quot;predicted&quot;, type = 1, pages = 1) # plot fitted values as a 2-d track dev.off() ## null device ## 1 plot(fit, what = &quot;predicted&quot;, type = 2, pages = 1, ## 95 % confidence ellipses (orange-filled ellipses) around the predicted ## values are also displayed, but can be faded away by choosing a low alpha value alpha = 0.05, ## Observations that failed the prefilter stage are displayed (black x’s) ## by default but can be turned off with the argument outlier = FALSE) outlier = T) # plot fitted values as a 2-d track dev.off() ## null device ## 1 plot(fit, what = &quot;predicted&quot;, type = 2, pages = 1, ## 95 % confidence ellipses (orange-filled ellipses) around the predicted ## values are also displayed, but can be faded away by choosing a low alpha value alpha = 0.00, ## Observations that failed the prefilter stage are displayed (black x’s) ## by default but can be turned off with the argument outlier = FALSE) outlier = T) &quot;CONSIDER: How can we help user to decide whether their data is of high enough quality or not for a track2KBA styled analysis? Perhaps the outputs from grab(fit, what = predicted) can be of help? Here, see an indication of standard errors around predicted locations via (x.se, y.se in km)&quot; ## [1] &quot;CONSIDER: How can we help user to decide whether their data is of high enough\\nquality or not for a track2KBA styled analysis? Perhaps the outputs from \\ngrab(fit, what = predicted) can be of help? Here, see an indication of standard \\nerrors around predicted locations via (x.se, y.se in km)&quot; dev.off() ## null device ## 1 plot(floc.predicted$x.se) dev.off() ## null device ## 1 plot(floc.predicted$y.se) &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 7: Further assessment of model fit&quot; ## [1] &quot;STEP 7: Further assessment of model fit&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## SEE: https://ianjonsen.github.io/aniMotum/articles/SSM_validation.html &quot;Does this assessment take into account all tracks simultanesouly? Or does it only assess each track individually? What are the implications for this assessment in the context of track2KBA? Not sure...&quot; ## [1] &quot;Does this assessment take into account all tracks simultanesouly? Or does it only\\nassess each track individually? What are the implications for this assessment in\\nthe context of track2KBA? Not sure...&quot; # use patchwork package to arrange plot.osar options #library(patchwork) # calculate &amp; plot residuals &quot;NOTE: Computationally intensive! Takes time!!&quot; ## [1] &quot;NOTE: Computationally intensive! Takes time!!&quot; #res.rw &lt;- osar(fit) #(plot(res.rw, type = &quot;ts&quot;) | plot(res.rw, type = &quot;qq&quot;)) / # (plot(res.rw, type = &quot;acf&quot;) | plot_spacer()) &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 8: Assess potential behaviours along track: Move_persistence_models&quot; ## [1] &quot;STEP 8: Assess potential behaviours along track: Move_persistence_models&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## SEE: https://ianjonsen.github.io/aniMotum/articles/Move_persistence_models.html ## NOTE: You can fit this model in two ways ## SEE: Alternate script: tracking_CleanAndPrepareData2_AllTracks_aniMotumAllSteps &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 9: Reroute tracks that went overland back via the sea&quot; ## [1] &quot;STEP 9: Reroute tracks that went overland back via the sea&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## NOTE: This will reroute the point locations only! So if you have a very detailed ## coastline, then it may appear the animals still move over land when plotting lines ## between points. The success of the analysis is also dependent on the underlying ## basemap used. The natural earth map (used by default) is good, but not very finely ## detailed. i.e. resolution could be higher ## install packages #install.packages(&quot;pathroutr&quot;, repos = &quot;https://jmlondon.r-universe.dev&quot;) library(pathroutr) # for rerouting tracks #install.packages(&quot;devtools&quot;) #devtools::install_github(&quot;ropensci/rnaturalearthhires&quot;) library(rnaturalearthhires) # for higher resolution natural earth map ## reroute the track using the predicted values of the previously fitted model fit.reroute &lt;- route_path(fit, what = &quot;predicted&quot;, map_scale = 10, dist = 10000, append = T) ## data.frame of rerouted values ## NOTE: Some of these locations may not be ecologically realistic anymore ## i.e. if you were to recalculate travel speeds, they may be unrealistic ## must consider trade-off of approach accordingly floc.predicted.reroute &lt;- grab(fit.reroute, what = &quot;rerouted&quot;) ## review data head(data.frame(floc.predicted),2) ## id date lon lat x ## 1 20_Tag40118_Z-175_10 2020-05-23 00:41:00 16.87376500 42.77560400 1878.378928 ## 2 20_Tag40118_Z-175_10 2020-05-23 01:11:00 16.91178928 42.79809711 1882.611772 ## y x.se y.se u v ## 1 5248.851500 9.999990762e-06 9.999951414e-06 2.630553167e-12 2.092932393e-12 ## 2 5252.251028 4.504251162e+00 4.504240895e+00 8.475094487e+00 6.806617985e+00 ## u.se v.se s s.se ## 1 0.000010000 0.00001000 1.856746329e-314 NA ## 2 9.018512652 9.01850149 1.085794797e+01 NA head(data.frame(floc.predicted.reroute),2) ## id date lon lat x ## 1 20_Tag40118_Z-175_10 2020-05-23 01:11:00 16.91178928 42.79809711 1882.611772 ## 2 20_Tag40118_Z-175_10 2020-05-23 01:41:00 16.95701156 42.82535314 1887.645892 ## y x.se y.se ## 1 5252.251028 4.504251162 4.504240895 ## 2 5256.372077 3.176431626 3.176422433 ## plot original vs predicted vs re-routed map %&gt;% ## Predicted addCircleMarkers(data = floc.predicted, #label = bird_track$nlocs, radius = 5, fillColor = &quot;green&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between predicted points addPolylines(lng = floc.predicted$lon, lat = floc.predicted$lat, weight = 1, color = &quot;green&quot;) %&gt;% ## RE-ROUTED addCircleMarkers(data = floc.predicted.reroute, #label = bird_track$nlocs, radius = 3, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between re-routed points addPolylines(lng = floc.predicted.reroute$lon, lat = floc.predicted.reroute$lat, weight = 1, color = &quot;red&quot;) &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 10: Reroute tracks that went overland back via the sea using pathroutr package&quot; ## [1] &quot;STEP 10: Reroute tracks that went overland back via the sea using pathroutr package&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## SEE: https://rdrr.io/github/jmlondon/pathroutr/f/vignettes/reroute_demo.Rmd ## Consider the tutorial for pathroutr ## NOTE: This is very computationally expensive when you have many data points ## and high resolution coastline data. Therefore, it may be worth subsetting ## parts of the track that go over land and trying to reroute these parts only. ## Then you could merge these parts of the track back onto the remainder of the track &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 11: Simulate animal tracks&quot; ## [1] &quot;STEP 11: Simulate animal tracks&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## NOTE: This step is used more for habitat modelling / SDMs. ## Step not required for track2KBA st &lt;- sim_fit(fit, what=&quot;predicted&quot;, reps=5, ## cpf: is the animal exhibiting central place foraging behaviour? cpf=T) dev.off() ## null device ## 1 #plot(st) &quot;NOTE: Can also reroute these simulated tracks again as above. Will need to consider application of this step.&quot; ## [1] &quot;NOTE: Can also reroute these simulated tracks again as above.\\nWill need to consider application of this step.&quot; 43.10 Compare different interplation methods Now that you have applied the different inteprolation methods, you can compare the outputs. Compare the outputs via visual inspection. [Consider discussions about ways to support comparisons] ## plot original vs predicted from aniMotum vs re-routed from aniMotum vs speedfilter &amp; linear interpolation map %&gt;% ## Predicted addCircleMarkers(data = floc.predicted, #label = bird_track$nlocs, radius = 5, fillColor = &quot;green&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between predicted points addPolylines(lng = floc.predicted$lon, lat = floc.predicted$lat, weight = 1, color = &quot;green&quot;) %&gt;% ## RE-ROUTED addCircleMarkers(data = floc.predicted.reroute, #label = bird_track$nlocs, radius = 3, fillColor = &quot;red&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between re-routed points addPolylines(lng = floc.predicted.reroute$lon, lat = floc.predicted.reroute$lat, weight = 1, color = &quot;red&quot;) %&gt;% ## Speed Filtered and Linear interpolated addCircleMarkers(data = trip_interp, #label = bird_track$nlocs, radius = 3, fillColor = &quot;cyan&quot;, fillOpacity = 0.5, stroke = F) %&gt;% ## plot lines between Speed Filtered and Linear interpolated points addPolylines(lng = trip_interp$Longitude, lat = trip_interp$Latitude, weight = 1, color = &quot;cyan&quot;) 43.11 Review comparison You can see from plot above that the “advanced” interpolation method of CRAWL via aniMotum creates some additional loops on the tracking data. I.e it appears that the animal sort of shoots past some points and then returns back. Either this tutorial is applying the aniMotum protocol incorrectly to the data, OR: It’s likely that the algorithm underpinning something like CRAWL is more suited to animal tracking data for diving marine predators that move much more slowly. Future examples should consider comparisons with tracking data for diving marine predators. 43.12 Interpolation: all data [Will also need to find appropriate way to bind metadata back to individual trips] Now that you have compared interpolation methods, you will want to apply the interpolation to all trips from the tracked animals. 43.12.1 Linear interpolation: all animals # ## total number of trips # length(unique(tracks$tripID)) # # ## create data frame and remove trips with &lt;5 locations; as required for track2KBA analysis # trips_to_keep &lt;- data.frame(tracks) %&gt;% # group_by(tripID) %&gt;% # summarise(triplocs = n()) %&gt;% # dplyr::filter(triplocs &gt; 5) # # ## # tracks_df &lt;- data.frame(tracks) %&gt;% # dplyr::filter(tripID %in% trips_to_keep$tripID) # # ## # length(unique(tracks_df$tripID)) # # ## start blank df # tracks_interp_df &lt;- data.frame() # # for(i in 1:length(unique(tracks_df$tripID))){ # temp &lt;- tracks_df %&gt;% dplyr::filter(tripID == unique(tracks_df$tripID)[i]) # # ## remove any erroneous locations due to speed use the McConnel Speed Filter # ##from the trip package # trip_obj &lt;- temp %&gt;% # #group_by(tripID) %&gt;% # dplyr::select(x = X, # y = Y, # DateTime, # everything()) %&gt;% # trip() # # ## McConnel Speedilter ----- # ## apply speedfilter and creat data frame # trip_obj$Filter &lt;- speedfilter(trip_obj, max.speed = 100) # speed in km/h # trip_obj &lt;- data.frame(trip_obj) # head(trip_obj,2) # # ## How many locations were removed with speed filter? # nrow(subset(trip_obj, trip_obj$Filter == F)) # # ## Keep only filtered coordinates - after checking dimensions of other outputs again # trip_obj &lt;- subset(trip_obj,trip_obj$Filter==TRUE) # # ## Linear interpolation ----- # ## Apply linear interpolation step to speed filtered only data # # ## create ltraj object # trip_lt &lt;- as.ltraj(xy = bind_cols(x = trip_obj$x, # y = trip_obj$y), # date = trip_obj$DateTime, # id = trip_obj$tripID) # # ## Linearly interpolate/re-sample tracks every 30 minutes (specified in seconds) # trip_interp &lt;- redisltraj(trip_lt, 1800, type=&quot;time&quot;) # head(trip_interp) # # ## convert back into format for track2KBA - dataframe for now # trip_interp &lt;- ld(trip_interp) %&gt;% # dplyr::mutate(Longitude = x, # Latitude = y) # # ## bind back onto dataframe # tracks_interp_df &lt;- rbind(tracks_interp_df, trip_interp) # # ## remove temporary items before next loop iteration # rm(temp,trip_lt,trip_obj) # # ## # print(i) # # } # # ## review it worked by checking total number of unique trips and comparing to original # length(unique(tracks_df$tripID)) # length(unique(tracks_interp_df$id)) 43.12.1.1 Review interpolation for all animals ## Review interpolation for all animals # head(tracks_interp_df,2) 43.12.1.2 Save linear interpolation for all animals for next steps ## save updated file for next steps #save(tracks_interp_df, file = &quot;data-testing/tracking-data/Tracking_YESH_raw_step4.Rdata&quot;) 43.12.2 Advanced interpolation: all animals ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## aniMotum filter: All trips ---- ## Bulk filter individual trips from all birds ---- &quot;May need to consider a way of bulk checking quality of data.&quot; ## [1] &quot;May need to consider a way of bulk checking quality of data.&quot; ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; &quot;STEP 1: Format the data&quot; ## [1] &quot;STEP 1: Format the data&quot; &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; ## [1] &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # all_track_am &lt;- data.frame(tracks) %&gt;% mutate(lc = &quot;G&quot;) %&gt;% # dplyr::select(id = &quot;tripID&quot;, # date = &quot;dttm&quot;, # lc, # lon = &quot;Longitude&quot;, # lat = &quot;Latitude&quot;) # # ## remove trips with &lt;5 locations; as required for track2KBA analysis # trips_to_keep &lt;- all_track_am %&gt;% # group_by(id) %&gt;% # summarise(triplocs = n()) %&gt;% # dplyr::filter(triplocs &gt; 5) # # ## filter out the tracks # all_track_am &lt;- all_track_am %&gt;% dplyr::filter(id %in% trips_to_keep$id) # # # ## # head(all_track_am,2) # length(unique(all_track_am$id)) # # # &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # &quot;STEP 2: Fit the model&quot; # &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # # ## fit the model to all data # fit_alltrack &lt;- fit_ssm(all_track_am, # ## specify what kind of model you want to fit. See details about different model types in paper. # model = &quot;crw&quot;, # ## specify the speed at which data points could be considered outlier points (in m/s) # vmax = 27, # ## time.step in hours - specify time.step of new values to be predicted (interpolation) # time.step = 0.5) # # &quot;NOTE: Depending on how you prefilter your data before running fit_ssm, you may # want to consider changing some of the function parameters. E.g. you might indicate # fit.to.subset = F, if you have filtered your data already and are sure all your # locations are true locations.&quot; # # # &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # &quot;STEP 3: Review the model fit&quot; # &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # # ## review the model summary # ## See: https://ianjonsen.github.io/aniMotum/articles/Overview.html # &quot;Check that converged and phHess were True. NOTE: I&#39;m not sure what it means if they are false&quot; # fit_alltrack # fit_alltrack %&gt;% dplyr::filter(converged == F) # fit_alltrack %&gt;% dplyr::filter(pdHess == F) # &quot;Review overall summaries and SSM details for each individual. Again, not entirely sure what all the important bits are&quot; # summary(fit_alltrack) # # &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # &quot;STEP 9: Reroute tracks that went overland back via the sea&quot; # &quot;~~~~~~~~~~~~~~~~~~~~~~~&quot; # # ## NOTE: This will reroute the point locations only! So if you have a very detailed # ## coastline, then it may appear the animals still move over land when plotting lines # ## between points. The success of the analysis is also dependent on the underlying # ## basemap used. The natural earth map (used by default) is good, but not very finely # ## detailed. i.e. resolution could be higher # # ## reroute the track using the predicted values of the previously fitted model # fit.reroute.all &lt;- route_path(fit_alltrack, # what = &quot;predicted&quot;, # map_scale = 10, # dist = 10000, # append = T) # # ## data.frame of rerouted values # ## NOTE: Some of these locations may not be ecologically realistic anymore # ## i.e. if you were to recalculate travel speeds, they may be unrealistic # ## must consider trade-off of approach accordingly # floc.predicted.reroute &lt;- grab(fit.reroute, what = &quot;rerouted&quot;) # # ## review data # head(data.frame(floc.predicted),2) # head(data.frame(floc.predicted.reroute),2) "],["contact-us.html", "44 Contact us", " 44 Contact us The primary contact for this toolkit is Jonathan Handley: jonathan.handley@birdlife.org Members of the Marine Science team at BirdLife International can also be contacted for support. "],["references.html", "45 References", " 45 References Aarts, Geert, John Fieberg, and Jason Matthiopoulos. 2012. “Comparative Interpretation of Count, Presenceabsence and Point Methods for Species Distribution Models.” Methods in Ecology and Evolution 3 (1): 177–87. https://doi.org/10.1111/j.2041-210X.2011.00141.x. Arranz, Patricia, David L. Borchers, Natacha Aguilar De Soto, Mark P. Johnson, and Martin J. Cox. 2014. “A New Method to Study Inshore Whale Cue Distribution from Land-Based Observations.” Marine Mammal Science 30 (2): 810–18. https://doi.org/10.1111/mms.12077. Beal, Martin, Maria P. Dias, Richard A. Phillips, Steffen Oppel, Carolina Hazin, Elizabeth J. Pearmain, Josh Adams, et al. 2021. “Global Political Responsibility for the Conservation of Albatrosses and Large Petrels.” Science Advances 7 (10): eabd7225. https://doi.org/10.1126/sciadv.abd7225. Beal, Martin, Steffen Oppel, Jonathan Handley, Elizabeth J. Pearmain, Virginia Morera-Pujol, Ana P. B. Carneiro, Tammy E. Davies, et al. 2021. “track2KBA: An R Package for Identifying Important Sites for Biodiversity from Tracking Data.” Methods in Ecology and Evolution 12 (12): 2372–78. https://doi.org/10.1111/2041-210X.13713. BirdLife International. 2010. Marine Important Bird Areas Toolkit: Standardised Techniques for Identifying Priority Sites for the Conservation of Seabirds at Sea. Version 1.2. Cambridge, UK: BirdLife International. Bolton, Mark. 2021. “GPS Tracking Reveals Highly Consistent Use of Restricted Foraging Areas by European Storm-petrels Hydrobates Pelagicus Breeding at the Largest UK Colony: Implications for Conservation Management.” Bird Conservation International 31 (1): 35–52. https://doi.org/10.1017/S0959270920000374. Boyd, Charlotte, Thomas M. Brooks, Stuart H. M. Butchart, Graham J. Edgar, Gustavo A. B. Da Fonseca, Frank Hawkins, Michael Hoffmann, Wes Sechrest, Simon N. Stuart, and Peter Paul Van Dijk. 2008. “Spatial Scale and the Conservation of Threatened Species.” Conservation Letters 1 (1). https://doi.org/10.1111/j.1755-263X.2008.00002.x. Boyd, Charlotte, Ramiro Castillo, George L. Hunt, André E. Punt, Glenn R. VanBlaricom, Henri Weimerskirch, and Sophie Bertrand. 2015. “Predictive Modelling of Habitat Selection by Marine Predators with Respect to the Abundance and Depth Distribution of Pelagic Prey.” Edited by Michael Wunder. Journal of Animal Ecology 84 (6): 1575–88. https://doi.org/10.1111/1365-2656.12409. Browning, Ella, Mark Bolton, Ellie Owen, Akiko Shoji, Tim Guilford, and Robin Freeman. 2018. “Predicting Animal Behaviour Using Deep Learning: GPS Data Alone Accurately Predict Diving in Seabirds.” Edited by Jana McPherson. Methods in Ecology and Evolution 9 (3): 681–92. https://doi.org/10.1111/2041-210X.12926. Buckland, Stephen T., M. Louise Burt, Eric A. Rexstad, Matt Mellor, Adrian E. Williams, and Rebecca Woodward. 2012. “Aerial Surveys of Seabirds: The Advent of Digital Methods.” Journal of Applied Ecology 49 (4): 960–67. https://doi.org/10.1111/j.1365-2664.2012.02150.x. Burger, Alan E., and Scott A. Shaffer. 2008. “APPLICATION OF TRACKING AND DATA-LOGGING TECHNOLOGY IN RESEARCH AND CONSERVATION OF SEABIRDS.” The Auk 125 (2): 253–64. https://doi.org/10.1525/auk.2008.1408. Camphuysen, Kees, Tony Fox, Mardik Leopold, and Ib Peterson. 2004. “Towards Standardised Seabirds at Sea Census Techniques in Connection with Environmental Impact Assessments for Offshore Wind Farms in the U.K.” Carroll, Matthew J., Ewan D. Wakefield, Emily S. Scragg, Ellie Owen, Simon Pinder, Mark Bolton, James J. Waggitt, and Peter G. H. Evans. 2019. “Matches and Mismatches Between Seabird Distributions Estimated From At-Sea Surveys and Concurrent Individual-Level Tracking.” Frontiers in Ecology and Evolution 7 (September): 333. https://doi.org/10.3389/fevo.2019.00333. Chandler, Richard B., Daniel A. Crawford, Elina P. Garrison, Karl V. Miller, and Michael J. Cherry. 2022. “Modeling Abundance, Distribution, Movement and Space Use with Camera and Telemetry Data.” Ecology 103 (10): e3583. https://doi.org/10.1002/ecy.3583. Chimienti, Marianna, Thomas Cornulier, Ellie Owen, Mark Bolton, Ian M. Davies, Justin M. J. Travis, and Beth E. Scott. 2017. “Taking Movement Data to New Depths: Inferring Prey Availability and Patch Profitability from Seabird Foraging Behavior.” Ecology and Evolution 7 (23): 10252–65. https://doi.org/10.1002/ece3.3551. Critchley, E. J., W. J. Grecian, A. Bennison, A. Kane, S. Wischnewski, A. Cañadas, D. Tierney, J. L. Quinn, and M. J. Jessopp. 2020. “Assessing the Effectiveness of Foraging Radius Models for Seabird Distributions Using Biotelemetry and Survey Data.” Ecography 43 (2): 184–96. https://doi.org/10.1111/ecog.04653. Croxall, John P., Stuart H. M. Butchart, Ben Lascelles, Alison J. Stattersfield, Ben Sullivan, Andy Symes, and Phil Taylor. 2012. “Seabird Conservation Status, Threats and Priority Actions: A Global Assessment.” Bird Conservation International 22 (1): 1–34. https://doi.org/10.1017/S0959270912000020. Dias, Maria P., Rob Martin, Elizabeth J. Pearmain, Ian J. Burfield, Cleo Small, Richard A. Phillips, Oliver Yates, Ben Lascelles, Pablo Garcia Borboroglu, and John P. Croxall. 2019. “Threats to Seabirds: A Global Assessment.” Biological Conservation 237 (September): 525–37. https://doi.org/10.1016/j.biocon.2019.06.033. Dias, Maria P., Steffen Oppel, Alexander L. Bond, Ana P. B. Carneiro, Richard J. Cuthbert, Jacob González-Solís, Ross M. Wanless, et al. 2017. “Using Globally Threatened Pelagic Birds to Identify Priority Sites for Marine Conservation in the South Atlantic Ocean.” Biological Conservation 211 (July): 76–84. https://doi.org/10.1016/j.biocon.2017.05.009. Diop, N, L Zango, A Beard, Ct Ba, Pi Ndiaye, L Henry, E Clingham, S Oppel, and J González-Solís. 2018. “Foraging Ecology of Tropicbirds Breeding in Two Contrasting Marine Environments in the Tropical Atlantic.” Marine Ecology Progress Series 607 (December): 221–36. https://doi.org/10.3354/meps12774. Donald, Paul F., Lincoln D. C. Fishpool, Ademola Ajagbe, Leon A. Bennun, Gill Bunting, Ian J. Burfield, Stuart H. M. Butchart, et al. 2019. “Important Bird and Biodiversity Areas (IBAs): The Development and Characteristics of a Global Inventory of Key Sites for Biodiversity.” Bird Conservation International 29 (2): 177–98. https://doi.org/10.1017/S0959270918000102. Elith, J., J. R. Leathwick, and T. Hastie. 2008. “A Working Guide to Boosted Regression Trees.” Journal of Animal Ecology 77 (4): 802–13. https://doi.org/10.1111/j.1365-2656.2008.01390.x. Evans, Rhian, Mary-Anne Lea, and Mark A. Hindell. 2021. “Predicting the Distribution of Foraging Seabirds During a Period of Heightened Environmental Variability.” Ecological Applications 31 (5): e02343. https://doi.org/10.1002/eap.2343. Fox, Ch, Fh Huettmann, Gka Harvey, Kh Morgan, J Robinson, R Williams, and Pc Paquet. 2017. “Predictions from Machine Learning Ensembles: Marine Bird Distribution and Density on Canada’s Pacific Coast.” Marine Ecology Progress Series 566 (February): 199–216. https://doi.org/10.3354/meps12030. Garriga, Joan, John R. B. Palmer, Aitana Oltra, and Frederic Bartumeus. 2016. “Expectation-Maximization Binary Clustering for Behavioural Annotation.” Edited by Attila Gursoy. PLOS ONE 11 (3): e0151984. https://doi.org/10.1371/journal.pone.0151984. Gilman, Eric, Milani Chaloupka, Brett Wiedoff, and Jeremy Willson. 2014. “Mitigating Seabird Bycatch During Hauling by Pelagic Longline Vessels.” Edited by Antoni Margalida. PLoS ONE 9 (1): e84499. https://doi.org/10.1371/journal.pone.0084499. Glennie, R., S. T. Buckland, R. Langrock, T. Gerrodette, L. T. Ballance, S. J. Chivers, and M. D. Scott. 2021. “Incorporating Animal Movement Into Distance Sampling.” Journal of the American Statistical Association 116 (533): 107–15. https://doi.org/10.1080/01621459.2020.1764362. Gutowsky, Sarah E., Marty L. Leonard, Melinda G. Conners, Scott A. Shaffer, and Ian D. Jonsen. 2015. “Individual-Level Variation and Higher-level Interpretations of Space Use in Wide-ranging Species: An Albatross Case Study of Sampling Effects.” Frontiers in Marine Science 2 (November). https://doi.org/10.3389/fmars.2015.00093. Häkkinen, Henry, Silviu O. Petrovan, William J. Sutherland, and Nathalie Pettorelli. 2021. “Terrestrial or Marine Species Distribution Model: Why Not Both? A Case Study with Seabirds.” Ecology and Evolution 11 (23): 16634–46. https://doi.org/10.1002/ece3.8272. Hastie, Trevor, and Will Fithian. 2013. “Inference from Presence-Only Data; the Ongoing Controversy.” Ecography 36: 864–67. https://doi.org/10.1111/j.1600-0587.2013.00321.x. Hays, Graeme C., Helen Bailey, Steven J. Bograd, W. Don Bowen, Claudio Campagna, Ruth H. Carmichael, Paolo Casale, et al. 2019. “Translating Marine Animal Tracking Data into Conservation Policy and Management.” Trends in Ecology &amp; Evolution 34 (5): 459–73. https://doi.org/10.1016/j.tree.2019.01.009. Hochachka, Wesley M., Rich Caruana, Daniel Fink, Art Munson, Mirek Riedewald, Daria Sorokina, and Steve Kelling. 2007. “Data-Mining Discovery of Pattern and Process in Ecological Systems.” The Journal of Wildlife Management 71 (7): 2427–37. https://doi.org/10.2193/2006-503. Hodges, Samuel, Kjell Einar Erikstad, and Tone Kirsten Reiertsen. 2022. “Predicting the Foraging Patterns of Wintering Auks Using a Sea Surface Temperature Model for the Barents Sea.” Ecological Solutions and Evidence 3 (4): e12181. https://doi.org/10.1002/2688-8319.12181. Huettmann, Falk, Yuri Artukhin, Olivier Gilg, and Grant Humphries. 2011. “Predictions of 27 Arctic Pelagic Seabird Distributions Using Public Environmental Variables, Assessed with Colony Data: A First Digital IPY and GBIF Open Access Synthesis Platform.” Marine Biodiversity 41 (1): 141–79. https://doi.org/10.1007/s12526-011-0083-2. Humphries, Grant Richard Woodrow. 2015. “Estimating Regions of Oceanographic Importance for Seabirds Using A-Spatial Data.” Edited by Hans-Ulrich Peter. PLOS ONE 10 (9): e0137241. https://doi.org/10.1371/journal.pone.0137241. Johnston, Alison, Wesley M. Hochachka, Matthew E. Strimas-Mackey, Viviana Ruiz Gutierrez, Orin J. Robinson, Eliot T. Miller, Tom Auer, Steve T. Kelling, and Daniel Fink. 2021. “Analytical Guidelines to Increase the Value of Community Science Data: An Example Using eBird Data to Estimate Species Distributions.” Edited by Yoan Fourcade. Diversity and Distributions 27 (7): 1265–77. https://doi.org/10.1111/ddi.13271. Krietsch, J, S Hahn, M Kopp, Ra Phillips, Hu Peter, and S Lisovski. 2017. “Consistent Variation in Individual Migration Strategies of Brown Skuas.” Marine Ecology Progress Series 578 (August): 213–25. https://doi.org/10.3354/meps11932. Krüger, L., J. A. Ramos, J. C. Xavier, D. Grémillet, J. González-Solís, Y. Kolbeinsson, T. Militão, et al. 2017. “Identification of Candidate Pelagic Marine Protected Areas Through a Seabird Seasonal-, Multispecific- and Extinction Risk-Based Approach.” Animal Conservation 20 (5): 409–24. https://doi.org/10.1111/acv.12339. Lavers, Jennifer L., Mark G. R. Miller, Michael J. Carter, George Swann, and Rohan H. Clarke. 2014. “Predicting the Spatial Distribution of a Seabird Community to Identify Priority Conservation Areas in the Timor Sea.” Conservation Biology 28 (6): 1699–709. https://doi.org/10.1111/cobi.12324. Lemos, Carolina Alves, Mauricio Hernández, Cristiano Vilardo, Richard A. Phillips, Leandro Bugoni, and Isabel Sousa-Pinto. 2023. “Environmental Assessment of Proposed Areas for Offshore Wind Farms Off Southern Brazil Based on Ecological Niche Modeling and a Species Richness Index for Albatrosses and Petrels.” Global Ecology and Conservation 41 (January): e02360. https://doi.org/10.1016/j.gecco.2022.e02360. Lieske, David J., David A. Fifield, and Carina Gjerdrum. 2014. “Maps, Models, and Marine Vulnerability: Assessing the Community Distribution of Seabirds at-Sea.” Biological Conservation 172 (April): 15–28. https://doi.org/10.1016/j.biocon.2014.02.010. Lilliendahl, Kristjan, Jon Solmundsson, Gudmundur A Gudmundsson, and Lorna Taylor. 2003. “Can Surveillance Radar Be Used to Monitor the Foraging Distribution of Colonially Breeding Alcids?” The Condor 105: 145–50. Louzao, M, J Bécares, B Rodríguez, Kd Hyrenbach, A Ruiz, and Jm Arcos. 2009. “Combining Vessel-Based Surveys and Tracking Data to Identify Key Marine Areas for Seabirds.” Marine Ecology Progress Series 391 (September): 183–97. https://doi.org/10.3354/meps08124. Matthiopoulos, Jason, Ewan Wakefield, Jana W. E. Jeglinski, Robert W. Furness, Mark Trinder, Glen Tyler, Aly Mccluskie, Sophy Allen, Janelle Braithwaite, and Tom Evans. 2022. “Integrated Modelling of Seabird-Habitat Associations from Multi-Platform Data: A Review.” Journal of Applied Ecology 59 (4): 909–20. https://doi.org/10.1111/1365-2664.14114. McClintock, Brett T., and Théo Michelot. 2018. “momentuHMM: R Package for Generalized Hidden Markov Models of Animal Movement.” Edited by Sarah Goslee. Methods in Ecology and Evolution 9 (6): 1518–30. https://doi.org/10.1111/2041-210X.12995. Merow, Cory, Matthew J. Smith, and John A. Silander. 2013. “A Practical Guide to MaxEnt for Modeling Species’ Distributions: What It Does, and Why Inputs and Settings Matter.” Ecography 36 (10): 1058–69. https://doi.org/10.1111/j.1600-0587.2013.07872.x. Mikami, Katsura, Kentaro Kazama, Mami T. Kazama, and Yutaka Watanuki. 2022. “Mapping the Collision Risk Between Two Gull Species and Offshore Wind Turbines: Modelling and Validation.” Journal of Environmental Management 316 (August): 115220. https://doi.org/10.1016/j.jenvman.2022.115220. Oppel, Steffen, Mark Bolton, Ana P. B. Carneiro, Maria P. Dias, Jonathan A. Green, Juan F. Masello, Richard A. Phillips, et al. 2018. “Spatial Scales of Marine Conservation Management for Breeding Seabirds.” Marine Policy 98 (December): 37–46. https://doi.org/10.1016/j.marpol.2018.08.024. Oppel, Steffen, Ana Meirinho, Iván Ramírez, Beth Gardner, Allan F. O’Connell, Peter I. Miller, and Maite Louzao. 2012. “Comparison of Five Modelling Techniques to Predict the Spatial Distribution and Abundance of Seabirds.” Biological Conservation 156 (November): 94–104. https://doi.org/10.1016/j.biocon.2011.11.013. Orben, Rachael A., Abram B. Fleishman, Abraham L. Borker, William Bridgeland, Amanda J. Gladics, Jessica Porquez, Peter Sanzenbacher, et al. 2019. “Comparing Imaging, Acoustics, and Radar to Monitor Leach’s Storm-Petrel Colonies.” PeerJ 7 (April): e6721. https://doi.org/10.7717/peerj.6721. Patterson, Allison, Hugh Grant Gilchrist, Lorraine Chivers, Scott Hatch, and Kyle Elliott. 2019. “A Comparison of Techniques for Classifying Behavior from Accelerometers for Two Species of Seabird.” Ecology and Evolution 9 (6): 3030–45. https://doi.org/10.1002/ece3.4740. Pereira, Jorge M., Lucas Krüger, Nuno Oliveira, Ana Meirinho, Alexandra Silva, Jaime A. Ramos, and Vítor H. Paiva. 2018. “Using a Multi-Model Ensemble Forecasting Approach to Identify Key Marine Protected Areas for Seabirds in the Portuguese Coast.” Ocean &amp; Coastal Management 153 (March): 98–107. https://doi.org/10.1016/j.ocecoaman.2017.12.014. Phillips, Elizabeth M., John K. Horne, Jeannette E. Zamon, Jonathan J. Felis, and Josh Adams. 2019. “Does Perspective Matter? A Case Study Comparing Eulerian and Lagrangian Estimates of Common Murre ( Uria Aalge ) Distributions.” Ecology and Evolution 9 (8): 4805–19. https://doi.org/10.1002/ece3.5083. Plumptre, Andrew J., Daniele Baisero, Thomas M. Brooks, Graeme Buchanan, Stuart H. M. Butchart, Anne Bowser, Charlotte Boyd, et al. 2024. “Targeting Site Conservation to Increase the Effectiveness of New Global Biodiversity Targets.” One Earth 7 (1): 11–17. https://doi.org/10.1016/j.oneear.2023.12.007. Quillfeldt, Petra, Jan O. Engler, Janet R. D. Silk, and Richard A. Phillips. 2017. “Influence of Device Accuracy and Choice of Algorithm for Species Distribution Modelling of Seabirds: A Case Study Using Black-Browed Albatrosses.” Journal of Avian Biology 48 (12): 1549–55. https://doi.org/10.1111/jav.01238. Renner, Ian W., Jane Elith, Adrian Baddeley, William Fithian, Trevor Hastie, Steven J. Phillips, Gordana Popovic, and David I. Warton. 2015. “Point Process Models for Presence-Only Analysis.” Edited by Robert B. O’Hara. Methods in Ecology and Evolution 6 (4): 366–79. https://doi.org/10.1111/2041-210X.12352. Renner, M, Jk Parrish, Jf Piatt, Kj Kuletz, Ae Edwards, and Gl Hunt. 2013. “Modeled Distribution and Abundance of a Pelagic Seabird Reveal Trends in Relation to Fisheries.” Marine Ecology Progress Series 484 (June): 259–77. https://doi.org/10.3354/meps10347. Requena, S., S. Oppel, A. L. Bond, J. Hall, J. Cleeland, R. J. M. Crawford, D. Davies, et al. 2020. “Marine Hotspots of Activity Inform Protection of a Threatened Community of Pelagic Species in a Large Oceanic Jurisdiction.” Animal Conservation 23 (5): 585–96. https://doi.org/10.1111/acv.12572. Robinson, Néstor M., Wendy A. Nelson, Mark J. Costello, Judy E. Sutherland, and Carolyn J. Lundquist. 2017. “A Systematic Review of Marine-Based Species Distribution Models (SDMs) with Recommendations for Best Practice.” Frontiers in Marine Science 4 (December): 421. https://doi.org/10.3389/fmars.2017.00421. Scales, Kylie L., Peter I. Miller, Simon N. Ingram, Elliott L. Hazen, Steven J. Bograd, and Richard A. Phillips. 2016. “Identifying Predictable Foraging Habitats for a Wide-Ranging Marine Predator Using Ensemble Ecological Niche Models.” Edited by Wilfried Thuiller. Diversity and Distributions 22 (2): 212–24. https://doi.org/10.1111/ddi.12389. Smith, Adam D., Scott R. McWilliams, Kristopher J. Winiarski, Carol L. Trocki, Brian Harris, Jason E. Osenkowski, and Peter W. C. Paton. 2015. “Using Land-Based Surveys to Assess Sea Duck Abundance and Behavior in Nearshore Waters of Southern New England, USA.” Waterbirds 38 (3): 252–59. https://doi.org/10.1675/063.038.0305. Spear, Larry B, David G Ainley, Britta Denise Hardesty, Steve N G Howell, and Sophie W Webb. 2004. “Reducing Biases Affecting at-Sea Surveys of Seabirds: Use of Multiple Observer Teams.” Marine Ornithology 32: 147–57. Tasker, Mark L., Peter Hope Jones, Tim Dixon, and Barry F. Blake. 1984. “Counting Seabirds at Sea from Ships: A Review of Methods Employed and a Suggestion for a Standardized Approach.” The Auk 101 (3): 567–77. https://doi.org/10.1093/auk/101.3.567. Torres, Leigh G., Philip J. H. Sutton, David R. Thompson, Karine Delord, Henri Weimerskirch, Paul M. Sagar, Erica Sommer, Ben J. Dilley, Peter G. Ryan, and Richard A. Phillips. 2015. “Poor Transferability of Species Distribution Models for a Pelagic Predator, the Grey Petrel, Indicates Contrasting Habitat Preferences Across Ocean Basins.” Edited by Antoni Margalida. PLOS ONE 10 (3): e0120014. https://doi.org/10.1371/journal.pone.0120014. Waggitt, James J., Pierre W. Cazenave, Ricardo Torres, Benjamin J. Williamson, and Beth E. Scott. 2016. “Quantifying Pursuit-Diving Seabirds’ Associations with Fine-Scale Physical Features in Tidal Stream Environments.” Edited by Gavin Siriwardena. Journal of Applied Ecology 53 (6): 1653–66. https://doi.org/10.1111/1365-2664.12646. Wakefield, Ewan D., Ellie Owen, Julia Baer, Matthew J. Carroll, Francis Daunt, Stephen G. Dodd, Jonathan A. Green, et al. 2017. “Breeding Density, Fine-Scale Tracking, and Large-Scale Modeling Reveal the Regional Distribution of Four Seabird Species.” Ecological Applications 27 (7): 2074–91. https://doi.org/10.1002/eap.1591. Waliczky, Zoltan, Lincoln D. C. Fishpool, Stuart H. M. Butchart, David Thomas, Melanie F. Heath, Carolina Hazin, Paul F. Donald, Aida Kowalska, Maria P. Dias, and Tristram S. M. Allinson. 2019. “Important Bird and Biodiversity Areas (IBAs): Their Impact on Conservation Policy, Advocacy and Action.” Bird Conservation International 29 (2): 199–215. https://doi.org/10.1017/S0959270918000175. Warwick-Evans, V., N. Kelly, L. Dalla Rosa, A. Friedlaender, J. T. Hinke, J. H. Kim, N. Kokubun, et al. 2022. “Using Seabird and Whale Distribution Models to Estimate Spatial Consumption of Krill to Inform Fishery Management.” Ecosphere 13 (6): e4083. https://doi.org/10.1002/ecs2.4083. Weber, Sam B., Andrew J. Richardson, Judith Brown, Mark Bolton, Bethany L. Clark, Brendan J. Godley, Eliza Leat, et al. 2021. “Direct Evidence of a Prey Depletion ‘Halo’ Surrounding a Pelagic Predator Colony.” Proceedings of the National Academy of Sciences 118 (28): e2101325118. https://doi.org/10.1073/pnas.2101325118. Žydelis, Ramūnas, Rebecca L. Lewison, Scott A. Shaffer, Jeffrey E. Moore, Andre M. Boustany, Jason J. Roberts, Michelle Sims, et al. 2011. “Dynamic Habitat Models: Using Telemetry Data to Project Fisheries Bycatch.” Proceedings of the Royal Society B: Biological Sciences 278 (1722): 3191–3200. https://doi.org/10.1098/rspb.2011.0330. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
